

serialized build
	when  no pbsfiles are changed
	
	create a list of dependencies for each node
	create a build file for each node
		use the pbsfile to pull in all build subs
			no depend is run since we already have the dependency list
		
		multiple nodes using the pbsfile can be build together
			loading a pbsfile takes little time 
	
	create a list of dependent for each node
		let us look up serialized build files without having to compute anything 



prepare for next parallel run
	once a build is done we can prepare for the next run by analysing the graph
		split the graph so distribution doesn't require computation
			given a list of changed nodes we can start only the build of
			sub graphs and propagate the nodes that are rebuild in the sub graphs up
			
			

virtual graph splitting node
		given a graph with 500 dependencies (this is aan unlikely use case!)
			create a 5 new nodes, each having 100 dependencies
			make the original node depend on the 2 new nodes
			
			as each new node is a its own sub graph, we can schedule
			each one separately

			each one can get a simplified pbsfile which doesn't need to run all the
			rules


? use slurm to manage cluster
	or simpler bash cluster management

variables as nodes
	can have dependencies
		do they change when dependency change => no
			but we could warn when a dependent variable is changed after the dependent used it
				there are two places where variables can change
					in the pbsfile
					while the rules are executed

	can be computed
	can be checked
	can be a dependency

	all : a.o %CC
		%CC $< $@

	%CC: %CC_DEBUG
		if %CC_DEBUG .....
		%CC = "%CC_DEBUG %CC"
		%CC == '' and die

	%CC_DEBUG :
		%CC_DEBUG == '' and die
		
warp time
	load time reduction
		save graph with
			link to file containing all nodes data in warp format
			nodes containing
				md5
				link to individual nodes warp data
					in warp format or preferably in full format (if only fews nodes are reloaded)
					full node format could be in the node's digest
	eliminate warp regeneration
			the graph is not needed
				just a list of files and what they trigger
				node depth can be used to optimize node invalidation

			non live nodes data is not accessed anymore, no need to regenerate node

			only added/changed changed data are re-serialize, the graph/list is update

	save time reduction
		create patch and add it to previous warp file 
		when necessary do a garbage collection

		
link graph+hash, all node, individual nodes
graph patch and gc


? Allow code inside rule
	see shake https://shakebuild.com/manual

	rule 'all',
		Code => sub which can define rule local variable, ...
		Match(...)
		reh ;

FS Log/Stream
	rather than generate a monolitic output, put the sections pertaining to a node where the node is build
	output generator can follow nodes instead for reading a stream

FS History
	add information about the build
	each build has it's own directory
	artefacts that are not regenerated can stay in the other build directory and only linked, this gives us history across builds
		if multiple artefacts are generated in the same directory it becomes difficult to know what rule build what
			artefact.log tells us
			.artefact.dir can be a sub directory that contains the artefact, and links to its dependencies
	and makes it possible to write scripts to track the origin of artefacts

Do we need 'Rule'

	Match 'all' => qr/all/, Match(something else) # more than 2 arguments act like Rule
		reh,
		reh ;

	rule 'all',
		Match qr/all',
		Match(something else),
		reh,
		reh ;
		

	rule 'all' => qr/all/, Match(something else)
		reh,
		reh ;

	rule 'all' => Match => qr/all', Match(something else, return tupple), # rule finds tuples and runs REH
		reh,
		reh ;
		
idea for output renderer
	each chunk of data that's displayed also has UUID that's displayed
	if the renderer only display some information about the data, it's possible to apply
	another renderer on the same data without having to re-run

	a simple application could update the renderers dynamically
		or even present a choice of renderers

build distribution
	the remote node don't need to have the whole graph, they can build sub graphs
		same environment/tools
		same code base

		give a target, a config, and a pbsfile

		even better if there are no links

	
	linking nodes can also use the env/codebase + target + config + pbsfile
		if two sub graphs have common nodes (which would be linked if they were in the same process)
			if the above is equal the graphs are compatible

	linking nodes rather than computing their sub graph (and making sure they are equal in all dependeing processes)
	is to minimize the time spend building their sub graphs.
		building sub graphs is not, in most cases, is not too time consuming, that needs to be compared
		with the complexity added to synchronize the processes graphs

		another advantage of local "common node" sub graph is that it can be checked locally if the process is remote

		different processes may have different intermediary nodes and create different build sequences
			the build can be optimized by comparing the build sequences and the remote process build sequence
			changed 

			building different nodes on different machines means those nodes need to synchronized
				a post build command that's injected
				a new intermediary node

				the receiving machine must also wait for the specific node
					a binary repo could queue requests

				when a process waits for a node, a new ode builder is created to continue building, when the 
				node is received, the process dies and is removes from the builders list

			building all the nodes on the remote process has the advantage of updating the generated artefacts and 
			they will be available in next build

				we can:
					synchronize the build nodes around after the build
					let the remote process build the entire graph (its graph)
					let check verify where the is available
						the binary cache could have a link rather than the artefact

multiple matching pbsfiles rules
	we want to be able to match multiple times a node that is to be depended in a pbsfile
		for example to add switches to the subpbs run
			particularely via rule injection

	as long as we don't define dependencies and builders
		what if we want to depend in another pbsfile too?

		why can't a pbsfile node have a builder somewhere else?

sugar wrapping pbs calls
	when a complex set of operation is needed, it's easy to create new function that call the pbs API
	
	the pbs API remembers where it is called to display the call site

	all the wrapped calls get the wrong call site

	we can call PBS internal rule registration and give another call site
		this would show the place where the wrapper was called

	but we also want to know where the wrapper is, not only its call site

	we want a call stack from the pbsfile down to the API call

	either implement it with the API taking the call stack till it finds a pbsfile or
		by setting a call stack in each wrapper, that lets the wrapper writter
		show/hide what she wants and add the text she wants to the caller place

	an option controls if the stack is displayed

	=> see PBS::Stack

Documentation
	guided tours
	vocabulary list
	snapshots of runs
		debug session
		graph generation
		...
	videos
	pod site to generate HTML or other formats
	debugging document
	option documentation
		each option is documented and it's effects shown as well as how it interacts with other options 

pbs distribution digest is computed for every build process
	makes sense if it's distributed but on the same machine it's a waste of resources

distributed pbs, sub graph selection
	to work efficiently on a sub graph in a build process we need to get a sub graph
	that has as little dependencies as possible on other sub graphs, preferably none
	which remove the need for synchronization

	to find such graphs we need to start "numbering the nodes"

	A -> 1 2 3
	1 -> a aa aaa 
	2 -> b bb bbb
	3 -> c cc aaa
	
	A: 1
		1: 11
			a: 111
			aa: 112
			aaa: 113

		2: 12
			b: 121
			bb: 122
			bbb: 123

		3: 13
			c: 131
			cc: 132
			aaa: 113

	we can also tag sub graphs that link to other sub graph, 13 in this example
		3: 13, links: 113
	
	counting the nodes in the sub graph also helps us balance the load
		A: 1, nodes: 13
			1: 11, nodes: 4

	the tag also gives the depth of the node so we can indent the rule matching and dependency list
		
	different processes will build different sub graphs but two sub graphs can hold a very different
		number of nodes, a build process is allowed to split its sub graph into smaller sub graphs
		and build them in other processes, the processes would preferably be on the same computer
		but can also be send to remote machines


	when checking the graph we look into a distributed node repository, among all the build nodes, that information
		can also be used to distribute sub graphs more efficiently

		the build nodes need to be synched to the build nodes that will _use_ them, ie a node with those dependencies
		needs to be rebuild, there's no use to synch all the nodes

		the node repos could synch which each other continuously if no build is ongoing (as to save resources for the build)
	
	before building we try to find already build artefacts on the build nodes, we get a triggered graph
		triggering information is part of the node so it's available in the sub graph
		if we need to remote a subgraph for build we can send start a pbs instance at the sub graph root
			since we have a config for the package, we can also send a warp/meso file to speedup
			the instance. it will have to rebuild the graph, load rules, ... but it's a simple distribution scheme
			what it returns is a location for the build nodes, or it can put them in the local node repository

	pbsfiles could be a nice boundary for the distributed depend
		we could also reload a pbsfile to depend a specific node
			the node@root builds a whole graph and build only node, we want a different mechanism for 
			depend node@root, we want only the sub graph containing node to be created, we do have more information
			than node@root to help, we have the full path to the node, since it is being depended in another process
			that wants to off load it to another process, node@root/dep1/dep2/dep3/... in a single pbsfile

	distributed nodes have their own pool of processes but can query the main pbs for other distributed nodes that have free
	resources, the distributed nodes work directly with each other distributing the graph in a mesh of pbs nodes
		the nodes could ask each other for resources without the main pbs having any knowledge about it

	depending in a distributed environment
		we need to synch the pbsfiles, only the needed pbsfiles, the nodes could fetch the needed pbsfiles on demand, from the mesh
			there's no need to synch although a simple VCS command can do it more efficiently and in a simpler to control way

		nodes are added unless they exist in which case they are linked
			nodes can be anywhere in the distributed graph

			we need an efficient mechanism to check for existing nodes


		what when a process has finished depending a sub graph?
			check it and create meso files

			the process could serialize the sub graph and exit but it's more
			efficient to keep the process in memory and have it handle multiple sub graphs
				we need a pbs front end that accepts commands via RPC and that will create multiple separate graphs


	 	we can create the same node in multiple graphs as long it is exactly equivalent (config, pbsfile, build system, ...)
			we just want to build it only once, on the most logical node

			what if two pbs depend nodes add the same node, to which one other would link?
				to the one on the same pbs depend node but in other process
				to one on another pbs depend node
				to whichever, they are equivalent

				we just want to build one, although we could build it multiple times

			to build just once we need to synch the triggered nodes before we generate a build sequence
				if all the pbs nodes build everything it would be a monumental waste of time!

			LOCAL needs to be implemented so we actually get the nodes we need locally

			if a build is done but not all nodes are local we can run a build with a rules that adds LOCAL to all nodes
				the graph will be build, distributed too, and checked before a nothing to build and a LOCAL
				suych of all nodes

				the other way is to get the nodes from the warp file and synch them, if one is sure the latest build is done 

		still it is a better to link to nodes than to re-create them as they may have a deep sub graph themselves
			we can ask the other nodes what they have in they sub graphs
			they return a list of nodes and the highest index so we only need to synch the new nodes next time

			we can ask for other nodes every X amount of nodes added and handle discrepancy if it happens
			
			if an equivalent node is available on another pbs node we can cut its sub graph and just link to it
				it important that the other nodes doesn't do the same thing
				the sub graph we want to remove may itself have nodes we are linking to, those nodes should be in the other
				sub graph but it may not be in it yet, the linked node may just have appeared, the machine is slower to run rules
				more processes are running on that machine, ...

				we don't need to cut the subgraph, we need to link the nodes to the "master" nodes

				we want to link to the nodes so we don't have to depend them at all locally
			
				it doesn't matter which node become the linked node "source" as long as all the pbs nodes know which one it is
					if the processes are numbered in start order, for each sub graph, we can link to the lowest process
					number node

		checking out files is on demand
			if each build node has to checkout everything we are wasting resources since we want to work on sub graphs only

			we need a list of the files and their hashes as well as a way to get them, either via a vcs or via a shared repo
				there's no reason to not add pbsfile, source files, ... to the "binary" repo

			synch of large files should not be done at all, we should remote the build on the nodes where the files are
	

FORCED and __PBS_FORCE_TRIGGER
	both are used to force the triggering of a node

	FORCED always forces the triggering

	__PBS_FORCE_TRIGGER[:reason] is a dependency added by a depender to force the triggering
		the depender can dynamically decide to trigger the dependentg

		the check phase handles __PBS_FORCE_TRIGGER

		we get a nice message and it's easier to debug the way it's implemented

	is this useful? 
		the old use case was the C depender triggering if a H file was changed
		but we now integrate the H files in the graph and pbs handles them as 
		any nodes

Creator vs IMMEDIATE_BUILD
	Creator, file that need to exists before depending a node
		often a file that itself points to other dependencies

		often a single file but mechanism should be good enough to handle complicated dependencies
			a: b at dependency time but
			b:c and b:d at dependency time
			d: needs to exist

	C: "list that is included in C"(LIC)
	LIC: processed "files in a diretory"

must IMMEDIATE_BUILD be inherited?
	IMMEDIATE BUILD builds a node just after it is depended
		before the rest of the graph is depended

	=>  no, as the node dependencies are build first
		so there is no need to inherit the IMMEDIATE_BUILD type

	it is still interesting to know when a node is build due to IMMEDIATE_BUILD
		the node itself
		the dependencies, including the information about which node started the build

		pbs1 display a build cause, not found on disk, digest. dependencies, or --triger
			this would be a good place to add the information


single run builder
	builder that's runs only once and build multiple files

	this is useful if a tool generates multiple artefacts
	we can list all the dependencies and when one is build the other are build too

	in pbs 1 we either wrapped the builder or used a node sub that wrapped the builder when a node matches

	we must insure that the builder is only called once, even if the build is run in parallel
		if depend is not run in parallel
			we can wrap the builder so it checks a semaphore 
				we can listen to a socket on the main process
					heavy

				we can use a lock file
					doesn't support distributed build except if FS is shared

					when is the lock file removed?
		
				we can use pbs as a key value db and have a tmp/ dir that's remove after each run
					we can use the file system as back-end in /tmp and a unique directory per run

how do we make build and parallel build into real nodes?


log data sources, viewer, and time line
	
	log display is based on the idea that everything is output by the system and
	a different process displays what's relevant, this allow us to change what's
	relevant dynamically and even go back in "log time" and re-display data
		eg, late i the build we want to see how a top node was created and
		where it's config was changed. We can look at the top node was created
		and continue from where we left


	log is a serialization of time
		we can look back in time anywhere in the log

		we can look while the system is building or when the system is build

	
	time travel in log (also called history in other requirements)
		we know what node are in the graph at each log step, so we can run from a specific point
			the closes specific point to a pbsfile node creation and even node creation
			if we serialize the rules used to create nodes with the nodes

			not sure there's use case, using the log to find an error is usually followed
			by a fix and running a build again not continuing in the debugger which would
			be another time line but it's possible even if it requires a more advanced UI
	

	given the parallel nature of a build system (specially if depend is also run in parallel) the
	log data sources are also generated in parallel. the visualization system must be aware of
	when the sources are available, this can split in two processes, one that "simply" displays data
	based on an incoming stream and another process creating the stream from the different sources


build from top vs triggers build

	most build are driven by a target, eg: some top node all

	we have a list of all the nodes in the graph 
		all the dependencies

		all the dependents

	we can check the nodes and start all relevant builds (that contain a triggered node) 
		computing all the top targets
			top targets are for one specific configuration (node may not exists in all configurations)

	we can also have multiple dependency graphs ("builds") with different configurations
		merge the parts that have the same configuration -> that's meso except meso doesn't need merging

		point at parts that are different
			that's different meso warp files, if they were named after the top target
			we could find all the meso that build the same node 


	trigger build are very useful when we want to discover paths or don't know which top target to build

		ISO9000 example
			all: doc_ok, lamp_off, air_clean

			air_clean: ventilation_ok, no_toxins

			no_toxins: no(toxins)

			toxin: display_toxin_warning, call_help(toxin), open_ventilation
				
		
		#note: call_help(toxin) and no(toxins) are unique nodes based on a template


		we can search in the graph for "toxin", "call_help(toxin)", ...
		we can see the "toxin" graph lines
			what todo (can be multiple)
			what they depend on

		verify the completeness, in the examples toxins is named but not handled "toxin" is

		nodes can be assigned data, eg: timing, so we could get the minimum time it taxes to
			handle toxics in the air

pbsfile nodes
	correspond to real files
	contains the data that's internal to pbs and serializes them

	possibility to ask for a pbsfile "build" in a pbsfile
		with different targets: depend, check, build, postbs, ...

		have a node for each of those targets

		the idea is to have an alternative to PBSFILE_CONTENT and make the api to build it
		available in the pbsfile

			pbsfile: ordered_rules
				REH_RUN_PBSFILE_RULES

			ordered_rules : rule_ordering_pbsfile
				IMMEDIATE_BUILD
				re-order_rules_builder rule_ordering_pbsfile

			rule_ordering_pbsfile

				CREATOR (not needed if dependent is IMMEDIATE_BUILD)

				serialize curent pbsfile rules # because we like having artefacts
				create rule_ordering_pbsfile


	we can access the internal data in rules
		pbsfile: subpbsfile
			build (we know subpbsfile node is up to date)
				print subpbsfile.some_data
					eg: compute cumulative time for this branch of the graph

	we can get a build sequence for the pbsfile node chain and build it in parallel
		as if each pbsfile node was a mini build system
		in a different process, makes the build more robust and we can re-start where an error occured


meso are graph "libraries"
	building a graph with meso looks like linking an executable
		there are symbols (nodes) that are needed and libraries of
		symbols (themselves possibly containing needed symbols) that we try to link
		to generate an executable (a graph)

	what can we learn from linking technologies

		symbol table for quick lookup

		library format in sections

		tools to manipulate libraries: concatenate, strip, linker, loader, ...

		
	dynamic libraries are loaded at run time, how does that relate to graph construction?

virtual pbsfile
	once a virtual pbsfile has been accepted as the pbs source it should be THE pbsfile
		no two different ways to handle virtual and non virtual pbsfile
			same error message, ...

		we can keep an origin and display it
		virtual pbsfiles are generated for various reasons
			to replace another type of souce, IE: virtual studio projects get transformed to pbsfiles
			to run a mini "build", IE: rule ordering

			the virtual pbsfile has a purpose, it's target but the target name doesn't reflect what's to
			be done
		

			=> 
				pbsfile (file or virtual)
				origin
				purpose
rule merging
	in pbs1 we generate rules to find order of execution of ordered rules
		the rules are generated then merged to speed up the execution 

		all rules with the same targets are merged in one rule

		the rules are bare bones, just dependent and dependency


	it's seldom we have many rules with the same dependent (same regex works too)
		we'd need to merge the REHs too

	one case is when a rule matches everything, those can be merged to
	all other rules, if options are implemented as rules we could merge the option
	rules to other rules.
		
	a simpler, and maybe cleaner, implementation would be to keep the rules that
	match everything in a separate group and apply them when a node is added
		that works if the rules don't have an order

	handling the option-match_all separately allows us to not show dependency data on the display
	for them
		using log output we could filter those out instead


completion, documentation, help, ...
	ask pbs to do completion rather than a bash script

	-doc seems broken in pbs 1, what did we want to achieve compared to static doc

	perldoc like help or info format

	man pages

Rules run order

	see rule_order example in pbs 1

	rules are run in registration order in pbs1
	
	we want to control at the rule level in which order they are run

	first/last
	before other_rule
	after other_rule
		this is in itself a little dependency graph that can be wrong
			circular
			impossible to run
				rules want to be before each other
				last rule that's not last

From time to completion example
	can't set config on source nodes
		maybe we could only run node subs
			but we need to "build" the source nodes to get any result


		IsNodeDigestGenerated means node is source so
			no rules is run on the node
			the node is not build
			no digest is generated

			why?
				as long as the source is not changed what is done in pbs data structures
				has no impact

		IsNodeDigestGenerated  can be replaced by a rule

			rule the_source, builder => SourceBuilder

			this lets us add node subs and extra "builders" to source nodes

			SourceBuilder is called only if the source is changed and can log something interesting

			another problem is that nodes have to be build to generate gant data so once a node is built
			the node has to change so the gant data is rebuild
				this is the problem with data that has no file like gant!

				the right thing would be to have a gant data file generated for each node
					done!

				rule gant
					match, everything that's not a gant file
					post builder: find the not gant file node and use it's dependencies

					better idea is to have a node added for each non gant node
						=> implemented in example

						not gant node get a gant dependency
						gant dependency depender finds the matching node and extracts it's dependencies

						rule order doesn't matter as the not gant node is always completely depended before
						it's dependencies (including it's gant node) are depended.

	we want to run a build that does a computation on the graph, via builders, rather than the normal build
		post pbs would do but we need a target!
		
		how do we "not build" the graph? eg: if a has a builder and we want to compute a.gant without building a
			specially if a.gant is a dependency to a, once it's build a will also be build

	we may want to run both a normal build plus the graph computation at the same time, or one of them

	not only do we want to have multiple builders but we want to chose between which ones to run
		this has to be done via a category since we may want multiple builders in a category to be run
			eg node a has two builder, one to be run for normal build and one, doing nothing but succeeding
			to run for graph computation.

		DefaultTarget('all') ;

		# adding a rule depending on a target for all nodes is easy
		# the rule can also match specific nodes

		push @builders = \&gant if target gant
		rule * 
			builders => gant
		
		rule [V], gant, BuildOk() ;

		
		# removing the other rules is more complicated
		push @builders = \&normal if target all
		rule all
			builders => @builders

		pbs
		pbs all 
		pbs gant
		pbs gant all
		
	postpbs solved the graph computation but can't be run in warp as time data is not saved from the node config

		should all the node config be saved?

		postpbs is after build but we want this to be run post depend

		postpbs works because the node are depended in the same process
			if depend is parallelized postpbs can't see the timing data in other processes


		=> it's much better if the timing data and computation actually produce an artefact which serves as 
			a synch object between processes
	
		rules, via node subs, can add elements to warped nodes
			this would allow the gant data to be available when running warp and thus not limit gant to warp 0 (no warp)

option to display some element of the node in a graph
	should  be set via a node sub
		ยก thought this was already implemented !

Default target
	pbs has no default targt and certainly doesn't run the first rule in the pbsfile

	targets can be added in the pbs.prf file

	it should be possible to declare a target in the pbsfile which is used only if notarget is given in the prf or the command line
		DefaultTarget => something
		DefaultTarget('something')
		...


	if no default target is found we could
		run a sub, help() for example
			the user can define which subs to look for 
		 
		assign a default target, help for example
			the user can define which target to use

	can targets be defined in different pbsfiles at different levels?
		what if a target in a subpbs is itself a root

		that's bit like node at root except that it's node@inserted_nodes

prf for a tree of pbsfiles
	the prf file is searched for when running pbs in the root

	sometimes we want to run pbsfiles in sub directories but still use the prf (specially if it doesn't contain a target)
		we could scan the directories above

		note that we really want to avoid changing directory to run a subpbs 
			
NoDigest
	function used to record regex used to tag nodes as source files

	the name could be better,specially for people who don't want to learn about digest
		IsSouce
		SourceNodes
		...

	we could also assume that nodes that are not depended are source node
		we could do that depending on an option

		we can display the list of node that are assumed to be source node, and log them

		it's OK to assume as if the node is not present pbs will display an error

		if it is a generated node and has no rule then it will be uses as is till the rules contain a builder
		
		NoDigest can still be used, then no assumption is made

time to completion
	we want to use pbs to generate time plan for activities
	the activities are described as a dependency tree
	each activity has a "build time" which can be zero, a "start time" which can be immediate, and a set of dependencies
			#build time" and "start time" are attributes to nodes

	the time to completion of a node is max(time of completion dependencies, "start time") + "build time"
		this is computed by traversing the dependency graph

		all activities are run in parallel or a dependency must be added

	this can be implemented as a builder for a "time to completion" node (virtual or, better, a physical report)

	a rule for "time to completion" is added in a pbsfile, the node is dependent on the top target or any target we want to compute
	a time to completion for, the only thing needed is a dependency tree we can traverse

build phases as a dependency graph:

	these artifacts depend on a pbs phase being done
		time to completion -> dependency
		graph generation -> dependency
		build analysis -> build
		warp generation -> build
		build -> warp loading
		...

	we can describe the relationship between these phases as a dependency graph
		each "node" can be build by a builder, a perl sub for internals or even an external program which
		returns data we can integrate in the dependency graph


	eg:
		pbs run
			warp generation
			build analysis
				build
					build nodes
						generate digest
				time to completion
					dependency graph
						rule execution
							pbsfile loading
						warp loading
							check node digest
								regenerate nodes
	

	since rules and REH have no knowledge about a build system we can use them to describe and implement the build system
		eg: adding warp as dependencies rather than a piece of code at a specific place

			this lets add warp/caching anywhere in the graph, ie: C dependency computation


	to create a dependency graph for the build phases we need a description file, a "build phase pbsfile" which is an internal
	implementation

	some of the nodes in the phases graph are optional/user defined
		graph generation
		time to completion
		...

		the user should be able to give a "build phase pbsfile"

		we could also manipulate the rules ser in the "build phases pbsfile" with code injection

			options are run at every level so they can add rules and nodes to the "build phase pbsfile"

			code injection (same mechanism as options) could manipulate the "build phase pbsfile" rules more deeply
				remove some rules dynamically, insert a new phase between to phases, ...

				although possible, it seems better to clone the "build phase pbsfile"



alternative dependency definition
	a more "graphical" dependency definition, note that this is what the graph looks like when depend is done

		dependencies pbs run
			warp generation
			build analysis
				build
				time to completion
					depend
						warp loading


Linking to an existing node can be under the control of the user
	eg: a module knows that a node shouldn't exist before the module is run


handle ENV in warp
	that means handle CM for all the tools too, that can't be done automatically by pbs

distribute centralized data
	statistics can be per loaded package and merged together on demand

	package config is in the PBS::Config module but should be in the package
		this was done to force manipulation of config via API and remove the possibility to directly access the config
		it also allows inheritance of configuration

		both above can be done and still have the data itself in the package

--save config saves the config in the output directory
	the config is the parent node package config (a cow version of it), change option names to reflect it
		save_parent_config, save_start_config?
		we can also save the config just before we start running rules ( which can only modify node configs not package config)
			this allows us to diff the configs and see what has been changed
				this is also supported as a log already

	list use cases
		subset build
		pre-emptive warp generation
		debugging 

	how is pbs_config{LOADED_CONFIG} used? loaded in PBS::FrontEnd
	can load and save config be used simultaneously ? make a backup of the old version

	the target is also saved in the parent/start config, warn if it is used for a different target (which is OK for debugging)

	document how the parent's config loading works and what effect it has

	sort the saved configs so they are easily readable

	load_parent_config runs should generate output in a different output directory but use the normal output directory as a binary repo

	starting a subpbs build with saved config and the original build as a binary repo is error prone
		a wizard creates a command if it finds a saved config

build directory per config-target
	rather than put everything in the same output directory create specific directories per config-target

	we need a way to garbage collect

	we need a way to follow logs for a specific pbs run
		can we create a directory per config-target and link to sub trees output directories? 
		this allows sharing output directories
	

FrontEnd
	line 70 config is overridden without warning
	all actions taken only for level 0 should be moved in a specific subs or a package

depend log
	rules triggering are displayed aligned the same way even if the node triggering is at a lower level

		all ... a, b
		b ... x
		a ... y

	
		should be
		all ... a, b
			b ... x
			a ... y


	this has the disadvantaged to use more screen

	dependencies should have a graph, as tt, to make it easier to follow log


configuration
	query an undefined variable is an error is option is used

	display which variable have not been used,and where they were used

	

pbs switches are sorted in categories
	a help switch per category is available

pbsfile_use_statistics
	option is implemented as a REH on the package node
	is displayed before ** depend ** phase not at end of run, even though that's were we want it
		best would be to let the log visualized decide
		

log visualizer/greper
	a set of scripts that extract data from logs

		eg: -- display_pbsuse_statistics

		that's a data we are interested in specific cases only but it should be possible to get that information for previous builds too

	all data that's not in the warp file should be in another set of files ( so we can access them but not bloat he warp file that needs to load fast)

confusing -bi and -bni options
	-bi help needs fixing, refers to not existing options
	obscure option to control what is displayed or not ( ie: options names are bad)




caching rules
	rules are not cached because the pbsfiles that they are defined in may have code in them that makes the rules work differently in different context
		this is safe but paranoid and slow
		
		even pbsfiles that only contain rule may have dependers that work differently depending on context and configuration ( probably what we want)

	let the user decide if a rule is available, by name, for all sub nodes, and only sub nodes
		this makes sense as we already give the top nodes control over configuration inheritance

		this should be displayed clearly in the nodes' logs
			what rules are taken from cache
			where the cache rules where defined
			how many of the rules in a pbs run are from the cache
			if a rule is marked as forced

		sub nodes should be able to reject parent nodes rules
			warning are displayed

	is it possible to find out if a rule definition should be re-loaded from the context?
		probably not


	implementation
		Rule checks the current rule definition to see if it is
			marked as "forced" aka ignore cached version
			marked as "non-exportable"
			marked as "local"

			finding out if a rule matches a set of node and selectively using them or loading new rules is difficult ( but possible)
				that could be done by a test at rule loading time

			if it exists in the cache or if it needs to be loaded 
	
			cached rules are aliased within the pbs run package
				it makes it easier to access them, alternatively the code running the rules can check but that's bloated

			a loaded rule has an origin attribute added, the parent's or the local pbsrun

			parent package can limit the rules children can use from the cache, using "local"

Create warp tree via rules

	MW is a dependency graph for a node
		it corresponds to the run of a depender in a different package/pbsfile

		there's no reason that MW is run dor a depender in a different package except we decided so, this means that MW could also be create
		during a normal node dependency ( although it may be more efficient to generate all the wanted MW from the final dependency graph )
			this gives us the possibility to decide the granularity of the MW, eg: we want a MW for each C library

		since MW is a dependency graph, it's generated by a depender ( as a side effect of a pbs run), it's loading is done at pbs start time
			pbs start time loads all the MW to create a warp tree which is used to verify node changes and minimize the parts of the graph
			that need to be rebuild.

			MW could load themselves and give a sub graph + node list back, this makes it possible to have MW generated in different formats
		it corresponds to the run of a depender in a different package/pbsfile

		there's no reason that MW is run dor a depender in a different package except we decided so, this means that MW could also be create
		during a normal node dependency ( although it may be more efficient to generate all the wanted MW from the final dependency graph )
			this gives us the possibility to decide the granularity of the MW, eg: we want a MW for each C library

		since MW is a dependency graph, it's generated by a depender ( as a side effect of a pbs run), it's loading is done at pbs start time
			pbs start time loads all the MW to create a warp tree which is used to verify node changes and minimize the parts of the graph
			that need to be rebuild.

			MW could load themselves and give a sub graph + node list back, this makes it possible to have MW generated in different formats

			if MW can load themselves they can also check themselves, this allows parallelization of the warp tree build

			MW contain references to other MW and whould load them rather than having a  pbs global loading mechanism
				a pbs controlled loading mechanism is good for debugging but we could have log output API that needs to be followed by MW

			as soon as a branch of the warp tree has been re-created ( it'as nodes as checked already) it can be rebuild if necessary

			

		since MW is a "depender" it can be a REH
			this means that warp can be written using rules!
			
			MW_REH load the MW, check the node, create a trigger list ( it would be nice to be able to run a pbsfile with such rule, for debugging, outside a normal pbs run)
					
				if sub MW are found during the MW load, they can be run in parallel

			or maybe it's the pbsfile_REH that should load the warp file?
				pbsfile_REH  "links/merges" config+target trees, by using warp, and eventually using normal rule running

		problems:
			we need to control how many processes are being run simulteanously

			when the same node is referred to from different branches of the warp tree, we don't want to compute their hash multiple times
				we want a centralized digest cache, for this specific build
					this is exactly what the watch_server is! except it also watches nodes and can handle multiple builds
				
				since the watch server gets modification signals it knows if a file has been changed during a build

				use a watch server for hash sharing for every pbs build

	implementation ideas
		don't re-create nodes that are not needed in the build

*line new c depender inserts nodes in the graph after the build to create a complete warp file
	the c_depender injected nodes should be in their own micro warp files

	if the dependencies are needed during current the pbs run a mechanism to reload the micro warp at run time is available
		when accessing node dependencies, reload them if flagged as not loaded
			this allows us to mark the c files dependencies as not loaded if it has changed or if they don't exist



create set of scripts that run queries
	scripts take a log to work on or use the latest build

	output is in the terminal

	output is structured and can be filtered to produce different formats

	example of output
		nodes in the graph
		nodes triggering
		nodes rebuild
		rules run
		...

options 
	should not interact with each other
		if option a and b can be used separately and together but give a result that's different from
			using a and b, then a third 

	if option a has sub option a1, setting option a1 automatically set a

Add comments directly in the node and make the comment part of the build output log

	AddRule
	  ...
	  ...
	  comment "somec comment" ; # node sub?

	we already made the rules a bit more comprehensible by giving them names, comments can help further

	we have a link in the log to the rule and it's definition line
		we could extract the rule and inline it, that would also make navigation unnecessary
		we also have the textual representation of the rule in the rules that could be displayed instead 

	possible syntaxes

		3
		Rule [V], 'release', 'the release of release releases a release that would release a releaser released',
		['release' => glob '{'. Config('OEMS') .'}/{'. Config('LIBRARIES') .'}/encrypted.mol' ],
		BuildOk();

		8
		Rule [V], 'release',
		'
		the release of release releases a release
		that would release a releaser
		released
		',
		['release' => glob '{'. Config('OEMS') .'}/{'. Config('LIBRARIES') .'}/encrypted.mol' ],
		BuildOk();

		6
		Rule [V], 'release',
		['release' => glob '{'. Config('OEMS') .'}/{'. Config('LIBRARIES') .'}/encrypted.mol' ],
		BuildOk(),
		Comment(" the release of release releases a release
		that would release a releaser
		released") ;

		9
		Rule [V],
		[
		'release',
		" the release of release releases a release
		that would release a releaser
		released"
		],
		['release' => glob '{'. Config('OEMS') .'}/{'. Config('LIBRARIES') .'}/encrypted.mol' ],
		BuildOk() ;


! web server
	use signal and request queue (file plus index)
	output text (html, json)

	client uses ssh to send signal and send back answer
		use timeout
		returned data can be "massaged", eg: png file, or raw and the requester renders it


	box 1: ssh box2 -c get_something --pid 123 request > answer

		get_something
			echo @args > uuid_request_file_time
			kill -user2 -p 123
			timeout inotify -exists uuid_answer
			cat uuid_answer || echo "request failed"
			rm uuid_answer

		p123
			get signal ->
				read queue of requests
					process log
					print uuid_answer file
				while requests

	? why would we ever want to do a query on a running build system
		if the build system is distributed, each build system has it's own data and display
		we _may_ want to know if one of the build system is running

	start_build
		start:
			b1 (local machine)
			b2 (remote), give me log data -> display
			...
			bn

	=> processing of data is best done on requesting box
	=> the build log is structured, the main log points to sub logs
		the build log contains the graphs meta data
		the build log is kept small to be synched to other nodes
			data necessary are loaded on demand



Meso warp dangling subpbs and nodes
	within a pbs run, nodes are:
		immediately depended
		depended in a subpbs
		not depended
			may be depended later or not

	the pbs checks for the presence and validity of subpbs run mesos, if none is found it
	synchronizes with other pbs runs to insure only one process is creating a node/pbs run

		if no meso exists and a process gets a lock to create it, the subpbs is build

	the synchronizing mechanism is via flock or a or a service which should also use flock to make it easy to
	find the lock files on the locking server.


Timing framework
	pbs1 has  a breakpoint framework, it has practical advantages but the code is spread all over pbs1

	the urge to time things is strong when building software
		
	maybe the urge is synthetic and social rather than correspond to a real need, this is the case
	for the need to see "progress"

	during debugging and optimization, timing is important

	what do we want to time?
		build time per node
		build time per group of nodes, eg: a lib, a sub project
		build time per type of nodes, eg: object files
		build time of some time - specific nodes, boolean operation
		specific operation, eg: checkout of files
		REH time
		rule time across multiple subpbses
		a pbs phase, depend, check, ...
		shell commands for a node, for all nodes, compared to sub time
		time spend in a modeule, pbsfile, ...
		
	
	implement the timing framework as a REH
		no run time impact if not used

		do we want the timing data in the output stream, just writing current time has little impact 
			since the output filters do the work of comparing timing and displaying data (if the user wants to)

			we could also generate timing artefacts which are practical when debugging, no need to extract the information from the log
				we can have an REH for log and on for timing artefact
					REH are injected via options on the command line

	timing framework needs to handle parallel processing
		if we use the output log as a framework the problem is moved to the output log

build timeout to change control behavior
	build system users do not trust the build system
		build tool is too complicated to be sure it does what it should
		build system is too complex
		...

	the control behavior is satisfied by bombarding the user with useless output in the hope that she may catch
	something a continuously displayed build log

		although this soothes the user it seldom is of any use, when error occurs the output is used
		as a log, that its real value.

		perusing the log is made difficult by unstructured logs, long logs, incomplete logs

		the lack of tools that make it possible to extract information from a structured logs makes it even more
		difficult.

		the log should be made of pbjects that can be queried and acted upon

			eg: extract node and show me information

			eg: which node have a config set to a specicif value

			eg: on whic machines is a node build and what other nodes have been build on that node

	pbs2 default is to be quiet, very quiet
		the problem is that it makes people nervous till they trust the build system (IE tests are run)
		
		not knowing what's going on is acceptable only if one knows the build system is not going to hang

		of course the user can get a full display and she can create filters so only "interesting" portions of the
		data is displayed most of the time the "interesting" portions are not interesting at all!

	letting the user, optionally, define a "silence" timeout value may ease the apprehension

		die, with trace if the build is not done within a certain amount of time
			the timeout can be an external control process but the trace must be generated by pbs
			the trace could be generated from the output stream (log) which makes it possible to have the
			timeout be handled by external processes completely

		start using a filter after specific amount of time

		start showing progress after specific amount of time
			percentage
			job info
			...
output stream format
	a format that can be greped ( section of log, xml, yaml, json)
	a format that can be loaded in memory
		preferably in section (like meso)
	a format that cn be transformed to other format
		eg: from perl to yaml or any other format

Default REH
	a string is a default REH (and unlike other REH it doesn't have an argument)

	this let's us have the string as a shell builder REH and makes the rules much less "dense"

		Rule 'name' is type => V is something_else, 
			depender => ...
			dependencies => ...
			whatnot => ...

			"touch %FILE_TO_BUILD" ;


	multi line string is a shell script

	operator 'is' is sugar to call REHs
		this may force us to push REH is classes

example REH
	
	REH_BUILDER => file_name.pl ( or other language)
		uses code in file_name to build node

	REH_MATCHED
		run as last rule, and matches only for the nodes that matches
		run as a normal rule after at least one rule matched a node

		use case: ?

	REH_BUILD_AFTER after_what, code
		only runs after another builder

	REH_BUILD_SCHEDULER
		decides which builders are run when

	REH_BUILD_RESULT
		runs after build is done and can set result to success or not


depending on an external build system
	use case #1 source code may change
	use case #2 source code tar ball may change
	use case #3 version of tar may change
	use case #4 library is never changed and always present


	The usual way is to have a dependency on a symbolic name (phony, virtual, ... note: that pbs also has triggers)
		disadvantages:

		- no clear configuration management
			main build needs to make sure the right version is installed not rely on the fact it is
		- build system is run even if the system is up to date, ie: no caching
		- no clear dependency
			sub build is done something installed at unknown location
			dependency is in the form of a non checked library
			library is named in a config but is not a node
			linker does the magic

	case 4
		copy the library in the main build and tag it as source

	case 3 and 2
		add dependency on the needed library

			Rule dependent -> library
			Rule library -> library_version.tar # where version is in the main build
			Rule library_version.tar -> [], curl the lib

	case 1
		to be able to cache the build (only interesting when we have a global binary cache or incremental builds) we need
			a dependency list which is generate by the sub build
				this is a bit like object file caches generated during compilation
				it can be achieved by taking a snapshot of the build tree in the file system


	This caching scheme advantages are only interesting (for build time) if checking the cache takes less time than running the library build
		there are other advantages but those may only be interesting when debugging or analyzing a build (and can be optional)


pbsfile chain
	is used to invalidate a sub graph
		if a pbsfile changes the dependency graph under it may change, because of nodes added/removed or configuration change
		
	the pbsfile chain should be a dependency of every node

	the pbsfile chain is implemented as an internal list while it should be implemented as a node list that's in the dependency graph
		it doesnt have to be implemented differently (except it's a reverse dependency, node at a sub level depend on pbsfiles
		at higher levels)

	the dependency on a higher level pbsfile should be added via a rule injected in the pbs run

	only the graph under a pbsfile level is invalidated, upper levels aren't


	Note: even if a parent level pbsfile invalidates the graph at lower levels, the cost is not a complete graph reconstructions as
		when the lower level pbsfile is run, and it hasn't changed, it will be gatherer from meso warp quickly, the pbsfile is not
		loaded

	* pbsfile chain is STILL needed to remove sub graphs from warp

		target : A
		A: B
		B: C
		C: D

		B pbsfile is changed, B is removed from the graph, may be quickly regenerate by meso
		C and D must be removed from the graph, may be quickly regenerate by meso


		meso files are valid independent of any graph

		if a node dependency (its pbsfile in this case) has changed, the node is not present in the warp graph and thus it's pbsfile is reloaded
		all the nodes added by that pbsfile are not in the warp graph and created during the pbs run
		lower levels node either exist in a meso (same config, same target, same pbsfile) and is merged or a new meso is created

		=> the pbsfile chain that points to levels under B's level is used to remove all sub graphs, there may be another way using dependencies
			it would be nicer to have a distributed "pbsfile chain lower levels" than the current implementation

			if the pbsfile for B has changed, all nodes from that pbsfile are invalid and removed, we must also remove the nodes dependencies
				that's what the current pbsfile chain does, by invalidating the pbsfile sub pbsfiles

				the pbsfile chain is a warp structure, it doesn't exist in the dependency graph, it's created by adding the pbsfile of every
				node in the dependency graph, IE this done as many times as there are nodes

				this would be more efficient if there were pbsfile dependency graphs, we'd be able to do the same thing but once for every
				pbsfile rather than every node

				the dependency to the sub node pbsfile should be added by subpbs rules


				B : C(sub pbsfile) 

				also means

				current pbsfile : sub pbsfile ( what about "virtual pbsfiles" ( we want to avoid anyway)


				current pbsfile (pbs run for the pbsfile) also has a builder
				current pbsfile is also a dependency to all the pbs run nodes
					B: C

					also means

					B: current pbsfile

					we used to squirrel it in the digest but we now put it in the graph

	* pbsfile chain is STILL needed to trigger dependents

		target : A XXX
		A: B
		B: C
		C: D

		B pbsfile is changed, B is removed from the graph, A needs to be rebuild because its dependency has changed, the only way to rebuild
		a node is to have its builder, the builder is in A's pbsfile, A needs to be removed so it's pbsfile is loaded

		XXX is still valid

		=> pbsfile chain is not needed, A is removed and the build need to restart from the top, which load the top pbsfile. pbs will load
			the pbsfile for all the nodes that have been removed without the help of the pbsfile chain

non file dependencies in the node digest
	pbsfiles were added as a package dependency
	pbs libs are added via package dependencies
	configs are added with user defined code
	ENV
	...

	we need a better way

		pbsfile and libs can be added to the dependency tree
			we need to add options to filter them out/in the graphs display

		configs need to get into the dependency graph
			since the config is a node it will get a digest, the digest contains the build time values

			the config has the pbsfile as a dependency

			the config is either a dependency to all nodes or a dependency to a pbs_run node which is a dependency to all nodes
			
			the config is directly in the package

			how do we check if config has changed?
				the pbsfile has changes
				at parent config has changed, that means it's pbsfile has changed and thus it will remove all sub graphs

		node specific configs need to get into the digest too

		ENV is simple since we force the user to tell us which ENV is used
			not all ENV are used for all nodes, we need to control it at the node/package level, not only top level

digest generation and computation
	digest is a REH that's added to all nodes
		this allows new digest mechanisms to be added without changing the core pbs
	
	nodes can override the digest REH, creation and verification

	stats data for generation/verification are possible
		a config option that the REH checks and generates data ( possibly serialize it)

AddFileDependency
	used to add a dependency to all the nodes in the current package

	better use: rule '*: file

post_pbs and post build commands
	should be rules
		we should be able to inject those rules from the command line

	post_pbs is limited, we want to run a script after specific nodes, packages, or the whole build

	
rule injection during debug
	with history pointer?

	we have a mechanism to inject rules when packages are loaded, on top of a current graph, during debug we could use that mechanism to 
	add logging or rules

	we have a graph we can go back into, using the log, so we can back to the point where a node is inserted, back before its pbsfile is loaded
		add rules (including extra logging) to be injected, load the pbsfile and step through it

		note that this is anoter build "branch", once we back in the log and change something, we have a new build

		having the original build in a history viewer and the new build ( because of rule injection ) allows us to diff them
			we need nodes to be inserted in the same order to be able to diff efficiently

			--reproducible_build forces pbs to run serially with nodes in a specific order



	

Controlling ENV at the node level
	? 

parallel depend
	if we run depend (on nodes) in parallel, what can we do with the generated sub graphs?
		merge back to the main process

		keep them in the depending process
			if we reuse the same process to build, the node is already there and we don't need to fork builders
	
		write each node data to disk and only merge back the file name to the main process
			we can keep the node in memory and use the same process to build it (as above)

		=> depending process is more efficiently run per pbs run not per node
			we already have a package for all the nodes in it in memory (note: also true when per node)

			serializing a pbsfile run is a meso warp, simpler to do it in a single process than collecting
			the individual nodes and putting them back together in a meso warp

			the meso warp name computation is constant so we can return the meso warp name to the main process
				we can also send other information but the information is in the meso file, that would be for efficiency only
					an example of information is "dangling" targets, see below

		=> depending a pbs run does not depend subpbses!
			it stops at the pbs run limits
				linked nodes and subpbs targets remain "dangling"

			the main process gathers the meso information and "links them together"
				there may not be the need to load the meso files, having the graph truly distributed
					if showing the graph is necessary we can merge recreate the $inserted_nodes in the main process
						cooler would be that each process can create its sub graph and the graph concatenated
		
		=> depending processes (we could name it a meso process) can
			check nodes disk image validity (hash), making the checking parallel
				this doesn't check the linked dependencies or dependencies from subpbs runs
				that is done after "dangling" meso is "linked"

				still most nodes will be checked immediately, in parallel, while other parts of the graph are depended

				=> if a node doesn't have a "dangling dependency" (a dependency that can't be checked yet), and it's
					disk image is changed, it can be immediately build

		linked nodes
			can be in the same pbs run
				just link to them directly, like in pbs1

			can be in different pbs runs
				ie: node is created but not depended

				this is close to the late dependencies mechanism in pbs1
					in pbs 1, a node that was not depended was used later by the pbs run who has the rules to depend it

					in pbs2, the node is created in multiple places and one of them, possibly more, will be depended
						the "linker" points the dangling nodes to the depended node, if multiple non equivalent node
						are found, an error is generated

		trigger nodes ?

		=> meso warp doesn't have a pbsfile chain
			each pbsrun only depends on it's start config

			which means a pbsfile cahange up the chain doesn't invalidate a meso file
				the meso file may be invalid for the build where the pbsfile has changed but
					it may still be valid and we don't need to run anything to check that just compare start config
					and check the meso hashes (including dangling nodes)

					if it is not valid, because of a configuration change, we can still keep the old meso files and 
						create a new one for the new config

						we need to name the meso files based on the start config
		
	biggest problem with parallel depend on different machines is that we want to avoid depending the same thing twice and veryfy that those
		common dependencies are configured in the same way whatever branch of the dependency graph adds them.

	how do we visualize a parallel depend?

	how do we debug a parallel depend? how do we force the depend, and a specific state on the depend nodes?
		reproducibility!

 
parallel depend, check, build, ...
	how is the output stream put back together if multiple processes generate it?

	how is log handled?
		although log is supposed to be integrated in the output stream

	during build how does a separate process wait for its dependencies to be build
		does each process build a sub tree or nodes

	how are files put back in a single file system (if needed, see LOCAL in pbs1)

running all the rules for all the nodes
	without scoping we get a hit rate below 30%, sometimes much less
		each call is aot a rule that needs to be constructed (once) and called via a sub ref

	if scoping the rules is unpractical, is it possible to filter out rules that we know will not match?
		the cost of finding which rules matches is probably less than call 70% of the dependers for nothing
		rules that never match should not be compiled
	
display 
	display used/unused rules
		per pbs run
			display rule statistics
			display rules not run only

		global statistics
			filter output?

	use configuration variables


missing data in warp
	
	environment variables
	nodes starting a subpbs
	all data that's package specific
		no digest
		no dependencies
		...

	package data should become node data, where a subpbs node can also have the old "package" data

	we can also serialize the missing package data, they are very small and simple to serialize;

new warp data format
	meso, let's us load smaller package/pbs-run in parallel as if we were running multiple pbs
		can we distribute the graph to multiple processes?

	some node trigger the whole meso warp so we can stop loading/re-vivifying after those nodes

	load warp and check the nodes with minimal data while loading full data in another process
		we get the speed of warp and all the data
		
		since we have two caches, we can minimize the first one for load and check speeed and keep the other
		cache data as it was in pbs so there is no use to re-vivify nodes, just load them in memory

		with meso we can also load only part of the full node data rather than whole graph
		

	can we start depending as soon as we have a node that is triggered?

-hint
	hint the user of whatever they could do
		this is going to require some thinking

if only terminal nodes are checked the warp file can be split in terminal and non terminal nodes for quicker loading and checking

--quiet is the default
	return nothing but an exit code except when the user asks for it

output stream
	pbs can't generate all the trees for every build as those are time consuming specially if many nodes are in the graph
	the user may not want to see them anyway

	the output filters could generate the graphs if they have the nodes and the filters used by pbs
		add the nodes to the output or a link to their data in a warp/meso files
		add the filters to the output, since the same filters are used, have just one instance

	if we add the nodes to the output stream we are creating a huge cache
		incremental builds should refer to previous caches
			can we merge the output streams?

output filters mean that the data stream needs to be on stdout
	does it? doesn't even have to be in a stream?
	should we write to a socket? file?

	what about applications wrapping pbs? web applications? remote debugging?


make it possible for wrapper application to show its own message
	write everything to stderr in log format and let the wrapper andle it
	no exit


node@root
	rather than retiring it ...

	build a graph from root
	save it
	run multiple node build without re generating the graph from root

	we need use cases for this

	one use case is to build node in different ways by changing the config
	
	another is to make the build faster by just building a node and not the whole graph
		we planned to relpace that with meso warp (which is build as a sub graph of root)
		we can run a local build (we should also generate command line to build just that node) and use the meso warp as warp
			meso warp must be recomputed if it is changed during the local builds

		is it that much faster? if we want to build just that node it means that it has failed and running in warp will just 
		rebuild it till it builds

	=> node@root is extremely useful in one case, when creating the build system we want to ignore nodes that already have a 
		build system. node@root creates a complete graph and ignores everything but node@root

		warp speeds up the creation of a new graph except when the pbsfiles are changed as they invalidate the graph
			meso is the solution to reuse partial graphs

		what we want it to only build the graph portion that leads to the node@root
			if node at root doesn't link to other graph branches we could sort out the nodes we don't need to generate a graph for

			eg:
				all -> b, c
				b -> b/b1
				b1-> b/b1/b10
				c -> c/c1


				building c/c1@all doesn't need to creat b's sub graph

			note that if node at root depends on a node in a different sub graph, we can have that node@root too and pbs
			will build the two subgraph

		but doesn't meso give us an even better mechanism as it has the complete graph and still is fast?
ENV
	given variables are known (can be all variables if the user wants)
	we can remember them and rebuild everything if any changes (since we don't know how they are accesses)
		we could strace all sub processes (bleh!)

	this would work with warp too
	
	subpbs can restrict the environment variables
		this would let us trigger less nodes

		where do we limit the used environment variable (and how in the subpbs definition)

			in the parent pbs but it makes little sense to put the knowledge there

			in the subpbs definition
				the problem is that we can't control that's it's done at the very start of the pbsfile
				
				suppbs file:

				qx'a command that used ENV variables'
				...
				limit_env(...)

				rest of pbsfile ...


				Make it the user's problem, pbs can't do magic
					pbs has control over the loading of the pbsfile and limit_env()
					it can check if limit_env is called early in the pbsfile and warn

		in perl sub the ACCESS to ENV should be logged too
			with the complication that a perlsub can run other processes we have no control over

			shell command are simpler because we  run the external commands for the user, in perl subs
			the user has full control!

--STRACE and REH_STRACE
	run all build command in a wrapper that generates extra information

	strace is just an example, the user can change the wrapper

	the output should be in a node_log_strace

	REH_STRACE_ENV is a specialized REH that logs the ENV access
		post build it checks the log with the allowed ENV variable


	we already do some type of wrapping via plugins in pbs1, we EvaluateShellCommand and let the user
		add %something_custom, if they want to. this wrapper is slightly different as it is applied
		by node via a REH when running an external command.

build node in separate process
	pbs1 calls the perl system function which either starts a shell or runs the process directly
		we still need that

	create a wrapper process that can be run
		it can be a simple bash wrapper as long as it can be called separately from the build system

		this allows us to do build elements separately which is very useful during debug

		this also allows us to
			run the build in a different shell
				with tmux we can start a session for the current build and
				run failed builds in it allowing the user to get in a setup environment

			run on a remote	machine if the environment is the same, IE Kubernetes
				this can still be a in different shell for each build like above

		if run on a remote machine, the wrapper can use whatever protocol it wants, for pbs it's just
			a local process

			we can, prior to a build, generate all the wrappers then pick some of them for remote build
				pbs doesn't even have to be aware

				the wrapper can generate output data that get in the general log 
					it can also generate output from what it gets in the remote build
		 	
output filters should use a templating system
	preferably one that's already written
	one that can refer to other templates recursively

write logs in yaml with color tags so cat would display them
	if yaml doesn't accept the tags, filter them out when necessary

catch external command std and std out
	pbs1 Shell::Command redirects stdout to stdin!

text graph
	generate sub tree graphs
		menas that we can't have references to parents or we get the whole tree 

	generate a "surrounding" graph

	graphs should be build from parts that can be cached, eg: not build from scratch

	interactive text graph mode?
		isn't the node log a super interactive graph?
			yes but we don't have the tools to show a graph, ranger hides the tree, and broot is worse
  
	a third party application would be even nicer



warp file
	we re-use the same warp file although we override it completely with new content
		but we generate a triggering log each time

	the warp size is 1 MB but trigger list is just a few Kb

	maybe we should have a new warp file and triggering info would be inside it

	this lets us compare build
	
	warp contains only the information to find which nodes need to be rebuild
		a secondary files containing node data is loaded on demand from serialized nodes
			we want to load them in chunks for better io
			we could keep them in memory for some time to load them even faster
				keep in text/compressed format so external tools can also access it

warp patching
	most often the pbsfiles do not change and the graph stays the same
		in some cases the same pbsfile can give a different graph, IE: an include file includes more files

		it would be nice to be able to verify some hash of the graph to verify it's the same
			the hash can be computed while the nodes are being built
				that exactely what a patricia tree is
					and we already have the hashes of the non regenerated nodes
					

			alternatively, we can remember the nodes we removed and compare (on the fly) to the nodes we add
				although some dependencies are added after the build (IE: c dependencies)

		in that case the only change that can happen is that some nodes change md5 (IE: source file changes during development)

		the old warp file is still valid, the only thing needing change is the md5 for the node in the warp file
			that can either be done directly in the file or via a patch

	
warp re-vivification
	is done at every run
	mostly so %inserted_nodes has nodes that are __DEPENDED so we only rebuild part of the graph
	
	serialize a re-vivified %inserted_nodes directly rather than rebuilding it


preemptive duplication
	move a copy of the build to other nodes in case we need 

	ยง in CI system where any build node can done on different build nodes, checking out code on
		all the nodes for each project (during down time) saves time at build time

		keeping the build directory separate is advantageous or having a "clean" target

	dockerization of build
		note that everything below can be done with a fs that uses a file as back-end
		and that building in an overlay keeps that file pristine 

		for OSes without FS layering a compressed file can be used
			it may even be a better solution than FS and docker as it removes dependencies
			but the compressed file has to be generated, that's automatic using FS

			another advantage is that duplication takes less disk

			compression can be optimized for space or speed

		for each build there's a CM configuration which includes repos checked out
			in release builds the repos are checked out again but since it's the same repos 
			we do the exact same work again or the same work plus getting the latest commits
			
			if builds are done in docker, base checkouts can be used and we let the CVS checkout the 
			new commits

				a hash for the current repos heads(including branches) is generated
				a snapshot, corresponding to the hash, is saved
				next build can compute a hash list for its current CM configuration and request it from docker
					since the build is probably for a new configuration that will fail 
						we can optimize this away since the vast majority of builds are new builds

					the build computes hashes backwards and requests docket till it gets a fs layer
						computation can be cached, previous builds update it

		the FS layer can be for the complete CM configuration but that's of low granularity
			it works fine for a build but a FS layer needs to be created for each build

			if the CM layer is per repo/branch (a checkout) we can create the build

		old FS layers can be deleted when new ones appear
			
		when two build are concurrent they will both create a FS layer, synching the build so only one is done
		is an optimization but it needs a global CI check difficult to implements in a generic fashion
			don't use the CI system to know what jobs are running, use an external DB


pbs in warp mode aka how to do nothing but build

	if pbsfiles are unchanged, and the graph is the same (if no new dependencies are added/removed)
		the rules applied are the same, we don't need to run them since we already have the dependencies
		the only thing needed is run the builder
			it's often the same command (or the pbsfile would change)
				external dependencies (the compiler, it's dependencies) need to be cheked

	rules can be transformed in an external program/module
		dependers and builders in separate programs since they are used at different time

		it can be run on external files
		it can be used as a rule cache
			if the rule hash is unchanged we just reuse the external program
			nodes can remember what program/rules where run on them

memory usage
	access to nodes in pbs code could use the same mechanism with a maximum amount of nodes
		in memory at the same time

	this becomes even more important if we merge builds or intersect builds

	acting on files, one at the time, drastically reduces the amount of memory needed
		it also allows external processes to act on selected nodes only

	we need to know what uses memory
		the graph is itself distributed in the node, it's not an abject in itself but all the nodes need
		to be in memory for the graph to be in memory. we can load only the nodes we need or even just query the information we need
		eg: we need the dependency names

	
debugger
	pbs1 needs breakpoint, pbs2 starts at the insertion of root if no files are given
	
	add possibility to add/modify breakpoints during the run

	implement gdb interface!
	what about the per debugger?
		isn't it implementing gdb already, 
		can we run pbs in ddd?

	where do debug output go?
		in the log? it's mostly noise, better reference from the debug log to events in the main log

output filters
	can we implement a query engine on the log? Yes!

	interactive log viewer? what's the difference with the node logs?

	generate data for the user
		each node can be given a different color
			(little like -node boxing in pbs1)

		errors are displayed so they can't be mixed

		debugging/query filters can be run as output filter or part in an output filter
			eg: highlight some specific nodes
			eg: display specific information for specific nodes
			eg: filter out nodes or sub graphs

		filters can rearrange the order the nodes appear in

		filters can extract part of the data to a sub directory


	filters should be able to do what post-pbs could do
		so we must have a graph to re-load

	the output data could be the serialized graph!
		timing information give the order pbs ran the phases
			we can put the timing info with links to nodes in a section to speed up the filtering
		depend. check, ... is kept in the graph

		the serialized graph should be in parts so there is no need to load everything

		if the node digest are build as mini graphs we could just refer to them

	? is the data generated like a stream which is later split and located in the nodes sub directory
		or do we generate directly in the sub directory

		=> there are advantages in having all linearly generated
			less work (although putting stuff in a different file is not that time consuming)
			no need to do it if not needed
			all the data is in one place
			not a zillion files
			much simpler core code which doesn't care for display switches

		=> disadvantage, everything is in one place, post processing is needed
			

	? what size of data is acceptable, we can't have a mega data structure serialized

	warp is nothing more than a filter! should it be a post process?
		we need to reload the log in memory
			except if it's a rule and then it has access to it in memory

			
	? why do we generate data that we may not use, post filtering or not
		let's keep as little as possible in memory!
		data can be re-generated when needed, eg: a node fails, recompute all its parents

		if we keeps the pbsfiles in the graph, we can re-gennerate even if those files are modified in the file system
			can we use git and an in-memory repo that we serialize?

		=> we can leave it to rules to decide if something is serialized or not
			start with serialization then create new rules for more efficient storage

	output filter don't have to be monolitic, they can be an API which acts on the log or part of the nodes
		top level filter call the apis, eg: render_node can be reused in many filters

	cache rendering
		this allows use reuse previously done work
		eg: show some node, max_depth 3; show other node, ... we don't recompute the common nodes since they are immutable

	use tree like output as much as possible
		we need a mechanism to
			insert already rendered data without re computing everything
			extract parts of the already rendered tree, eg: not everything but some fields, or to a specific depth

node data
	node data is transient in pbs, it may interest the user but for pbs once a step is done its data is of no more interest
		once depended all the depend info is not used anymore (except when failing but we can regenerate the node info then)
		once checked the check/trigger/.. data is of no interest
		we could keep the nodes with just their builders, a list of sub refs or shell commands

	=> this stinks "make"

output filters
	they generate the output  _and_ the node logs (or whatever they want

	node logs can be
		move the data to the right directory
		transforming it for display can be done later (or not at all

		even moving the data to the right directory doesn't need to be done before it's needed
			also saving time

		the user can say what needs to be run during and aftert the pbs run

		when an error occurs the log files must be generated (do they?)
			for the failed node, its dependencies and dependent


	output filters are called BY REH!yeah at different times
		some default rules (to be included) but the user can define his own rules on the nodes or pbs phases
		
	since pbs will output the graph, the generation can be done at any time

	a smart output filter can use a vfs to generate nodes on demand!

	log should be immutable

mechanism to find where installed files come from
	if files match a rule they are nodes

	but if files are not-build/source dependencies they 
		don't match anything
	 	don't have a log
		only appear in their dependent's log

		--nodes list them, except for h files since they are not part of the graph till after build
			dependencies are not displayed if the have been checked
				not good but logical since we piggy backed --files on check and check doesn't
				sub graphs if it doesn't need to

--files
	rename to -nodes
	do not display the output path again and again
		just display it once

	do not display the sub path if its the same as the pbs path
		ie: display those that are full path or from another repository

	do not piggyback on check, many nodes are not displayed

query to find about files/nodes
	display name of log for files when --files is used


flashcards+cheatcheat+fzf

plugin mechanism that can get files from github or other source
	eg: pbsplug "nkh\pbs-Cdepender3"


pbs repository directory
	we can reuse the output from a previous compilation
		we need to make sure the files are not modified in the repo directory while we build
			make the repo dir read only
			copy the file 
			keep a hash and re verify it at build time
			
			binary repo, not directory ... repo, fixed  these problems
				but it's a repo of read only file which means that they are copied there
					well we could build them directly in the repo under the hash name and 
					link from the build directory to the repo directly.
				
				owner of the file is the repo

			binary rpo also fix the problem of multiple repositories with the same file in pbs1 the search
			stopped at the first file

wizards
	pbs init (omake)
		create pbsfile and pbs.prf

		we already had wizard!
			pbs -w init

	wizards don't need to be in the wizard directory

	why is pbs involved in the wizards if pbs doesn't provide any data to them?!


Do we need to have TARGET_PATH set?
	problem #1, TARGET_PATH is taken from the first target
		works OKish as all subpbs have just one target
		but would break if TARGET_PATH was used at top level

	dependencies which are relative to the target are simply declared in a rule, pbs handles TARGET_PATH
		and if necessary perl regexes allow the use of $path which is the dependent path
			BUT TARGET_PATH is only the targets path, not it's dependencies paths

			TARGE_PATH is alittle bit like . (the root of the build graph) except it's the root of the target

		 
	check how make uses it

merge ideas from Todo
	md5 stats doesn't work as checks are in sub processes 
		merge stats
		=> should let the rendering plugins do the merging
			simplest for visualization but not for queries where one wants data to be together
				queries either merge themselves or we make a function available that does that
		
	warp generation can start as soon a subpbs ends
		meso warp
		generation of warp can be optimized
			do no compute dependents if other nodes have already computed it
			when checking we create a children to parent link (to start parent build) it's the same thing as 
			creating a dependent list

			warp contains less, filename and md5 list (to check externally)
			a pointer to a dependent list which can be share among nodes, but nodes point at different places
				we'll need multiple lists but the reuse is high with shared lists
				some nodes may point at multiple lists (parents)

			data serialized in warp file should not be serialized at all
				just have the node name and let the data be in an external file, alt a meso warp

			better yet, warp nodes should not be used at all and thus no re-vivification is needed
				graphs? queries?
				
		utility to regenerate a graph, for query, from a warp file (the dependency arrays)


	logging
		we log which node have triggered in the _warp directory
		log which files have been removed from the graph
		log which files are build

		all this could be extracted from full log instead for being generated by pbs

	node log dependencies (dependencies named in the node's log)
		are listed without link to file
		triggered nodes have the needed information

			   Dependencies:
			      ./1.o: __DIGEST_TRIGGERED, ... (2)
			      node info: /home/nadim/no_backup/pbs_tests/generated_pbs_project/_out_nadim/1.o.pbs_info
			   Matching rule: #9[B] '1.objects:/home/nadim/no_backup/pbs_tests/generated_pbs_project/pbsfile:77'
			      => ./1.o ./2.o ./3.o ./4.o ./5.o ./6.o ./pbsfile_2/7.objects

	node log contains spaces rather than tabs
		output tabs!
		set tabs or use expand in the pbs wrapper
		output filter can have different tabs per section
			how does one set tab stops from the output filter
				call tabs!


	warp 1.5 size
		_LOCATION field
			it's repeated for each node but often we have 2 different location
			indexing the _LOCATTION can speedup loading of the file and reduce memory footprint 
				in a test _LOCATION:some location took 70 KB space for a 1300 KB warp file
					we still need _LOCATION:index so it will still take some space

					we could use a shorter variable too
		#--warp_human_format
			save a more compact format by default and use this option for something readable

	depend log
		we call NodeInfo but that's not the depend log, that's the node after depend
			depend log should contain:
				the output for the pbsfile run
				the rules run to create the node
				the rules run to create the node's dependencies


	generation of pbs_log during depend takes a long time 0.8 s for 800 files ... in parallel
		the generation is useless if the build goes through as it is re-generated in the same file with build information added
			maybe we should generate the files when the build fails instead
				=> only for the nodes that fail and their dependents
				=> as a custom post build command for discovery
				=> as a different call to pbs which doesn't build but generates the files

		it's useful for discovery but a switch to generate all for discovery can be used

	use hashes to index dependents in the warp file rather than file indexes
		it's just slightly more expensive but we can find the nodes while debugging
			maybe debugging in the debugger could make things easier but it's 
			overkill to check to dependents

		check node, get dependents, get dependent name, get dependent node, get hash

		it's less expensive!
			today we load all the nodes to get the location and hash to verify validity
			node that trigger, and their dependents, are removes so we have loaded their
			data just to remove it

			if the dependent list contained the loaction+name: hash we wouldn't need to
			deserialized node that are going to be re-created

			we still need to load the nodes that are not changed to get some data from them
				today all the nodes are grouped together, loading one is loading all

			it would more efficient if the nodes where grouped per pbs run as removal of nodes
			usually removes all dependents and dependents pbs run (check this!)


	build regex
		allows us to point at nodes to be build
			the problem is that parallel build takes any node in any order, making it difficult
			to debug a specfic node manually (or look at what's generated before it is build

	use external program to compute hash of dependencies
		pbs --list-files | bao > file with current hashes

		might be faster than computing the hash on demand during check
		external program is optimized and may run in parallel (like pbs and bao does)
			parallel may make it possible to parallelize anyway
				can we compute the hash on other machines too

		--check_only_terminal_nodes makes this moot

# pruning shows the same node multiple time
		checkers are run in parallel

#--trigger -fb
		nodes loaded from warp trigger even if --trigger is not given in the run!

#--trigger ., triggers .o.trigger_dependencies
			that stops the build!

			-bi . makes it go forward
			PARENTS is not set for .o.trigger_dependencies, stopping the queueing of parents in the build list

	a lot of options exist for us to run queries and display information on the graph
		most of the time it's the current graph being build but sometimes it is about a warp file

		could the object be serialized and queries run on it without pbs?
			we want to be able to script new queries not only run the one pbs give us
				which means that the queres could/should be external to pbs even if pbs run them
					which is what plugins do

			we can also manipulate the graph then build it

			warp is a serialization although heavily specialize
				warp could be extracted from a serialized graph (one that's on disk)

	--trigger could be done by
		a breakpoint
		a rule that contains a trigger REH 

	broken in vi with color
		first time goes to the file but not the line
		second time refuses to go to c:_objects ... even if the cursor is on the file name

		Matching rule: #1[B] 'c_objects:/home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Rules/C.pm:48'

	in log for object file
		a dependency is missing and and an info file is pointing to a location that does not exist

		dependencies:
			node info: /home/nadim/no_backup/pbs_tests/generated_pbs_project/_out_nadim/pbsfile_2/pbsfile_9/pbsfile_10/pbsfile_11/pbsfile_12/pbsfile_13/73.o.trigger_dependencies.pbs_info
			__SELF: : not found on disk

	warp 1.8 pbs chain merge
	linking during non warp depend must also update the pbsfile chain 

	md5 request for C dependency cache are not counted in the md5 stats
	md5 cache flushed before returning stats!
		in warp lots of cache flush all !

	watch_server drops events
		use fluffy and generate files that can be reparsed by pbs
		we can use a named pipe but the files have the advantage of advantage of being present in the file system
			we need to have watchers on different machines, possibly different OSes)
			using files is universal
			format so they can be parsed rapidely

		how do we know where to fnind the file system event logs?

		at each run, uniquely identified with a new handle, produce a new log file

#--tno
		shows all the nodes
		shows the PBS libraries as dependencies (which is right but boring)
			when loading graph from warp file
		stopped displaying __WARP_NODEs except those linked in the new nodes

		this also stopped the display of the library nodes, because those are warp nodes
		but not linked to by the new nodes, the linking to the library nodes is not done during
		depend (which it should) but during the warp phase

	--no_has_no_dependencies
		=> hide warning for C dependencies file not having dependencies itself (it is dependend)

	--node_environment
		display the environment variables active during the node build
			maybe in a separate file to not spam too much in the terminal
			=> in the log

		how do we control the environment variables per node?
			we don't, the only thing we control is $ENV at the start of the build

		for pbs2
			control env per node, per command in the node, per phase in the node
			inheritance of env from node to node
			package env is default for nodes
			env should go in the digest


	--log_html generates a node information, inlined in html?, that information
		is updated when build but is still interesting before the build or if the 
		build fails, --log_node_info and use it fron html

		=> switch already exists config->{CREATE_LOG}
		
		--create_log is the same as --keep_pbs_build_buffer

	builder can be generated on demand
		we compile builders as soon as AddRule is run
			even for nodes that don't need to be build, everytime a rule is added
				in a test case, 2000 nodes, 3 to be rebuild, 21 builders generated

			but that checks the rules at pbsfile run

		the time could be spread over the build phase
		the builders are referenced from the node and thus kept in memory
			if they were to be compile and reference in the scope of a node build
			the  memory would be released

			if the builder is used by multiple nodes we would need to compile them again
				late compile and keep in memory

				!reference count the nodes using a builder and release the builder
				!when no node need to be build by it
				!	node count is incremented when a node matches
					=> let perl do the reference counting

#--tno should always be displayed as --tnt

	ddr
		rule matching PBS_WARP_TREE is not shown

	rule name deduced from regex?

	shorter name
		node types, V for VIRTUAL, ...
		Rule for AddRule
		...

	use tmux to keep session open when an error happens
		that would mean build in tmux
			or rebuild only the failed build in tmux

	on error generate a script that
		sets up a tmux environment
		cat the build buffers as if one was building in the session
		add commands to history
		runs set of commands to ease debugging
			display debugging information

		run ranger 

	keep runtime info for nodes
		build time
		node where the build was done
		environment variables (which should be in a node config)
		...

		the information is kept
			in the node itself
			in a log file in a perl format to allow post processing


	move NodeInformation to methods
		many information elements are generated and added to the log or output
			putting the computation of the information in methods allows post processing to generate the same output

	keep pbs buffers
		a bit like keep_build_buffers

		all debugging/process/flow/logic goes into external files 
			nodes get their files
			pbsfiles get their files
			graph get its file
			pbs gets its file

		all switches on
			switches can eventually get their own files if they output a lot of text

			maybe not _all_ but a good part of the debug data
				configured as all minus whatever the user deems not necessary

				the configuration and example files for the output are a good
				place for documenting the effect of the debug switches

		use normal cli tools for debugging

		use vi to gf from one file to another
			need an editor that can handle ansi codes for color

		optionally remove buffers for nodes that successfully build
			do it after building dependencies to always keep info when an error occurs


		time line of a build is also written down
			not only the graph but when things happen in the graph


	split pbs a la gcc

		different programs handle different phases
			depend
			check
			build

		data can be serialized between the steps or the build steps
			are both applications and modules to be use in-memory in pbs


# remove print to STDOUT

	log removal of environment variables
		log the kept variables too

	Creator vs immediate build
		Creator, file that need to exists before depending a node
			often a file that itself points to other dependencies

			often a single file but mechanism should be good enough to handle complicated dependencies
				a: b at dependency time but
				b:c and b:d at dependency time
				d: needs to exist

		C: "list that is included in C"(LIC)
		LIC: processed "files in a diretory"

			
	Fix all examples in pbsfiles
		make run
		document
		remove

	Roadmap
		Warp
			Meso warp

			load/regeneration 
				faster
					smaller size (15 MB for 12_000 nodes)
					less data
					on demand regeneration
						we regenerate the nodes but very few are reused in non warp run

			distribution


		Depend
			rule caching
				between runs
				between packages

			parallel rule running		
				
			distribution and parallelization

			# linking configuration check
				move linking code to separate package and call
				user definable plugin to do the check 

			rethink package dependencies

		check
			distribution and parallelization
			
			separate check hash, generate build sequence, create parent information
			
			by the time we get to check we have an inserted nodes list so we can check all the nodes md5 in parallel
				but when a node triggers it's parent nodes do not need md5 checking 
					we check nodes from the root down returning the build sequence
						do we need the build sequence when building in parallel?
							no but it is used in the current implementation
					we should check from the terminal nodes up
					
					the node level is known when it is inserted (parent + 1)
					parents can be known to nodes (not logical but for speed up purpose)

				that's the way warp does parallel check!
					one level at the time and main process triggers parents
					but the parents must be known to be triggered

			for distribution we need to synchronize common nodes
				synchronize with master for each node added to process local tree

				do a full depend and post process the graph to merge them
					we need to handle configuration as well as dependencies

					an added advantage is the possibility to query remote build nodes for sub graphs
						kind of meso warp for a sub graph but on another node

						if a remote node has a matching sub graph, it can start checking and building it as soon
							as the graph has been verified

					handling of sub graph mismatch
						report error if no sub graph matched
							do we try to build the sub graph locally? yes

						report warning if some sub graphs didn't match
		build
			distribute

			generate meso data for nodes/pbsfile/packages

			light weight build node (just run commands know nothing about context)
				gearman

		Watch server
			make robust using lib or other external server

		graph generation
			variants in the same graph

			remove local nodes 

		debugger
			interface
				rocky bernstein

			breakpoint
				variable access or modification
							
				grep output
					can be done today by using a breakpoint

			query interface
				database 
				csv  + text to db 

		Repository
			expand --source_directory to accept external binary repos
			
			make difference between source and binary repositories 

			
		General
			PBS 2.0
				more implementation
				work on the requirements

			#Zero ENV

			rename pbs switches

			rename/alias ExcludeFromDigestGeneration
				use REH_SOURCE

	move package dependent digest data to runtime package
		rather than in Digest.pm
			GetPackageDigest($package)
			$package::GetDigest()


		when applying rules, apply rule_package_dependency which adds node or package dependency to the node directly
			store in __PACKAGE_DEPENDENCY

			makes sense to have the dependencies directly in the node
			simplifies warp generation

	binary repository
		client
			
		server
			? replace  --source_directory for binaries

			homebrew
				http server vs adhoc
				forking?
				crawls output directories, links to them
				
				


			the shiny with a web page
				plugin to do the mangling
					run as proxy server or within pbs

		local cache
		precognito mode
			knows about things that are being build
			blocking / asynchronous

		spreading the word
			synch with other repos
			address book

		administrative work
			backups
			removal of old objects
				

	Add to docs:
		PBSFILE_CONTENTS is added as a variable dependency, those are not checked in warp
			OK if the content is generated in pbsfiles
			if the content is based on an external file, that file must be added in the dependencies
				it's the responsibility of the user, pbs has no idea where it comes from

	remove creator and PBS_FORCE_ type (only used by creators)
		can probably be replaced by a mechanism like the new C depender

	do not put all the big files in the same sub processes (duh!)
		checking the size of all the node may cost more than checking them in the same process

	log:
		#--log_node_pbs_data, adds pbs data to log, save time and apace

		rules triggering are not in the log
		pbsfile loading is not in the log

		--log_html
			generate a set of pages from the log files
			navigation link on node names
			bread crumbs to parents


			or a simple page wth minimum javascript that uses dependency data
				need an out directory and a start node
				and a dependency graph, parseable, where does it come from?
					generate is in the LOG directory
					maybe we do not need a full graph, we can use the node's data

					given that they are in the same out directory, the data needs
					only list parents and dependencies and their build name to find
					the logs, 

					can start a browser anywhere, practical when debugging, looking
					at log data one can simply "click" the node.html to start browsing
					the graph
						this means that the script is in every html file!
					
		No need to have dependencies in the list, they are in the node info
			we need -ni to generate the link for us or parse the output

	 breadcrunb/breadcrumb/breadcrumb/breadcrumb

	 .--------------..--------------.---------.-------------.
	 | node info    || build buffer | Log     | local graph |
	 '--------------''--------------'---------'-------------'------.
	 |                                                             |
	 |  name ...                                                   |
	 |                                                             |
	 |                                                             |
	 |        dependency                                           |
	 |        dependency                                           |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 |                                                             |
	 '-------------------------------------------------------------'





	AddEnvVariableDependency in --j 0+
		passes 	passes in warp 0 

		=> warp does not support ENV, the warpified tree has no idea of ENV or anything that is not a file MD5
			Meso Warp will handle it!

		#? how does it pass the automated tests!n warp > 0 ? 
			test is skipped

	working on JOB = 1
		automatic test pass when run by hand
			
		15% overhead for -j 1, probably much less for processes that actually does something more than compile 3 lines of code
			returning output and logs
			finding the node linearly
			handling the communication, splitting answers on tags

	Node@root: time to retire
		doesn't play well with progressbar (but it's the crappy progress bar that should be replaced with
			something much simpler)
		loads all the warp files, even in warp
			doesn't have a config

		either do it with warp, saving the configs or build locally after saving the configs
			always save the config?
			
		

	new C depender, what if the compiler generates the dependencies but post build commands are not run?
		=> we need the post pbs because the build is in another process and the warp is in the main process
			meso warp fixes the problem without post pbs build commands but still needs to be
			stiched up correctly when meso warp master generation fails (or is not run)

		add: new c_depender test
			current tests cover the change


		#extra out directory
		#takes an extra run to stabilize warp, fixed


	fork fails in windows, again!

	Tie::Hash::Index pulls in a zillion modules and libffi
		
	check simplified dependencies rules and perl rules
	Check pbsfiles/config project

	document EvalShellCommand and the order they are run as well as --evaluate_shell_command_verbose 
		that they are best put under lib/rules
		plugins are for global changes

	c depender:
			$config->{'C_DEPENDER_SYSTEM_INCLUDES'},

		#option to not take in the system includes
		option to make the system includes a sub group so they are not displayed all the time in -tno

	-bi does not work with -j
		shows info but build fails although it should continue
			probably node builder knows about --bi but not parallel builder

	add --tmux-error option to test, with limit on how many are opened


	\r \e[K

	example of output with options on
		pbs -ho -o1 -o2
		pbs -warp 1.8  --display_warp_checked_nodes --display_warp_checked_nodes_fail_only --display_warp_removed_nodes

		searches for examples with all switches
		displays one or more examples 


	[SOURCE] instead for NoDigest
		less typing
		no need to know the API
		regex (or single file) is already known
		name is better when it is the name of the rule
			in case multiple rules tag different  nodes as SOURCE

	[USER_TYPE]
		annotation like types, just tags the rule
		pbs keeps track of them
		rule can extract all dependency nodes that have some USER_TYPE set
		pbs can display them in -tt, maybe with an extra option


	AddNodeFileDependency
		the dependency must exist or it's MD5 can't be computed
		=> should wait till the depending node is build to compute dependent md5


		!!! why wouldn't we just add a rule? why does the file dependency have to be in the digest but not in the graph?
		
		not supported in warp
		=> Remove

		this is the mechanism we use to add dependency on pbsfiles, it can hardly be removed :)
			pbs2 put pbsfile dependencies in the graph, on another layer

		it is accessible to the user if they want to "use" non pbs files to define config or rules
			and want the dependency to be right

	AddVariableDependency
		=> should be done in the rule, not globally in the pbsfile
		=> should automatically add the variables that are used during the build of the node
			%PBS_REPO would force all nodes to rebuild on a change of repo or added repo,
			which is the opposite of the intended purpose of repositories!
		
		Warp doesn't check variables! it works because pbs checks the pbsfiles where the variables
		are declared

	AddEnvVariableDependency
		breaks warp
		env is evil
		=> put in config, add config variable dependency for lesser evil
			will still break warp
			overrides will be caught
			will be saved in config

	project generation script can generate project which doesn't require compilation
		- we can still use .c file but
			- replace the .o depender
			- build the .o by touching them
				
	debug breakpoint could display an informative message about what it is doing
	and what is available for poking

	install pbs on linux and pbs.pl on windows

	Add a bunch of test with bad pbsfiles to catch syntax errors


possibility to run commands directly from the log
	we need the directory to be set properly too

node config
	nodes can specify what config variables they need (probably written somewhere else)
	nodes verify, insertion time? build time?) if the variables they need exist
	ENV is reduced to the declared variables
		what about variables used by tools, does the node need to declare them?
		does the node declare the tool as dependency to build and import the tools variables?

	if no ENV is specified per node, do we have an empty ENV or the pbsfile ENV?

	
building in docker
	where does the log go?
		in docker but we'd like it outside, via mount or by making the logs available on a different machine via scp
			scp a tarball

generation of pbs_log_dep takes a long time 0.8 s for 800 files ... in parallel
	it's also re run for all the nodes in the graph, ? including warp nodes
	the depend is overridden if the build goes forward
		maybe we should generate the dep files when the build fails instead
			at least for the nodes that fail and their dependents

		it's useful to understand the the build structure

node logs contains information about their build time and what pbs generated it
	it could always contain some extra information like the compiler version, ...
		although the compiler digest should be in the dependencies

	it would be nice if the node also pointed to an extra file where the builds using the node
	can add themselves, extra information that shows how many builds are using a node that's already
	build

	the node log can contain the dependencies hashes

parallelization of build is done within a structure in memory
	we could reimplement it externally with multiple queues and some external worker that starts builds
		starting build is triggered by different stimuli
			for terminal nodes it's the availability of a builder 
				builders can be external applications, on different machines
			for parent nodes, by having all the children build, making it a terminal node

	we need to handle build errors
		particularly removing all the failed node parents and maybe continue
		the build for nodes that are OK

	the external builders, and queue manager can continue building in the background
		EG: pbs gives the hand back to the user because of errors

	on next build, pbs can verify which nodes have been build while it was not running
		it can also verify if a node from a previous build is not build yet and wait on it

	this makes sharing nodes between build much easier, there is no need to synch between pbs builds
		we only synch between build-nodes/being-buld nodes
		we can find the nodes we need via the node digest (is the digest of its sub tree needed?), including config

	
	
 
following variables defining link or compile flags
	from a node build, follow the changes done to a configuration variable (including where it was changed and why)
		this could be achieved with files so we can read them in vi
			or vi a query (that goes through the files)

insert color codes in the logs
	pbs2 generate monochrome data (logs)
	pbs1 generates colored node logs and adds some color tag in the pbs_md5 files

	the easiest way to look into logs is with ranger|broot|fzf and vim
		these show files in different "viewers" which often can handle ansi codes
		we need to generate those files from the pbs2 achromatic data

a very simple way to run in the debugger, including pbsfiles
	remember debugging DEFINED in cmake
		I would have liked to stop at the set
		execute it
		look at result
		run other set
		clear set
		write the current file modified
		continue building

	the repl can generate files, interactive generation of pbsfile, with localized runs

		psfile lines
			1
			2
			3
			current : modify current, ie insert multiple lines that will replace 4
				run the block till happy with the result
				possibility to undo, IE go back to state before current was modified
			5

		window to visualize what's going on

		the modified block must be run with a start config and target
			isn't the block close to a subpbs?

		we can keep the modified block and restart evaluation at previous line
			thus we need to keep a state per line to be able to undo

	we need to be able to specify which files to debug, simply
	we can continue running till next breakpoint

make pbs a normal lib so we can run in the REPL, including substraction of rules, going back in the graph evaluation ***, etc ...
	add rule
	pbsuse
	normal perl code
	set rules in rule set
	apply rule set to node(s) and get graph
	modify graph
	apply rules to node in the graph
	diff graphs
	check graph (without adding parent relationships as we me re use it)
	manipulate node group
	get build sequence
	build

including non automatic or very long steps in a build
	the user must agree on something being done
		that may be receiving a mail back with the agreement or directly typing yes

	check snake build
	no-build scripts, script that only whrite what needs to be done and wait for a key to press
		document the process
		partial script that automate some of the work (not different from the build system 
			calling a no-build script except that the process is self contained in a scrip
			it would be an error to contain the script in an external, non pbs, script when
			that can be achieved by writing the partial scrip in a pbsfile where taking a step
			toward automation is much simpler than having half the work in a script
			and half in pbs 

			of course we need to let the user decide but providing a framework and example help
			make a better choice
				the example show how to partial automate something and handle dependencies
				which is not a trivial step when going from manual to automated, particularely
				when declarative scripts are involved

what to do with large builds waiting for user input or a very long running command
	the build (possibly distributed) is taking resources in the form of open file handles, memory, ...

	even if not waiting, using resources is bad and should be reduced
		a flagrant example is keeping the whole graph and nodes in memory even after the nodes
		have been built.

tracking what build a file once it's moved from the build directory
	pbs node logs tell everything already in the build log
	manifest that can be searshed
	global md5 table of all node build pointing back at their build
		note that this is the same as a build cache except the search is reversed
			actual md5 to build instead for expected md5 (build) to node(actual md5)


	not installing but linking the nodes helps (and keeps them packaged)

parallel build systems
	if the warp file is split, each warp file can be run in its own build system/process
		if the start config and node for a dub build system is the same, the 
		sub build system generates its graph (which is righ if input is unchanged
			and delivers a trigger or not trigger for the top node
			no need to deliver the graph only the triggered node
				if its input is unchanged it can also start building immediately

		the sub build graphs are delivered on demand to upper level
			graph is node names only, the data is in the nodes_log/digest

		at the end of the run, global graph, component graphs, config data, ... is
		put together, rules could do that on nodes in the pbs layer (pbsfiles, configs, ....
		
	the complexity lays in what parts are run in a separate process
		once the build is set, the process should end and the cpu left to build tools

		this means that everything is serialized as there is no more object to talk to
		maybe we should never be able to talk to a service but only via files
			one advantage is that synch is done via files and files/processes can be on other nodes

		since a node information is serialized, including its dependencies, we could parallelize ad nauseum
			and let the nodes to be build synchronize the files they need, including compiler, ....

			the build node should keep the dependencies around as much as possible, ie multiple compilers could be kept
			on the build node
				some dependencies, IE: compiler, build themselves by installing themselves

			we could install in some sort of containers which would give the possibility to download parts of the install
			from nodes which already have those parts, a p2p solution is even better
				compare this with jenkins nodes where compilers are installed to avoid copy
				of course we can still install them and the node's build simply verifies that the compiler is installed

		we need to keep a weighted graph so the splitting is simple

	administrating the different nodes that compose the build should be trivial, like the log for nodes in pbs1, location is obvious
		CIT also has some idea about how to find a job which is not different from finding where a node is being build

		we could overlay the sub build fs, if it's on another machine, to give a local view
			could this work for CIT too?
				fs could be read only when the user only had read rights to the job, etc ...

		after running the build system to generate graph data it is possible to take a sub tree and 
			copy everything that's needed to build it on a remote node manually
				some trace information should be left so the automated build can try building on the node
				where me made the manual copy

			to find which nodes have a sub tree build data we can
				use a distributed hash
				query all the nodes
				ssh and query and check the nodes ourselves

				we're not sending GB of data just a few hashes so a simple solution is enough

				we need to trust the node since it returns binaries, pki?
				
				how do we debug with files on other nodes -> mount the other nodes
					but we need to lock the other nodes''s data so another build doesn't override data
					we could use an overlayfs layer to make the generated files uniq, other builds
					build in another directory which is another overlay

	remote node build also contains information about what started the build (and where)
		remote build may start another remote build
			some correlation ID must be shared as well as a system to collect error information from any node

build on an overlay, makes the output locked for a build
	other builds can still access the layer as read only if they need the data
		
	this smells like docker!
		maybe we should build in docker and each sub node/sub project can be build on it's own layer
		this would allow us to fetch builds from other nodes
			except that we want to keep stuff on the nodes  where it was build not bring it back: see local in pbs1

			we could also mount the other directory via a network fs or even sshfs (for CIT create a new user per build)
			
			given a local filesystem in a single blob (IE not the native fs but an extra fs) we wouldn't need to
			pack the files to relay them to another node, they are already packed, except we want to keep thing on the node
			where they are build :)

use bao to compute full graph md5s and serve the result
	also fix inotify by using an agent that works better than our implementation
		inotify should watch the directories not the files to save resources


pbs name of application + user info optional, via filter or option?
	via option --print_pbs --print_extra --print_location

	build: using 3 processes ...

	pbs: build: using 3 ...
	[some user text, eg: name of a build] pbs: build: using 3 ...
	pbs: @file:line build: using 3 ...

	via filter
		pbs: is added by the filter
		extra text is handled by a filter option not pbs option
		the line information must be added to the structured log

depend steps should create depend.log files in a directory structure just like build does
	we can still output the normal data (and the structured log)



directly show graphical representation of queries
	can be done via a wrapper
	query can output the file name to pipe in viewer
	sd can create a shadow structure

	use visidata for queries?
		can it lauch vi?

show access to config variables during run
	put them in the log
	internal variables and environment variables

	display which variables have not been used
		for a node
		for a graph
		for the graph
		
		tell where they are declared and used

		in a format that be queried, including their usage in sub trees

generate build manifests
	of nodes in the build
	of nodes triggering
	of rebuild nodes

	a graph that's easy to traverse for visual inspection
		sd | broot
		broot on _output_nadim

		the source graph and the output graph are not the same, we may need to overlay them
			sd links directories it doesn't link the nodes in a directory so we need to add that

		the node triggering in the source directory don't change names nor have config and extra data so we may need to 
		create extra data files in the source shadow tree, alt we can create a source node link in out directory

		it may be ok for a few thousands nodes but not for half a million
			we may need to create the links dynamically
				when looking at the tree

				when running a query that needs access to the source code in the shadow tree

					although all files are referenced in the graph

		

		although broot is OK, it's made for searches not traversal



	this is to look at the build at a high level

	to look at the details we need a graph and detailed 


	format of the manifests

		preferably tab separated, with column header


		query the graph
			preferred way to generate manifests
			we may need to keep a warp and complete graph
				or the graph is the warp graph and we load extra data on the fly

			the 1.8 warp graph is not even a graph anymore it's a cache lists to trigger nodes

		having the graph allows us to query more than files
			virtual nodes
			configs
			...

		user can write a simple printf as git uses in pretty print

		the query interface is a script using other query scripts
			this lets the user build her own queries on top of query modules
			the graph is loaded and the modules run on it

			using a standard graph query and traversal language
				we can still format our data as we want, we just need to proxy the language to our implementation


	query examples
		see above
		create a shadow tree matching the query
			eg: I am going to change this configuration in that pbsfile
				show me how the graph would look like starting at another node

generate a log for nodes as soon as they are
	added to the dependency graph
		from pbs1 implementation of this functionality
		1 # section below is disable
		2 # we could generate the node log info after each node depend but do it after the check step
		3 # that adds the check status for the dependencies
		4 # the best solution would be to add information incrementally, generate the node log info during depend (rules  inserting dependencies)
		5 # and adding the check information later
		6 # alternatively we could check the nodes immediately but that wouldn't work with late depend that delays the insertion of dependencies
		7 #โโโโโโโwe would have a wrong status for the dependencies

	build failed modes have a failed postfix

	the pbsfiles run
	the command line
	the environment variables
	
	everything that get on the screen
		for build we redirect stdout but we can't do it for the main process
			external filters can do that

user can grep/fzf/ranger to find broken nodes
	a file with the list of nodes (with meta data) can be generated -> give to fzf -> filter out log name

graph queries
	find nodes that are broken
		generate a context graph

	find a node, generate a context graph

	find node(s)  common to two or more nodes

	find common pbsfiles
	find common variables, that changed, ... where (this needs config history)


	=> all this would be easier with external node data in a parser friendly format


config history in a file
	serialize the config, at the end of the pbsfile
		with history
		nodes can link to that history
		pbsfile can link to that history


	if nodes contain their configs, their parent, their pbsfile, and that their pbsfile contains links to its
	parent node, we can re-construct the config history without having to serialize the config object
		some information is lost, where the config was changed and why



file system shadow directories
	_output is exactly that except for
		virtual nodes
		pbsfiles
		config


log files can have different extensions depending of if the build succeeded or not
	LS_COLOR can be used to make the error files stand
	we should never have a build and failed log present at the same time
		except if the user wants to save the previous log, which can be done by the user

API
	time to think about an api to control the build system

	this includes better options which are a type of api

	REST? REST for command line

	REPL? isn't the debugger a better REPL?

use hashes to index dependents in the warp file rather than file indexes
	it's just slightly more expensive but we can find the nodes

an option turns line output for print functions/log functions
	we need to know what logged not only what is logged
		IE: PrintXXX 

finding build nodes from somewhere else
	root
		tools
			utils
				the_tool
		install
			the_tool
				which means that it needs to have it as dependency

		test
			some_test
				need to run the_tool
				which means that it needs to have it as dependency
				
				point to the tool at root/tools/utils/the_tool or root/install/the tool


	=> which means that it needs to have it as dependency
		a dependency is either
			inserted by a trigger
				some_test > trigger > some/node @ alias
				

			pointed at full path
				if it's not there we get a late dependency
					can late dependencies be aliased
						eg: root/x/z/my_tool is aliased to root/tools/utils/the_tool

					who makes the alias?
						x/t/my_tool

						anyone? anywhere?

					can we have many aliases to one node?
						what happens when aliases are already used?
				
					what happens to aliases that are never used?
						do we warn about them


			found in the graph
				need support from pbs for that
				does it even make sense?

for CI
	importance of logging the start time (and end) of a job

parameter to a target (or sub target, a la "just" program)

	default: (build "main")

	build target:
		@echo 'Building {{target}}...'
		cd {{target}} && make


	example 2

	backup +what
		scp what me@server

	$> just backup a.1 a.2 b.1
		scp a.1 a.2 b.1 me@server

	# not sure it's better than: $> make backup WHAT="a.1 a.2 b.1"


	just has three types of variables
		variable
		+variable
		*variable

		they can have default values



	$> just backup a.1 a.2 b.1


polyglot command
	in just, prepending commands with a shebang runs the commands as scripts

	roughly translated 
		with the exception of string that is not needed in just as its syntax looks like make
			and that it accepts a single command

		rule polyglot
			...
			builder
				<<EOP,
				#!/bin/env perl
				some perl script
				EOS
				<<EOA,
				#!/bin/env awk
				some awk script
				EOA

listing rules
	idea from 'just', --list doesn't list "private" target starting with __, grep -v' ^--' sound like a better idea

	pbs --list 
		rule abc (:line)
		rule 123 (:line)

	pbs --show 
		rule abc (:line)
			body of the rule
		rule 123 (:line)
			body of the rule

listing body of rule before executing it
	idea from "just"
	
	pbs --node_rule_body
		add the rule body to the node log, although we can open the node and jump to the definition easily 



using #! instead for autorun in pbs2
	#!/bin/env/pbs -f
		#rest of the script



default target
	works nice with make because the target is the rule (which is pretty nice)
	but pbs applies rules to the target passed on the command line

	we know which rules we have since we register them and could make the first rule match
		but match what? a regex?

		rule name => xxx, Match /all/

		a lot of things match that!

		rule name => xxx, Match /^all$/ | Match 'all'
		
		only match all

		first rule which matcher has a string as input?
			special code _just_ to allow a default?! we don't like default variable, config, rules, ...
		

	we can show what the rules would match, IE regex or string

	
	prf, is it needed?
		no but it's convenient

		it allows us to put all the special cases in one place
			default target (user target really)
			configuration variables
			options


passing environment on the command line
	other build tools have the environment as a configuration db
		this is not good enough, to audit config IE

	still pbs allows environment variables to sip through for commands that may need them
		pbs only keeps the variables that are allowed to pass
			this is still not good enough!

		it is not possible to completely eliminate environment variables because tools depend on them

		it's also very convenient to be able to set variables before calling a tool

		multiple actions are possible and some already done

			filter out the environment variable

			make all the builds depend on the same environment, IE: if a variable was set when a
				command was run, it must be set next time or the node is rebuild, env variables
				become first class dependencies

				this is means that the user needs to have control over the environment variables
				that get in the build environment, probably per node to build
					REH_USE_ENV

				since we have the graph before building, we can alert the user for environment variable
				mismatch (or tools version mismatch) before building.

				tool version should be done via dependencies on the tools version instead
					can also be used for global variables we need to be set

		where do we filter the environment variables and how do we report them as we could report configuration variables

			per pbs process, and pbs forked processes (who inherit them)
			per pbsfile
			per pbsfile run, they can be passed down (by whom the parent node or the parent pbsfile)
				how does it work with pbsfile env filtering, who takes over?
			per node

		reporting environment configuration means keeping track of it
			do we keep it in a separate configuration object?
			can it be on a layer in C::Hierarchical?
				with what priority?

		whats the relationship with the pbs config
			are $CC and %CC the same?
				no because we must have a change to control the configuration at the node level

				but we also need to be able to override config from the command line
					that would work if env variables where on a layer in C::H
			
			are the environment variables put in the config when pbs starts?
				do we put them in all the build environment automatically

			do node handle environment variables in a special way or through pbs config

		if a pbsfile filters out environment variables, what if we let them through?

			shell: 		a=1 b=2
			pbs:		--keep_environment: a ...
			subpbs:		pass limited environment
			pbsfile:	filter_environment: b, must have c
						must have is an interesting concept, it can be verified when the rule is added
						
						it would be good if all this was through specialized REH in pbsfile_run rules

displaying/loging configuration
	on the command line
		??

	display config event when they are "special", I.E.: an override,
		shall we also display the normal variable setting/changes in the log/output?
			we prefer totally silent output with options to swith on specific output
			the total opposite of make (almost, all goes to logs instead for stdout)

	config is node specific
		if a node doesn't have  any specific config it gets it from the pbs-run node and it then
		becomes the nodes specific config.
		the pbs-run node config is read only for nodes, only the pbsfile run can set configs
			inherit from parent pbs-run, filter, set, ...
			the config is kept in the pbs-run-node  log/digest

	every node had the config in it's digest/log
		not all the config are part of the value included in the signature but the config is listed

		this also applies to pbs-run- nodes, ...

	is the config also a node ?
		if it is it can get verified and trigger 
			on any or specific entries
	pbs can save a pbs run config, shall we also save an environment config or should they be equivalent

node build commands
	pbs 1 can run multiple commands or pel scrits but there is no relationship between them, once
	can even set a config from one build step to the other
		note that pbs2-proto hands the node so there's a place to store data to be moved around
			that could also be in the builder loop
			or the command can do it on its own, like a shell command does



../../../something
	explain . and how to use it
	explain full path and no relative path
	catch ../..
	how does not having relative paths help?
	triggers in higher level directories (should be accessed from the machines root)
	how does full path impact reuse of artefacts in other builds
		can someone else reuse the builds if they are rooted differently
		C depender has full path and that stopped re-use
			a good thing? and what's the run time impact
			bad?
	how does one get a node path in a builder (and why would someone want to do that)

pbs_run rules
	rule name 
		is rule a REH?
			it takes a name ar argument and a list of REH that it registers?
			there's not reason the registration would be done by pbs when a REH can do it
				suubpbs are already handled this way

	rule name
		MATCH_PBS_RUN #is this the same as matching a subpbs rule? no there are two phases, start subpbs, be the top of the subpbs
		MATCH_TARGET
		FILTER_ENVIRONMENT (to subpbs, how about in the subpbs)
		OTHER_REHs

	if they have rules they have builders
		good place to sneak in warp distribution

	should the pbs run builder run the target builder
		that includes loading the subpbs (how do we do in the pbs2 prototype)


parallelization of depend step
	fork?
		on node
		on subpbs

	fork worker pool that can be controlled from the main process?
		
	we should stop handling nodes as objects in memory that reference each other and start handle them as 
		a text description that can be loaded on demand
		trees can be much smaller as they just just keep a reference to the files to load
			there will be an impact on performance but it may be small

	we can use the file system as a locking mechanism to know if a node is already in the graph or not
		being careful with nodes that are already serialized on disk from another build

		create the node, exclusively, first process creates it, other process use it
		gmake used a trick to control how many parallel process it runs


difference between config variables and environment
	should there be a difference

add section to elf file with pbs config for the node

nodes can be prioritized against each other to make them build in a specific order
	priority is a set via a REH as a node attribute which is used by the scheduler
	this is for nodes that are not dependent and only to influence the scheduling

nodes can catch/and/or forward that sub nodes are being build and thus that they are being built.
	this generates a lot of signals and catching
		the nodes who want to catch a signal have to register. 
			add_rule ...
				REH_CATCH_DEPENDENCIES_BUILD_START

nodes can add a notice to pbs information displayed when node is build
	print_info (maybe 'notice' is a better name) does just that

node can display information in the node log (which is also displayed on the terminal)
	REH_NODE_INFO can insert any amount of data, since it's a REH it can register to be called at different levels (depend, insert, build, ...) and
	thus insert information in the stream at different levels.

REH_NODE_INFO can be used in a rules for a subpbs, a node, ...

REH_xxx_CONFIG can insert data in the information stream
	like pbs1 inserts warning on the screen except that these warnings a structured

nodes can take over the normal pbs terminal output (which is normally the stream output)
	a rule can display its build differently
	a pbs option disables this behavior if necessary (debug)
	everything happening gets into the logged information stream 
	the fact that the information stream is changed is also put in the log

the node log file name is inserted in the information stream so it can be filtered out or opened directly from the terminal
	a related problem is finding out the build order
		it's sometimes the source of problems, mainly because dependencies are no declared properly

	we log the order of build but there's a difference between having a log and using it
		problem #1 is the amount of data
			filtering
				depth
				matching nodes
				matching pbs runs
				amount of data displayed
					each in own sections and can be filtered
			folding
		
		we want to know the build sequence of nodes that are dependencies
		we want to limit the depth of the dependencies shown
		we want to start from vim or the command line or a repl (although the repl should be dumb just running external script)
		we want to look at configuration for the nodes 
		we want to know when the configuration/rules where added/changed
		
		we want to see the pbsfile run for a node, that log entry should be in a pbsfile_run.log and linked in the nodelog
		
generate a list of nodes that have changed and a list of node that trigger (changed nodes and triggered nodes), the list contains the node log file path
	the list can be added to the information stream
	an option --display_triggered_nodes_list, displays the list and end the build, except if --force-build is active


caching tree for fast build
	fast build in this context means
		fast graph generation
		fast checking of dependencies
		fast determination of the commands to run and in which order
		not fast compilation 
			although finding where the sub graph could be compiled the fastest is part of the build 

	no build case, where nothing has changed, is the least interesting case
		not even interesting to compare build systems because it's, well, a stupid case of no relevance

	minimal build change is much more interesting and changes can be of many types
		deepest file
		file with most dependents
		pbsfile
		configuration change with different impact on the build
		...

	fast cache loading
	fast cache checking
	fast graph generation/regeneration
	fast dependency check
	fast command determination/order
	fast distribution
		that's the order pbs1 uses and it is not optimal
		
		if a graph is made of sub graphs (mini warp files) checking the micro-warp
			can be done in parallel
			only triggering micro-warp need to be merged to the global cache (maybe), the other just need to give the top node, un-triggered to add to the graph

		the libs and pbsfiles are checked first, if they are dependencies of the nodes then node checking does the same in a more generic manner

		the microwarp can be handled by an instance of pbs, which means that it can start building immediately
			the instances of pbs, and their result, must be orchestrated

			if the micro-warp is on another build node, the pbs instance can be run on that node achieving distribution

		the size and topography of the micro-warps can be computed to be optimal for the build node

		not checking intermediate nodes is the default, specially if artefacts are in a read only/pbs only filesystem
			an option forces the checking of all the nodes

		fast cache loading can be achieved by having less data in the cache, it can point to  the data in other files (log file, so we have the data in a single place)
		graph regeneration is to have data that may be used in display (IE: insertion line) 
			 we often set it to N/A only so it's not undefined and generates perl error when accessed

		command determination means re-loading the pbsfile but if the pbsfile wasn't changed then it's the same command as before

		the build order is the same as before and we can re-use it, it's just that some nodes, the one that didn't make it in the graph because they were not changed, won't be in the build sequence

		

	one case not handled optimally by pbs: only source change

	    since we have a dependent list we could use it to generate the build sequence instead we reload all the pbsfiles down to the change source and recreate the build sequence from scratch. It is not sure a more optimized rebuild is better for the code or the comprehension of the build but this is certainly less efficient even if it is really fast.

	to rebuild only the node and it's dependent we need to recreate the code that created it. Best would be to serialize it and/or keep it in memory

	the node may be build by a shell command (and a shell context, environment, installed version of toos, installed libraries, ...) or by calling a perl sub. the perl sub (it also has a context, closures, ...) transforming the code into a simpler "call context" may allow us to write an new code just to build the node in effect this transforms the sub into a shell command where perl executes a simpler script

	Rule ......, BUILDER => \code_ref, args

	writing node_builder.pl which contains the code_ref source code makes it possible to call it as an external command
	this could be achieve with a special code definition for builders, either by tagging its beginning and end or by making the code a string
	some perl modules serialize subs, they may be an even simpler solution, at least more transparent for the user

	even if we can serialize the code, we still need to handle errors in the same way as a full pbs build
	serializing the code makes it possible to build a node without having the build system involved, not sure what advantage that could be and calling the code through the build system is simple, simply build that node and only that node by running pbs on the node's pbsfile



debugging
	it should be easy to debug a build that runs command in the command line (and subs)
	if a node is build with shell commands, pbs should shellout for every command and give the control to the user
	the command, and other pertinent information should be written in the terminal, after commands are run the user can continue the build either
	by returning in the parent (pbs) shell or by sending a continue command and stay in the shell
	the user should be able to open multiple shells for nodes to be build (or no node if necessary but that doesn't need to be done via pbs, tmux is fine)
	this means that pbs needs to listen to a socket for "continue" commands
	how is this different from gdb? multiple terminals because we want to keep output separated
	should we implement gdb on top of pbs or continue with perldb?

	if snapshots of the files to build are done before building, we can trace back
		the user should be able to snapshot more than the node to build
		pbs need to snapshot its own data
		every time a node is build, a snapshot is made, which we get commit per buils

	git merge with conflicts can be seen as a template for this kind of commands line options (--continue, ...)

	on error create a file to open in vim with all relevant links

	on error create a shadow directory with links to
		failed node log
			dependencies log
		relevant pbsfiles
			their dependencies
		directory with saved config and command to run in that directory (while keeping everything at its place)
			commands to run with different types of debugging switches
		link to the whole source tree (since this is only a shadow directory with specific files)

		
	
handling of bulk dependencies added by a search function, eg: find all the libraries in a directory, makes debugging difficult
	because the dependencies are not named and grepping for their names gives no result, this forces one to grep through
	 the build node/run a query. Note that the biggest problem is a CM problem.

warp with reduced data
	to load faster, it instead points to full data for nodes, this allows us to do queries without having to reload pbsfiles.
	node data can be in microwarp, node digest and node log.
	microwarp should point to data not be data. 

a job in a CI system can be scheduled at any time, we need timestamps to see which one is started first
	a job that is depending on another job will always start before the dependency
	dependencies should be on artifacts not jobs! that a job created it is not relevant

	a CI job is an administrative process over a normal build
	but that's wrong, except the scheduling there should be not difference
	maybe a ci job should be a job, which generates artifacts not virtual "I build the latest"
	node builds must have information, time started, duration, in which context (build number if relevant, setup, config, ...)
	since some of the information is shared by many nodes it should be in configuration nodes that are serialized (looks like pbsfile nodes),
	linked to from the node build or serialized in it. if not serialized, on top of an url to the config/set/node, a md5 is kept, after all its a dependency too)

Telling a build story
	top down build systems are not always described top down, an example is setting up needed files before telling who needs them,
	and the importance of CI being driven/verified with the build needs; or distributed and all CM data gathered in a CM manifest

	by telling the story top down (possibly in different description files) 
	how do we define in a flat file or a series of flat files a build which is a graph and not a list in the best way? while keeping the build story.
	build system may need more comments if the build definition itself doesn't use a vocabulary that's clear enough, what makes a good book?
	links, bread crums, history, bookmarks, history from a bookmark down, scope+folding

	reading the story in the build description files is goo but we'd like to have the story readable in the graph and in the log while building
	in the graph means that chapter in the story are also node, with dependencies. Those can be added as virtual nodes, although sometimes the fit an intermediate file well. The virtual nodes also have a builder and thus are visible in the build log, they can also display extra information since they have a builder

	how to add dependencies to a story
		often dependencies are in a list and the  list is added to the dependent's dependency list, ach dependency then match a rule which creates a node
		in pbs1 a virtual node can be added, or a non virtual node

		in pbs2 the same mechanism exists but we can extend rule with specialized REH

		add_STORY_dependencies("the story", dependencies)

		the above REH can, create a virtual node, and/or, add information to the dependency nodes (using rules?)

		The REH can, during the nodes build, display information as it could also be a builder REH

		alternatively the story can be added to the dependencies
		Rule X, dependencies(), comments, belongs_to_stories(one or more story names) # I prefer dependents to set that information


		A story resembles more a container than a dependent, there may be a better way to describe that (a scope for example, which could be a name space at run time), a use case with description and output is needed

--node_environment
	display the environment variables active during the node build
		maybe in a separate file to not spam too much in the terminal
		=> in the log

	how do we control the environment variables per node?
		we don't, the only thing we control is $ENV at the start of the build

	for pbs2
		control env per node, per command in the node, per phase in the node?
		inheritance of env from node to node
		package env is default for nodes
		env should go in the digest

warp
	having unbuild nodes in warp is moot
		the node will build anyway after being removed and first revivified
			can we have only the build nodes or do we need all the nodes in the type of warp we have
				unbuild nodes trigger other nodes as their digest is not found
				warp file nodes contains dependents so we need the nodes
					but we do not need to check what we know will fail (because it is not build yet)
						check if MD5 ew 'not_build' rather than compute a hash

	warp can be prepared in the background as soon as the depend starts
		if the processes are kept synchronized as the new nodes do not appear in the forked worker
		yet another reason to keep everything textual so it can be streamed over

	it can also be prepared parallel (parallel with depend and build) (if forking is not more expensive)

	warp, after depend/build can be build in parallel as the graph is static
		rather than returning warp nodes, the workers could write file on disk and
			their format could be "cat"-ed together

	warp nodes should be used as is to reduce time transforming then back to warp nodes after revivication
		EG: no fiddling with the node data when serializing and de-serializing

remove package dependencies by matching them directly to nodes
	from pb1 code
	# add package dependencies to the node
	# package dependencies is sugar, we need to assign it in nodes to avoid triggering the whole
	# warp graph for a change that only impacts a few nodes


parallel depend and post build commands
	pbs1 runs all the depend in the same process/thread
	the node definitions belong to the main process till it's forked
	the node definition can be assigned a __POST_PBS_BUILD_COMMAND which is to be run after the build and before the warp
	__POST_PBS_BUILD_COMMANDS must be run in the main process

	if we depend in parallel we need a mechanism to synch the node definitions back to the main process to run __POST_PBS_BUILD_COMMANDS
		and to synch the nodes between the dependers

late dependencies
	check can't be done for every node after depend

	the depend and check step are separated in pbs1
	we can check in parallel in the check step but can depend a node and check it immediately because of late dependencies
		check is already done in parallel in pbs1

	late dependencies are dependencies that have no matching rule while depending a dependent, a separate part of the build system
	depends a late dependency making the graph valid

	if we were to check immediately after depend, the late dependency would not have sub dependencies (yet) and the check
	would be wrong

	late depend may be theoretically wrong
		the idea is that a sub module needs a dependency, say a library, it doesn't know nor care how it is build
		the top level over the sub module can decide to have the library as source or as a node to be build
		
		the right approach would be for the top level to add a depended library before calling the sub module
			and the sub module should fail if it doesn't exist 

		say the library is build by sub module 2 and needed by sub module 1
			with late dependencies it just works

			other wise we need to make sub module 1 depend on the library directly
				this is usually done by installing the library and configuring where it is so sub module 1 finds it
					this means building sub module 2 first rather than making a single build

				in any case the library must end in a location that sub module 1 knows, we can decide it's in ./libraries/lib
					now need to make sub module 2 put it there
						can we alias the nodes, before they are even depended?
							the top level can insert a node that's not depended in the graph

						ALIAS is used for the "target" of a subpbs run 
							we can't alias a specific node 
								well we can! inserted_nodes{alias} = inserted_node{whichever}
								but that's perl code not pbs code, not user friendly


				3 cases
					the library is installed, we want to point at it
						we want to make sure it is installed
							the node needing it would fail if it wasn't there, no rules to make it and not present on disk

						AddRule all => sub module needing lib
						AddRule sub module needing lib => ./libs/my_lib
						
					the library will be installed, we need to make sure it's installed first 
						IMMEDIATE_BUILD
						we can still use late dependencies

						AddRule all => ./libs/my_lib, sub module needing lib
						AddRule IMMEDIATE_BUILD ./libs/my_lib => ./sub module 2/path/path/lib
							ln  $dep1 %FILE_TO_BUILD

						AddTrigger sub module 2 => ./libs/my_lib 
						
					the library is used where it is build
						alias

						AddRule all => sub module generating lib, sub module needing lib (order doesn't matter)

						# if both modules already agree on location, we're done, late dependencies handles is
						# if not we need to point at the lib

						AddAlias ./libs/my_lib => sub module 2/path/path/my_lib # add both nodes to graph if necessary

						# nice, no need for installation

						# We could also pass the location via a configuration variable bu we would have no node in the graph!


history browsing 

	the time line is not based on when a node is build since the parallelization may schedule nodes at different times between builds

	note that it is a single build that is interesting but we should push the user to understand dependencies rather than build time

	at time zero (t0) we have a lot of nodes that are terminal and can be build
		that is the list of nodes that are of interest at t0

	that specific node is build at some specific time is of interest only if the dependencies are wrong

	finding a specific node, or specific nodes and being able to follow their build chain is more interesting than WHEN a node is build
		it is possible that we want to follow multiple node
		see what they have in common
		where in the graph they are relative to each other
		if they are parts of each other dependencies
		grep for dependencies and dependents (on command lines is even better than REPL)

		we must be able to generate a list of all dependencies from a node, recursively till we find terminal nodes
		generate the path from a node to another, displaying the information about rules that inserted each node (and a link to the nodes log)

	it is completely useless to have a REPL when the command line works better and is more flexible

	having the build information in the log is enough to follow the node build (from vi for example)

	the build time, build result, error due to sub dependencies not building, and which one (can be computed instead) is available in the log.

	pbs 1 stops as soon as a node fails building, it should continue generating logs for the nodes that have failing dependencies
		that's the equivalent to dumping the graph 
		can take a long time if 10s of thousands of log files must be generated
			can generate the file while depending and add data to the file (making it a real log)
				pbs1 has an option for that but it is not the same file as thee nodes build log
	 
	an old pbs1 requirement was to have the node in a database or in files rather than in memory, it seems that requirement, meso warp, and history are implemented the same
		the rules to generate the nodes, their config, โฆ  are themselves in files (the pbsfiles)
		nodes should have a pbs package information, pbsfile, target, start config, so it is possible to regenerate the node un memory as when global pbs is run
		all nodes in a package should point at the pbs package file as it is identical

	?should we keep the log and the digest together ? 

	We now have a lot of files that we use but don't verify, should the log have a digest or a way to be verified?


	use cases:
	file build failed, understand why

	understand dependencies between files when a build fails because of a missing dependency
		previous build succeeded now fail because a dependency has been removed that is needed


File system as the graph
	After depend is run (during?) It is possible to search the graph (grep, fzf, โฆ) and go through it (cd, cat, find, ranger, vim, โฆ)


pre-build warp
	when is it generated
	why are all pbsfiles re-run when   pre-build warp done but before warp generated

	see Meso warp


--node_environment
	display the environment variables active during the node build
		maybe in a separate file to not spam too much in the terminal
		=> in the log

	control env per node, per command in the node, per phase in the node
	inheritance of env from node to node
	package env is default for nodes
	env should go in the digest


text displayed with terminal control characters
	in pbs1 a control character is used to erase the previously written text and write over it

	some text will not be in the terminal because of this and that may make the debugging more difficult
		output is structured in pbs2 so everything will be in the log and it is the display plugin that is 
		responsible for using control characters
			eg: add control characters or not, pbs2 never does

long text display
	pbs1 use elision in some contexts
		--dd
		name of target of subpbs
		...

	sometimes we want the full name of things
		elision should be an option
		elision in some context only
			eg: --dd 
		elision on some paths only
			or not on some paths

graph display
	in text mode we need to be able to color the glyphss to show where they come from
		triggered nodes
		warp nodes
		merged build nodes
		...

	text mode graph doesn't show triggered graphs!

Information trees
	always present the information in the most logical order
	
	IE: displaying a trigger rule
		DEPENDER is of no interest
		NAME is not first

		trigger rule:
		โโ DEPENDER = CODE(0x558e27765d48)  [C1]
		โโ FILE = ./Pbsfile.pl  [S2]
		โโ LINE = 16  [S3]
		โโ NAME = T1  [S4]
		โโ ORIGIN = :PBS::Runs::PBS_1:./Pbsfile.pl:16  [S5]
		โโ TEXTUAL_DESCRIPTION  [A6]
		   โโ 0 = X  [S7]
		   โโ 1 =  blessed in 'Regexp'  [O8]
		   โ  โโ REGEXP = (?^:^\./y$)  [S9]
		   โโ 2 =  blessed in 'Regexp'  [O10]
		   โ  โโ REGEXP = (?^:^\./b$)  [S11]
		   โโ 3 =  blessed in 'Regexp'  [O12]
		   โ  โโ REGEXP = (?^:^\./bb$)  [S13]
		   โโ 4 =  blessed in 'Regexp'  [O14]
		      โโ REGEXP = (?^:^\./z1$)  [S15]
		  
pbs has many phases
	verify warp
	depend
	check
	build
	generate warp
	post build

reloading rule does take time
	Depend: pbsfiles: 100, time: 1.67 s.
	Depend: nodes in the dependency tree: 1901 [W:0, R:1901]
	Check: total time: 0.09 s.
	'PbsUse' statistic:
	โโ /home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Builders/Objects.pm
	โ  โโ LOADS = 100
	โ  โโ TOTAL_TIME = 0.034684
	โโ /home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Configs/Compilers/gcc.pm
	โ  โโ LOADS = 100
	โ  โโ TOTAL_TIME = 0.107334
	โโ /home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Rules/C_depender.pm
	โ  โโ LOADS = 100
	โ  โโ TOTAL_TIME = 0.078792
	โโ /home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Rules/C_EvalShellCommand.pm
	โ  โโ LOADS = 100
	โ  โโ TOTAL_TIME = 0.064047
	โโ /home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Rules/Compilers/gcc.pm
	โ  โโ LOADS = 100
	โ  โโ TOTAL_TIME = 0.054585
	โโ /home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Rules/C.pm
	โ  โโ LOADS = 100
	โ  โโ TOTAL_TIME = 0.445084
	โโ /home/nadim/perl5/perlbrew/perls/perl-5.28.1/lib/site_perl/5.28.1/PBS/PBSLib/Rules/Object_rules_utils.pm
	โ  โโ LOADS = 100
	โ  โโ TOTAL_TIME = 0.05924
	โโ TOTAL_LOADS = 700
	โโ TOTAL_TIME = 0.843765999999999

	=> let the user decide if rules are reloaded or re-used
		PbsUse vs PbsUseNoCache
		or global caching policy via a cli switch

trigger rule import
	in pbs1 an ExportTrigger is defines in a pbsfile, ImportTrigger looks for the function and calls it
		this has the advantage that we can do something special in the ExportTrigger sub
		
		declare rules as EXPORTED and let pbs create the ExportTrigger sub or simply scan the rules for an EXPORTED rule in ImportTriggers
		Exported rules are not called during depend if not imported

fzf
	completion via fzf, showing the help text
	--options which can be redirected to fzf
	documentation via fzf
	replace documentation module with fzf

layers
	warp nodes could be on their own layer
		this allows us to display graphs without the warp node
		we'd like to show the nodes that are directly linked to the new  graph (during warp)
			those are linked nodes

		we can generalize the system and make it possible to decide which nodes go to what layer
			via REH

			when displaying nodes from one layer in a graph form, we need to compute the minimal set of nodes  from other layer that are needed to make a graph

			? can nodes belong to multiple layers
				would be nice if we want to merge builds

	layers seem to be an attribute of the node (like linked or warp_node, ...)
		difficult to know if layers should be handled as layers or node attributes
		we can also add the node to a layer (push @layers, $new_layer)  even if the nodes have a layer attribute!

	can a node belong t multiple layers?
	do the node, existing in the different layers, be different from each other (aka just their name is the same, an other attributes similar is OK too)

how to show dependencies on pbs libraries, environment variables, installed tools
	if they were all dependencies to each node -tno would become unusable
		this happens already in pbs 1 when nodes are loaded from the warp file
		which puts them as dependency for each node to trigger in a better way

	we could have a "lib/env/tools" node, so we'd only see it once

	they could be in another layer of the graph
		we can chose which layer to show ... per node!


trigger start another build and makes the current nodes graph available
	importing graphs doesn't start another build

	is the order of trigger handling important
		if yes, how can we do that if we don't have any order for the normal dependencies?

the global build cache links back to graphs
	the idea was that each node get a UUID that completely defines them so other builds could use the previous build
		(it would be nice to have the attributes for th enode so we can make a partial matching, eg: some node but different compiler versions)

	if the global node also had its graph, we could load its graph in the current build


REH can add dependencies named dependencies
	the REH register itself as a depender and something else

	Rule something
		Matches
		dependencies => a b c
		named_dependencies => Frank => 1 2 3

		Builder => cat %NAMED_DEPENDENCIES_FRANK > %NODE_TO_BUILD
		Buuilder_two => some_file # some_file is  dependency but it's not declared as one

when building only one node a node number and percentage is added to the log
	why is here a difference?

log contains links to other files
	node dependent trees should contain link to dependent log so vim gf can open it
	also add links to dependencies log
	or any other file that is interest

log contents
	log build command
		so it can be run from vi, in terminal
	file names so they can be opened from vi
		libs, pbsfiles, nodes

node info generation
	can the generation depend on the pbsfiles md5 and thus may not need to be generated if already ok?

md5 request for C dependency cache are not counted in the md5 stats

assign color and level of verbosity to all the output classes
	we use colors right now
	to  support --quiet directly in the PrintXXX functions
		per class

	PrintXXX should be Print(XXX, ...) where XXX is the class corresponding to what is being done
		the class is set by the context instead for forcing the context to use an existing class

		instead for : PrintInfo(sprintf("Warp: total time: %0.2f s.\n", $warp_generation_time)) ;
			Print [class, class, class, could be a single string], ....) ;
			Print [WARP, TIMING, GENERATION], sprintf("Warp: total time: %0.2f s.\n", $warp_generation_time)) ;

		if the class doesn't exist, it's displayed in a color that makes the developer/user know that it needs to be set

		classes can be set from the command line, in the prf
		non_set class used to display warning can also be set, it's just a class like any other

	classes can be set during apbsfile run, in the pbsfile or by the parent



distribute the warp generation in the graph
	node generate their warp data
	pbsfile runs collect their nodes (who collects linked nodes)
	pbs collects the pbsfile runs

	leaving the data separated allows use to parallelize the reconstruction of the graph
		the reconstruction creates files containing reconstructed data (checked)
		
	it seems possible to distribute the creation via a warp rule matching everything

	the reconstruction also seems to be possible via rules
		actually a pbs run which creates a graph of already build nodes, to depend and build nodes

	another advantage of not collating the warp file is that distributed sub graph builds can keep their warp cache local
		warp can be returned as a sub graph with references to remote build system for the build
	

in warp nodes that are not to be rebuild are re-constructed
	we can't see which nodes are re-depended (only linked) because their package is loaded
	this information is interesting to show how much work is done in loading the pbsfiles that could
	be avoied if the node were not all together
		although the only work involved is linking
		visualization of re-constructed, re-depended, re-build could be interesting (although not as much as how many and where in text form)


Generate a log (like the build buffer) for nodes not build yet
	=> implemented as --lni in pbs1


	when a node fails, we may want to look at the dependents and their configs

	warp doesn't keep the information so -ni can't show them
	-ni shows all the nodes that are in the graph, not the nodes not yet build
		and easy option to add and a good information to show even when all nodes are displayed
		=> but -ni/-lni will display the nodes that are left to build, which is better

	even more reasons to distribute the warp data to meso warp
		?? should the whole node data be serialized?!
		including reverse dependencies?!

	the node data should be structured so it can easily be manipulated
		but how do we look at the build log in a text editor without the need of an external program
		write the external program!
		first section of the node data is the build log, as displayed

	what about pbs data? eg: pbs file chain

	=> practical after an error
		either generate with -ni manually 
		or when a build fail generate a node info for all the remaining node
			including which dependencies failed (this is only valid till the node is rebuild)

failed build should also be logged in a file

build priority
	node with most parents has higher priority has it may keep more cpus busy

	depth first vs width first
		depth build parents are much as possible, width builds children as much as possible
		cpus allocation is as high in both

build sequence, build triggering 
	in sequential build (-j 1) we use the graph to build a build sequence
	in parallel build we build a data structure where the children success build updates the parent till the parent children count to build is zero, we then start the parent build.

	using build event
		the build event is generated each time a build is done or by the check step if a node is already built
			=> this is already how pbs 1 does it!
		the event can be local or can be generated by remote build nodes
		or a separate builds (when we dynamically merge concurrent builds to reduce the number of builds).

		nodes waiting for children builds register themselves till their children build count is zero (and then de-register themselves)

		Note that this not different from the data structure (modified graph) that pointed to the parents
			we have moved the information to a different data structure, one that may be simpler to split and distribute

		Note that the data structure (node pointing to dependents) is a warp 1.8 equivalent
			each node child list should be serialized separately and the warp file generated from them

		Having the data serialized allows a more flexible management of the nodes
			The builders of the nodes may be functions that are not easy to serialize or which serialization takes too much time and space
				but we know where the builders come from! The pbsfile run with its initial configuration (given no rule are inherited)
					given that we know the dependencies, the config, the pbsfile, we could send them to other build node (having the same setup)
						for build
						we could also run the build system on the build node, so it has the same data and have it wait for a node name to build
							parallel builder does that except it is on the same node, distributed build need the same
							information, either by receiving it or by running the samebuild system

						=> cd project ;  pbs target --as_build_node ; cd - # poor man distribution! this how jenkins works, lol!

				we can recreate the rule for the node to build when its children have been built and start its builder
				pbs doesn't even have to be active, only the build phase
				no graph needs to exist
				This becomes a coordination problem rather than a build system generation problem.

		it's easy to pick a node to build, any one with child count zero
			we move the nodes to a location where only nodes with child count zero exist
			having multiple locations for nodes with different child count

		how do we handle build success and failure, and feedback?!  
			feedback is easy, we output a stream of information to the same place pbs would
			success doesn't need to be handled
			failure is handled by the event manager (just like in pbs 1)
				stop building, give feedback

			how do we handled nodes that build even if their dependencies fail
				REH_ON_ERROR, works because it's part of the node build

				REH_ON_DEPENDENCY_ERROR is part of a parent node which build may never start if nodes fail building and stop its scheduling

				What about generating a build_error event and pass it to the parents immediately
					what if parent has multiple children, what do we do with the children still building when a build_error event reaches the parent?
						the event handler can wait till all children are build, no_stop in pbs, before sending all events to parent
						the event handler stops all the node builds and goes in build_error mode, another build of sort
						the event handler passes the build error, when another child builds ok, the event is not propagated to parent

node log
	generated when the node is build, what if we want information but not build?
	
	we need to generate a log continuously and add the build info when building

	redundant info is OK if it is legible 

config node serialization 
	node have a digest and a build log
	configs have themselves and a history

	nodes point to a config, package or node config, the node log should point to the config log

nodes shared from cache 
	can be shared via inode linking, if multiple local build need them
	nodes are present only if needed locally
	the nodes to build could be put in a common directory (in a structure hash0/hash1/...) and the current build has a link to the node
	locally build nodes stay local but are visible in the global cache
	the cache can be remote
	nodes are identified by their digest
	no location information in the digest
	intermediate files stay in the global cache
	dependencies to needed nodes stay in the global cache
	cache entries, and sub caches, can be added an removed at any time
		knowing that a node existed but is not available can be useful for stats and cache strategies
	registering the local build generated node to the global cache is transparent
		local build put nodes in a local cache which can be made part of the global cache
			(oops artifactory but transparently)
		local cache connects to global cache, depending on local config)
	add metadata to cache nodes?
		retention time, build info(hmmm, njaaaa), ...


WAF: good presentation of what an automation framework does

build command (pbs) install:
	build command is an executable with no dependencies at all

build start directory
	 where is the build started
		what if I am in another directory?
		what if I want to build sub modules? from another directory?

DOT the root of everything
	. (dot) is the root of everything, what if I want another dot in sub modules? 
		aliases to depend a node that's named something else

context per rule, pbs uses a package context but can do a node context with node specific config
	how is node config inherited, should it?

function calls directly in the rule definition, possible but weird since the rule is not run when defined (except if the function is to create the definition)
	if the rule is a function definition (not a call to register it) then code can be inlined in it

removing generated files
	pbs doesn't at all but a user may want to know what's generated and what is source, and maybe implement "clean" on her own
	the graph doesn't even need to be traversed
		node_list contains them all, build_directory points at them, and IsNodeDigestGenerated, tells us which nodes are sources
		it's up to the user to list which nodes are to be kept, copied, run, ... attributes set on the nodes, via rules and custom REH, gives the user full control.


problem encountered with cmake
	guessing what and how things are installed, configured, or where they come from, is a headache


release/install target 
	the user tags the nodes to be part of a release
	the user adds a new global "release" rule at release time which uses the above tags (or decides itself which nodes to release/install and where)


	installing targets (different kind of targets)
		a node, created by a rule, that is depending on the build node, it's builder traverses the graph and copies (or whatever) the tagged nodes to some install directory. Since this is a user defined rule, there may be different rules that install a file in different directories. We want to know why a file has been installed. Maybe the best is to let the files install themselves instead for a top node doing the installation, the node installation can still be triggered by the top node but the lower level nodes need to match a rule to do the intallation, that rule we can track, that is the installed file itself is the target of a node

	tracking installed nodes
		rule, match A, install somewhere/a mean that a node install depends on node install/A that depends on node A
			the right dependency chain but a headache to implement and a nasty choice to make
			install depend step must wait for build step to be depended before it can run or
			install has a cache (like object files), if it doesn't exists install is run and the dependency cache is generated at build time by scanning all the node in the graph
		it's nice touch and uses the same mechanism as other types of nodes or
			the problem is that all the nodes have to be scanned, scanning 30_000 node to find 3 nodes is not very efficient, specially if the nodes themselves know they have to be installed, it would be better if those nodes registered themselves for installation (note that this doesn't exclude a dependency cache), but how do we register nodes for install when we want to use rules and that the install node was already depended with no dependencies as result. We want to re-depend the install node! with the rule added by the --install switch in the dub modules. I believe it's ok to redepend a node to add a dependency while we are not building yet (although that case is possible and should be taken into account), we already have nodes that exist in the graph and that have not been depended, those nodes can be depended later in other sub modules (late depend, a mechanism where we say I need node X and node X pops up later (hopefully)). there is little difference with Install node saying I need node ?, and node ? popping up later.

	install
		ask all node to install themselves with some configuration passed by the install node or install node does the install, up to the user


	node_a
		reh_install => name_of_dependent. will create a rule namespace, add rule install: install/node_a, add rule install/node_a: node_a, and re-depend install
		this way we get a chain of events that allows us to trace where installed nodes come from
		
		or it is a build info, information from lower levels send back to higher levels
		
		or nodes install themselves in a directory and the higher level just collects what's there, it's a bit like build info but dumber and simpler, not sure we can trace where the nodes are coming from; we could have an extra file with information but it is not like having rules that fire at the right moment.



release vs debug configuration
	 in pbs1, ifs in the config module, using one config namespace or the other, ifs in the pbsfiles
	can debug, release, ... be nodes? they are active during configuration, build, and install, or are they specific sets of config and rules included by --type options/global_rule? nodes/config/rules, ... should be tagged so their origin is clear, this is for any --option, not just build type (there is no such thing as a build type, just different rules and configuration). How do we merge/overlay nodes from different types of build? does this mean that reloading rules is better than global rules as one type of build can't give its rules to another type of build? Nodes with different configs/dependencies but the same name will co-exist in the same graph.

how does one start different types of builds at the same time?
	is it for different, possibly  distributed, builds to share nodes or to look at both build in an overlay common graph

 
pbsrun is a node that has a pbsfile, a config , and rule set dependency nodes

configure and build phases separated to run faster
	cmake, waf, ninja, all use this system (bad imo)
	pbs, when using warp, re-configures if it is necessary and only re-configures the part that needs it.

intermediary files
	interesting in the case their re-build would give the same result, when giving a build to someone, we can give only the targets (the nodes tagged as interesting to have at the end of the build) and source (which they can get from VCS) and the pbs digests. The other user will have enough to check the build and re-build only what is necessary. this is efficient in term of size of cache needed to be shared but the most efficient is to get all the nodes to never rebuild anything that already been built. if the cache is represented as a service (actually if the _checker_ can use a service or look for build nodes itself on other build machines), we don't need to give anything, just setup the checker. Pbs1 has a very simple mechanism where the build directory and local repositories are checked, this could be generalized.

Targets nodes 
	created by the command line and nodes tagged as targets
	nodes that the user want to have available in her local files_system after a build (see LOCAL in pbs1, and remember that nodes can exist in the distributed cache (and thus the build succeeds) but not locally.

transactions 4.3.2
  a transaction mechanism (shallow in waf, thus useless) to allow changes to environement (I guess not only config) and revert if there is a problem
  is it something that's needed in pbs2? isn't that already existing but with deep copy in pbs1 when a node is assigned a node config?

portable tools
	cmake has some crappy ones
	Perl has a full module of them, to replace thoses tools
	I think it's better to configure them for each os but if one wants to use portable ones they should not be part of the build tool, eg: no one stops the user to use the perl tool modules by configuring the tools 
		add_config SED => 'perl -Mtools -e 'run_sed'
	some good soul could write on of those configs for all the tools, with the associated module and installation procedure (a different project)

OS specific paths
	we need a command line tool to munge the paths and an function in the build tool ( preferably with the same name) which does the same thing ( IE: call the external command, even if it is slower it guaranties the same result)

Executing tasks before and after the build
	rule my_task : pbs_build ; target my_task # yohhooo done
	
	if pbs_build is automatically generated, have a getter for the name of the node
	
	this can be tested in pbs1 by replacing --post_pbs with a rule


Running the debugger for specific nodes
	a rule that matches the nodes (globally) added by a switch ( or in an included pbsfile)
	 when a specific step with debugging is to be run, start the step in the debugger instead for simply running it, the user is given the choice to stay in the debugger or leave it after the node. This is a bit of a bazooka to kill a mosquito, often a pause at the node and displaying the configuration is enough, if it is in a REPL, query other nodes is possible. Alternatively, a web based REP for the current build (or multiple builds if one can select which is accessible directly from the REP) could allow the same debugging without interrupting the build 

   
in-memory nodes
	not sure I like it but nodes for locally produced nodes
	nodes can be remote or a simple calculation that doesn't need to exist on the disk.
	The problem is that it becomes impossible to have a warp cache, how do we say if a node has changed or not if it doesn't exist?
	
	Note that intermediate nodes are removed by make and it still works; not sure it is possible to do the same with just a digest (not containing the nodes md5!)

coupling between nodes in the file system and in the grapk
	pbs nodes are just names who get matched to files during check step, in pbs the nodes can be anywhere, even in different file systems or networks

	pbs1 allows nodes to be just named as dependencies and left dangling for other steps in the build system to depend them
	pbs1 allows aliases (all subpbs targets are aliased)
	pbs1 allows trigger builds where a node in the current graph corresponds to another node ( can we do this nicely with graph overlay?)

locking the build directory till the build is done
	--build_directory does part of the job but there is no locking
	locking makes no sense, we should be able to build the same thing ( with or without config change ) at the same time
		but they should get in different directories
	
	WAF the locking is nice but it's half baked. How do we lock source files? how do we reuse node from previous builds (if we use a different directory) or even share nodes between concurrent builds? Node should get into a global cache and the build directories just link to the cache; the links don't even have to be to physical files.


build parallelization explanation
	concentrating  on how it is done, makes a documentation mess
	more than the build step can be parallelized

scheduling time prioritizing
	long running tasks can start first (doesn't pbs1 allow that too? node - __WEIGHT)

generating graphs of the current build step (for the paranoid)

Dependency on build tool, per functions, ...
	pbs rebuilds if the pbsfiles or pbs libs have changed
	but dependency on compiler (etc ...) is not automatically handled
		user can define an extra dependency but it should be very simple
			for shell commands, reminding the user that the command is not in the digest may help

	this mechanism can definine a dependency on a specific compile version or the operating system version

	for global dependency, eg: OS version, we need to add a rule in each pbsfile run
		we have a defined system to add rules via switches --os_dependencies but we may
		want to add it in the top file via "pbsuse 'os_dependencies'"
			it doesn't work if we are rebuilding a node in a subpbs directly with --load-config
			then it's the user's reponsibility

			note that "pbuse 'os_dependencies'" applies the current pbs run only, we have no way to inherit it

REH_EXPORT_RULE
	pbsuse rules that are not to be loaded in each subpbs but inherited
		then they should be exported down making it very clear what is done and where they come from

		AddRule xyz
			REH_EXPORT  # generates a warning, fills a history entry, ...

REH_EXPORT_RULE per rule
REH_EXPORT_CONFIG per config
REH_IMPORT_CONFIG per node
REH_IMPORT_ALL_CONFIGS per node

nodes with only configuration dependencies
	in waf:  was an example on how to add configuration in digests
	nodes without real dependencies? just virtual nodes? do we create a digest ;) ?


pbsfile in multiple languages
	snippet "binary", arg1, arg2, ... # free format, "java javafile" is a valid binary
	json_snippet "binary", some_json
	java_snippet "javafile", whatever

	the snippets return pbsfile code which is immediately evaluated as perl code, json, ... which ultimately returns some pbs commands (perl code)

	the snippets are added as dependencies, and snippets can return even more dependencies, rues, configs, ...

	there was a requirement stating that dependers, or any REH, can be written in any language, this is an extention where the pbsfile itself can be written in another language via specialized REH or functions (could we make the REH an function the same format)

	example multi language pbsfile:

		use "1" # perl use which can do anything a pbsfile can if it is run in the current package
		pbsuse "2" #can do whatever a pbsfile can do and is executed in the current package except if put in another package
		
		use pbs_bash # load specialized bash interface

		bash <<<EOB, config1, argument specific for the bash code # run bash code adn evaluate stdout in current package
		some bash code
		
		printf "AddRule from_bash, REH_BASH_DEPEND => "some other bash script", REH_BASH_XXX 0> this same bash script with oher arguments", REH_BUILD => "config1.CC", argument
		printf AddConfig "......"
		EOB

	this still is run by pbs but we could make pbs itself in multiple language
		when a subpbs is run, a target and some supporting function are given
			the subpbs doesn't have to be in perl or in pbs language it needs to return something that
			pbs can integrate in the graph (a sub graph)

			when running pbsf calls REH at specific phases, the nodes returned by the non perl subpbs can contain
			REHs that run code written in any language



Advanced examples
	build a compiler that's going to be used to build nodes

	in pbs, compiler is a configuration variable so it can be used in builders
	nodes that need the compiler have it as dependency
	dependency is added via a rule, the rule can be added by a switch
	the rule can be global
	the compiler itself has a rule to build it
	the target of that rule uses the configuration variable
	the compiler can be build in a different build system (possibly with the current configuration)
	the other build system can be triggered automatically
	multiple versions of the compiler can be build and used
	the compiler may be named differently, depending on config,  although it is build from the same code and compiler build system
	the compiler graph can be accessed
	the compiler graph can be merged to the current graph for display and query (and always for digest generation, as for any node)
	the compiler can be fetched from a remote node/server/...
	the compiler is either build or used as is it is found, in that case it becomes a source

	? is the compiler the value of the configuration variable or a node (with sub graph)? both?

	how do we transform a dependency (node) in something we can call

		# pbs 1
		Config CC => gcc_2.6
		Rule object_file
			dependency => "$path/$name.c",
			dependency => \&depend_source 
			build "%CC -o %FILE_TO_BUILD"


		Rule object_file
			named_dependency =>  [compiler => gcc_2.6],
			REH_SOURCE => "$path/$name.c", 
			build "%compiler -o %FILE_TO_BUILD"

		# above with sugar
		Rule object_file
			REH_COMPILER => gcc_2.6,
			REH_SOURCE => "$path/$name.c",
			REH_C_DEPENDENCIES, 
			build "%CC -o %FILE_TO_BUILD"
			
			# REH_COMPILER can be used multiple time to override the compiler, just like a configuration variable
			# REH_COMPILER can set itself to the default compiler in the system
			# REH_COMPILER can set the configuration variable, with comment and history
			# REH_COMPILER can verify the configuration variable and warn or bail
			# REH_COMPILER can be run in multiple phases, including when the command line has to be evaluated (although setting the config variable is enough)
			# REH_COMPILER can add the compiler as a dependency 


REH arguments
	pbs2 proto parses rules made of tuples REH => REH_argument

	REHs could say how many arguments they have
		this allows REH without arguments or with multiple arguments

		this can make debugging a bit harder just to make rules look good
			

	Rule something 
		REH_1arg  => gcc_2.6,
		REH_3args => "$path/$name.c", 123, something_else,
		REH_0args ; 

	Rule something 
		REH_1arg  => gcc_2.6,
		REH_3args => [ "$path/$name.c", 123, something_else ],
		REH_0args => [] ;  or REH_0args() 

	REHs can ask pbs if an argument is itself an REH
	
	?the biggest problem is that REH_0args is not valid perl syntax, even if we declared it as a function (which we do not want), it would still fail this:

		use Data::TreeDumper ;

		sub test {print DumpTree \@_, 'test'; 7}
		sub rule {print DumpTree \@_, 'rule'}

		rule
			a => 1,
			test , # test => 2 makes test a string
			b => 2 ;
		
	declaring a string constant works
		we also want to manipulate REH symbolically
			allows easier debugging, logging
			late compilation of rules

log file
	for each node a log file is generated
	the log should be structured, even if it only contains the output of the build tool
	extra elements (pbs config config, ...) should be in separate sections
	the node's digest coud be kept in the node
	pbsfile runs are nodes, with a log, and the meso warp could be in that "log" file


generate_ast
	it is not easy to follow the chain of dependencies when debugging even if the chain is not wide nor deep
	pbs has --tt --node_parents --node_parents ... 


REH registration 
	can be inline in the pbsfile (although not reusabe)
	the reh, can be applied in any step,
	its execution order within a step can be set relatively to other reh in the same sep, first and last are virtual reh used to place a reh relative to the begining or end.
	the sequence of reh executions in a step is validated so we do not have any priority problems.
		the sequence is logged in the node (already in pbs2 proto 1)
		it is possible to visualize the sequence of steps/reh_execusion without building

global rules
	means pbs adds them at every level

	GR can be added from command line switches, desc_extra, pbs, within pbsfiles (for all the pbsfiles after, withing the scope?)

	are GR
		added as text in each subpbs
		added in the current package and used in subpbses
		re-evaluated in different context

	information about GR origin are kept and displayed with high visibility

	if gr has associated code it must be reloaded in subpbses

	solution is to put the GR in a file and include it
		inlined GR can be serialized (we can also add meta data in the serialized file)
		switches that include GRs push the name of a file in the GR list

	GR can be selectively Applied, even from command line switches
		pbs --gr filename,regex,regex

		command line switches are aliases to --gr 


rule producing multiple targets at the same time


Textual output
	REH_VERBOSITY define different output message depending in the current verbosity
		the REH_VEBOSITY can be run at multiple steps
		use REH_VERBOSITY to 
			display all the output pbs normally displays
			generate logs
			progress bar info to the output stream (or not, they still are handled externally)...

		REH_VERBOSITY => phase, verbosity level, string # from that level up unless a most fitting REH_VERBOSITY exist
			best to not show phase in pbsfile

	--pretty-print
		content of the pbs display (progress bar or other) can be changed with pretty print option displaying only what the user wants


	Output elements
		each section
			can be associated with a display color
			section can belong to category (which has it's color, and be overriden. the color choice for any section can be computed at the moment of display by user code

	log output element
		log is just a normal output tagged with log, so external output processor know where to save it

	all the normally displayed information can be in different rehs and pbs adds a global rules to add all of them at once
		the rule is kept in a separate file

		add rule
			global
			match all
			REH_AT_BUILD_START => generate some output section 
			REH_AT_BUILD_COMMAND_START => generate some output section 
			REH_AT_BUILD_END => generate some output section 
			REH_AT_DEBUG_NODE => generate some output section 

		all depend on verbosity level

Global rule efficiency
	rehs that are applied to all nodes should be quick to apply on nodes
		EG: sort them and just apply them without running any regex (if that takes time, otherwise apply the regex)
	since every node is going to match these GR, node should point at them rather than have copies
	pointing at them should be done symbolically, by name not reference
	rather than storing all the GR, store the name in a global node section and always run it (optimization is the root of ...)


reh_short command description
	rather than display the build command, display a short comment
		 eg: gcc ccc abc ccc vvv eee fffff becomes compiling abc
	
	depends on verbosity level

	how do we override REH_AT_BUILD_COMMAND_START
		the override should be by specific node 
 

WEB interfacwe
	eg: gtg is send to the web server
	all the information stream is

	can we create a web REPL?


reh_needed_resources
	like jenkins node capability description, just an attribute
	can be used to reserve nodes for specific tasks
		the specialized pool resources should be made available when no more special node needs them

handle intermediate files a bit like make
	well, better than make 
	the choice of file removal can be left to the user
		 via a command line option with option for regex
			through a rule



bash completion
	commands taking arguments should get provide completion

	unfortunately the whole command line is not available so we can't analyse context

	plugins providing options should provide completion

	fix generated code to 

	my($trie) = new Tree::Trie;
	$trie->add(@completions) ;

	my ($command_name, $word_to_complete, $previous_arguments) = @ARGV ;

	if($word_to_complete !~ /^\s?$/)
		{
		my @possible_completions = $trie->lookup($word_to_complete) ;
		print join("\n", @possible_completions) ;
		}
	#~ else




handling of failed node build
	depending on the build some node may have less importance than other
		ie: doc build can fail but tests must pass

	parents of node, subset of nodes,  decide the importance of dependencies
		the nodes (with level of importance to be changed) may live multiple level deep in the dependency graph

		the higher level node must be able to catch a failed build  at the sub levels
			all nodes can catch sub node failures, scan the nodes to know why one
			has failed or ask the node directly

	Do we set REH_CATCH handlers after the dependency graph is build?
		this can't be applied on a node since it is not visible outside the package

		global rules could traverse the graph post dependency
			collect global rules while creating graph
			run global rules on the top node
				set global_depend_flag

			AddGlobalRule
				matches qr// # can match a node or pbs node (pbsfile, config, ...)
				dependencies => &get_dependencies_from_node
				REH_stuff we want to change

		desc_extra global rules are added automatically to sub levels
			AddRule --dd
				match
				REH
				GLOBAL

			are rules added to digest
				must as lower nodes don't include higher nodes digests (see pbsfile_path)

			what happens when linking a node
				does it have to have had the same global rule applied
					otherwise order of dependency becomes important

		
		AddRule(..., ..., GLOBAL) can be added by a switch
		pbs --pbsuse_global 'xxx' (see --gr)
			

	nodes can themselves catch a failure

		Rule
			REH
			REH_BUILD ...
			REH_CATCH

	? isn't this "--keep building"

REH_TIMER and REH_NO_TIMER
	possibility to add timing via rules
	
	the timer need to either wrap all the builder or to be run at the start and the end

	how do we time individual builders or build steps?

	can we use REH_TIMER to time the loading of pbsfile and where is the statistic gathered
		?REH_STATS 'where/how to save'

	display of stats can be via a rule applied on the root node
		? how do we display stats on a failed build
	 
	can TIME_OUT be applied the same way

		isn't TIME_OUT better as a wrapper?

		rule
			name => no_time_out
			...
			build => ...

		rule
			name => single_command_time_out_wrapper
			...
			TIME_OUT => 10, [ build => ... ]

		rule
			name => multiple_command_time_out_wrapper
			...
			TIME_OUT => 10, [ build => ..., build2 => ... ]

		rule
			name => global_time_out_wrappers
			...
			BUILD_TIME_OUT => 10,
			build => ...  


pbsfile is normal perl file
	running subpbs is, already, handled by a reh, one less thing to have in the pbs core

	packages, package configs and anything local to the pbsfile can be handled in a normal pbsfile

	global actions are more difficult
		options, prf, targets handling, colors, debugging, progress bar,
		statistics, indentation level, plugins, ...

		phases: depend, check, build, post_pbs
			maybe possible to replace them with rules

	possibly 
		use "pbs" ;
		use "reh_some_flavor" ;

	the pbs module can instantiate a singleton that does what pbs.pl does
		check the command line and include option_rules
			each option matches a file that is run to parse part of the command line
			non matching CL arguments are processed by a target "option-rule"

option rules
	have help
	parse the command line arguments an return 
		the rest of the command line
		text/rules to be run in the current package

	# this allows us to define options dynamically for debugging e.g.

	if option rules are called at each level of pbs
		and passed the current level
		they can act differently on each level

	example --dd option rule
		lives in options/-dd.pl
		parse command line (it is passed everything a PBS::Run is passed)
			return command line minus parsed portion
				can insert elements in command line
					eg --all_debug can add --debug_level1 --debuge_level2 ...
		handles --help--dd
		returns code to be run in the package
			debug option to show the code
			the code is a dependency for the run
				serialize it in the output directory
				the option rule code, that generated the pbsfile "injection" is also a dependency
		
		-dd has multiple types (call time type) so it can add a config when a node is created
			and display dependencies after a node is depended

	this mechanism can be used to implement rule injection
		create a new "option" which adds a rule, add it to the pbs call
		since options can take arguments, the injection can itself decide when to act

		as option rules are loaded at each level, they are add themselves as a dependency in the graph 
			they can also add whatever option is passed to them at the level it is used
			this makes warp trigger on the option rule implementation and options

	debugging uses rule injection
		we have spread debugging code around, instead DEBUG_REHs are run whenever a stage is run
		debugging rules can be added in pbsfile


		IE: in the  pbs code that inserts nodes we have a "if debug call all the breakpoints and see if one is of interest"

			that can be replaced by a rule added by an option_rule:

				pbs ... --display_insertion '*.c'

				which adds the rule

					Rule REGEX: '*.c', TYPE_NODE_INSERTION, code => if insertion echo node $node_name is inserted


				it's not different from option --dd, but adds a rule that's of type TYPE_NODE_INSERTION rather than TYPE_NODE_DEPENDED

		applying rule depending on context
			rules are added to a package and applied to all nodes in a package

			in some instances, eg: debugging,  we want to apply rules on specific packages, nodes, if an attribute
			in the node exists, depending on a configuration, if some node is in the dependency graph, ...

			rules need to be able to check the context

	"options" can
		add rules
		manipulate package configs
		add config rules
		run code
		access the graph
		access the package node

	option rules are 
		perl scripts (non executable)
			loaded within pbs during the run

		executables
			can be written in any language
			how do they communicate back?
				json/yaml on stdout

			example --default_colors option
				cat plugin/option/--default_colors
			
				#!/bin/bash
				printf "mine/text\n--color_define 'debug=red on_yellow'"

				alt:
				
				#!/bin/bash
				tail -n +3 $0
				exit 0
				some yaml
					here
			
code/rule injection

	see "option/rules"

	use cases:
		- from command line inject rule only in a specific package
			specific package or subpbs targets can be passed as an argument to the option injecting the code,
			including the filename to a fullblown config or even the source code of the rule


			eg: inject a rule to show the number of dependencies to a specific node at a specific level

				pbs --magnifier '{level: 7, regex: specific, rule_file: magnifier.rule}'
		...

	
	same mechanism can handle options, code injection, debugging, ...
		we just need to keep the dependencies right so a change will trigger a rebuild

	if possible implement code/rule injection with a physical file and PbsUse, this will add it as a dependency



target rule
	parse the targets, update the target "variable"
	start the build system

	if the targets are added as dependencies to the "package" we just need
	to start building the package, which we wanted to be a node anyway

	the package rule can be added by "use pbs;"

	"building" (maybe itself a step-node)  must be done after the rules are added
		and the configuration is build
	
	there can be multiple target rules

prf
	is an option rule that only adds options to the command line
	the options are read from the file given as argument
	
	pbs1 prf files are powerful (albeit restricted) perl scripts
		? remove that possibility or emulate it

colors
	part of the package->node config
		can specialize color per node type

	package->node configs are dislpayed with -nc during build but we don't want to
	see mundane config => filter them out
		see: structured text output  
		--nc is an option, a new option can be written to display whatever the user wants

	normal output is without color
		the color names are used (some pbs defined, some user defined)
		the colors are white on black

	--color
		option sets the package colors which are inherited

	--color_C_nodes
		adds a rule matching C node and setting special colors for them
	
	--color_define "name=defintion"

* debugging
	debugger
		not really part of pbs even though pbs provides special functions while running in the debugger

	breakpoints
		REH_DEBUG, matches all the levels
		stop in debugger
			nothing to do with pbs, except the starting of the debbuger
	
* progress bar
	output an update progress bar code for each build
		external filtering app, displays the progress bar

	see structured text output

display node info
	rule
		Global
		REH_display_node_info

* statistics
	Rule
		MATCHES type pbsfile
		REH_PBSLOAD_STAT
			type, pre-load and post-load
		GLOBAL

	Target pbs_load_stats
	
	Rule
		MATCH pbs_load_stats
		DEPENDENCIES => PBS_DEPEND_STEP or PBS_END_STEP


parallel depend phase 
	(these thoughts started with how we display the parallel depend phase and continues on how to implement it)

	for debugging, depend in parallel first then with a single process and display the indentation as pbs1

	a regex to display the depending of a specific node, or node and all its sub dependencies can limit which node are displayed

	triggering a specific node will display only that node's depending

	display node depend as node build
		the information about rules, triggers, ... displayed during depend are simply
		aligned to the left

		we can also display a progress bar

	depend display during parallel depend is still not simple to display

	depending nodes is not ordered like in pbs1, depend node, depend it's dependencies
		depend node, put the list of nodes somewhere a depend thread will pick it up
			this let us use the same type of scheduling as a build and even remote depend

		the current mechanism is efficient because the rules and package configs are already in memory but a node to be depended could be serialized and deserialized in another thread/process. if we keep the rules serialized, the serialization of the node is just its config and its matching rule.

	the output of the depend phase is unsorted, to display something we can use for debugging we must sort it
		we can  follow multiple nodes depend if each one is sorted in it's own stream

	depend log
		the output during the depend phase can be difficult to follow as a node depend is followed by
			its dependencies depend, the first node depend continues and al the sub dependencies have been depended
			when the next dependency to the first node is depended it's difficult to see what parent that dependency has
				? is it that important to know which parent

		the output could contain graph lines to help but that works only for smaller graphs

		the output background color could change with depth of depend, that's like graph lines

		the depend output of a node is written in a node depend log which can be looked at with an editor
			the sub nodes depend is not displayed but links to the sub nodes exist (build_name path + node name)

		the depend output for the whole graph is logged (pbs1 output)

		it is possible to crawl the node depend logs and generate a structured output (indented by level)
			the structured output can filter the node's depend output to a minimum and be decorate so one can jump from node to node in a text editor
			this is meso warp!

	fzf can be a great tool to use going around in nodes depend logs

	NOT RE-DEPENDING A NODE
		during depend in different threads/process/build_nodes, some nodes will be common dependencies
		we don't want separate depend nodes to depend the same node as it wastes cpu time
	
		first of all we should use depended nodes if they exist from an older build
		checking with a central location should be done in batch if possible, the depend process also gets a batch of nodes to process not just one  

*** THE GRAPH IS A BUILD CONSTRUCT ***
	we don't need a graph most of the time
	this allows us to spread nodes depend and build on multiple machine processes as long as the environment is identical (nodes carry their config and build instructions) 

synchronizing between build nodes (given they have the same (verified) environment) can be done with git/ssh (diff the remote nodes with local repo)
	the remote repo can be shallow

history of build
	time is defined by the dependency relationship, not by build time which means nothing!

	if the build log contains a time stamp we can put the node build logs on a time line
	the time stamp also contains the parents, or should it be the parents, time is not really important it's the relation between the nodes that describe the build sequence
	still nodes of equivalent build levels are build at different times (and on different build nodes, and can stay there, no need to copy them back

	We don't want to keep a dependency to dependent relationship, even on it's own layer
		we have the dependent to dependency available so we could build a reverse time line
			we can display the time line in reverse

		can this be used to schedule the build without having to keep the dependent information
			we use the information to increment the dependent count of dependencies left to build

			in any case this information shouldn't be kept in the node as we do in pbs1 as it is not a node data but a build data

Global rule

* indentation level
	mainly used during depend phase
		the depend phase does more than just find dependencies
			load pbsfile
				display when it starts and stops
			load pbs libraries
				do stats on it
			setup config
			trigger rules
			...
 
	indentation level is the depth of pbsfile levels
		pbsfiles have names
		some pbsfile can be called for different targets

	=> level is a path to the node: pbsfile:target/pbsfile:target/node
		we don't need to have an indentation level, the nodes name contains it

		an option can make the display indented or not

		the path to the node is the pbsfile path! node name can be different


		parent nodes give their path to their dependencies
		linked nodes get multiple parents paths
			but a node really doesn't care about it's parents, it has it's own config, rules, ...
				the parents paths are a layer of information needed by the build not the node

		
		the depth can also be a numeric node attribute rather than embedded in the nodes pbsfile/target path



* plugins
	add switches dynamically, problem with prf (see pbs 1 FrontEnd.pm)
	plugin path can be defined on the command line or prf after the switches that the plugin defines

		all this because pbs does the parsing of command line arguments using switches added by the plugins
		this, I believe, is a not a problem when the plugins parse themselves
			pbs runs the parsing (via the plugins/option rule files)
				if the command line is not consumed or transformed, there is an error
					if an option is not recognize because the plugin/option is not in the plugin path
						the plugin path option will add a plugin path and change the command line
							pbs calls the plugin/options again and finds them

* graph generation
	Rule
		MATCHES type pbs
		REH_PBSLOAD_STAT
			type, pre-load and post-load
		GLOBAL

	sub graphs
		Rule
			MATCHES type pbsfile
			REH_GRAPH
				type, pre-load and post-load
			GLOBAL

	graph option
		set a configuration variable in the package which is use by the graph node builder

* configuration setting and inheritance
	config is a node, its values are set with REH in a rule matching the node

	package
		add_config is equivalent to adding a rule

		get_config 
			!problem is that node exists after the rules are run
			add_config could create a node (with PBS::get_node) $package_package_config and run a rule on it locally
				is running a rule like immediate_build?

			get_config can then ask for the node and look for values
				better yet run a GET_REH which returns the value

				


		inheritance
			config nodes have a parent data entry

		
	node
		have a dependency config_node
			which can inherit from the node's parent
				would be nice if the inheritance was just symbolic (no real reference)
					easy to serialize, parent is just the name of the config node
					language agnostic, can be reused 
			which can be passed to dependencies
			which can filter the parents config node values

	sub pbs
		we want to override some of the config variables
		we want to pass multiple config nodes to the sub pbs
			normal node config
			pbs config
*warp
	warp, meso, ... all are targets
		added by switch

		need to run even if the build fails

*global artifact cache
	 not really part of pbs, it could be any mechanism on many types of cache

	one good thing is that it is possible to locate the artifact (including not finding one) with
	rules

	rule
		rehs ...
		locate_somewhere in the world
		locate_in_build_directory
		create_in_build_directory


	this allows us to implement ccache like  caches very simply


	pushing to the cache can be as simple as adding a reh to the rule
		
	rule
		...
		post_build_reh_push_to_cache

		# could also be node depending on the 


pbs builds nodes in differen overlay graphs


* post pbs
	also a target
	needs to be run even if the dependencies have failed


overlay graphs
	same build different variants
	different build overlayed later

	understand common parts of builds and differences
	without building know what parts can be reused and in which order to build different builds
		for maximum reuse, ie: build only part of what is common and wait for the other builds 
		to build the rest, distribution must be globally controlled to avoid race conditions 

	the same build could produce overlay graphs
		pbs nodes
		warp
		C files dependencies

		all valid grpahs on their own but of little interest during normal build

		the other solution is to have them in the main graph but filter out when presenting node
			this has the disadvantage to need code for each new type while overlay graphs are 
			not part of the normal graph at all
step nodes, pbsfile nodes, package nodes
	make all the elements nodes that are added by rules

	pbs can add the rule for the current package
	target add dependencies to the current package
	rules add dependencies to the targets
	configs are node which are dependencies to the other nodes
	
	depend, check, build can be seen as nodes
		build: check
		check: depend
		depend: package config
		package: targets
		target: rule generated dependencies
		config: rule generated or package generate


REH types
	reh can have multiple types so they are called multiple times
	how can we make a reh (in a matching rule) run when another rule matches
		e.g.: --dd needs to show dependencies when any rule matches
		? add a node element handler (NEH) (via a rule and a REH type) and each time a node is used
			(in any step, trigger, check, build, build step, ...) call the NEHs that match the step


	what did pbs_use do that use can't 
		adds the required package to the current package dependencies
		load time statistics

rule component can be shell scripts, service via rpc or http, ...
	rule name, regex, depender, builder, node_sub, ...
		perl dependers have access to everything, that's difficult when the depender
		is an external command. 
		
		we can chose some data and either pass them as arguments or serialize them in a file

		the great advantage of REH is that we can have different REHs depending on how we want to call the external code

		the REH can be given a command name to run and that command can be an executable with a shebang
			external command can be written in any language

		REH pointing to a language and give code is possible too
			REH_CMD_DEPENDER 
				language => Python
				code => some code 


		which takes us to other languages to write the pbsfiles
			given that REH are not built in but included, nothing stops one to load language
			specific REHs

			use 'perl_reh' ; # with the possibility to filter what reh and change their name

			Rule
				Regex => /must be perl regex/

			use 'java_reh' ;

			Rule
				Regex => /must be java regex/ 

			making pbs a REH tunner and nothing else

			=> of course there's more than writting the REH in other language for good support
				the possibility to define variables, includes, ...


	can AddRule be a REH?
		rule name needs to be a REH to be handled in another language
		
		Merge AddRule and REH_MATCH
			AddRule
				NAME         => 'first',
				Match        => /regex/,
				Dependencies => qw(x y z),
				Builder => 
					[
						'do something' ,
						'do another thing'
					];
  

			Match /regex/ =>
				NAME         => 'first',
				Dependencies => qw(x y z),
				Builder => 
					[
						'do something' ,
						'do another thing'
					];
	
			Target /regex/ , qw(x y z) => # target is AddRule, Match, and Dependencies at the same time
				do(
					'something' ,
					'another thing'
				);
	

? stop mandating NAME
	naming has the main advantage of forcing the user to think about what she's doing
	debugging gives the file name and the line, and could print the rule, matchers, ...,
		reducing the need for a name

	REGEX is also mandatory but why? if you forget the regex it will not match (siso)

	some elements are set by pbs2 like DEFINED_AT_FILE
		can't we let the REH handle that so the pbs engine doesn't have to?

Target-specific variables
	are considered harmful by other make implementations: kati, Mozilla pymake.
	Because of them, a target can be built differently depending on if it's built standalone, 
	or as a dependency of a parent target with a target-specific variable.
	And you won't know which way it was, because you don't know what is already built.  
		=> this means the node config has to be added to the digest
			we do that for some variables for object files, a generalized mechanism to chose which variable is needed
		=> pbs checks configuration variables when linking nodes

let user define log level
	use relative level, ie not a fixed value but relative to already defined levels (text without value)

intermediate files
	no such thing in pbs since we need to have a digest for any file that's not a source

structured text output
	output structured object (yaml|json|perl) natively and let external application transform the output for the user

		pbs ... | special_pager
		pbs ... | html_data | nc ... ; pbs_web ... &
				pbs_web can keep sessions, have timeline, ...

	multiple external programs can be chained

		pbs ... | tee >(nc to_server) | show_depend | show_build | show stats
		
		the external program can either consume the data or pass it through

	pbs has it's own structured text transfoms that are applied
		if no other are defined
			via a user defined switch  
		or disabled
		or own can be displayed on STDERR while structure text is written to a file descriptor (user defined)

show current directory when executing commands
	--pwd

	we can also add the cwd to thwe structured data


work flow primitives
	on_error
	or_build
	and_build
	try_catch
	! parallel => everything must run parralel, one can use a dependency to synch if necessary

	distribute
		to heterogen nodes, with synch, timeout, re-try on a different node

Interactive build/ kinda REPL except it runs in or around the build

	given a dependency graph, do interactive steps for debugging and recording
		close to debug mode but rather than running in a debugger user runs in an 
		interactive shell.

		INTERACTIVE_REH => 1
			BUILD => [shell command 1, shell command 2, ...]

		at each command start a shell, with the command inserted, and let the user control the command
	
	save the session to create build commands from it

	interactively add node to graph
		building node_1 the user realizes that a dependency must be build first
			add_node $current node dependency
				adds the dependency and takes user to the node build where
				commands can be added
	
	if we could record the state of the file system (hu hoo docker!) we could go back and 
		forth in the build time line.

	
PBS2 
	AddNode adds by name
		creates node if necessary and adds it

	we should be able to give already created nodes (eg: from cache or other graphs) to AddNode

	node and node content can be separated


matching urls and other objects
	rule 'name' matches some_URL, just a node in the graph, doesn't matter if it's an url or not
		depend on nodes which themselves can be as remote as this one or not, again just a node name
		checker the digest for the file, which may be on another machine
		builder, can be local or remote, pbs doesn't care as long as it gets a digest
		digest generator computes digest of not

	checker and generator could be the same code
	

	alternative: url is just an installed file
		url/file depends on file
			checker checks the remote file
			builder copies dependency to remote
			digest returns the digest of file

		file depends on local dependencies
			builder


	if the object type corresponds to a set of specialized depender, checker, builder, digest generator (or a subset of them)
		we can wrap those REH in one of
			Specialized add rule
			Specialized add REH


		AddRule
			name => *.special
			depender => special_depender
			checker => special_checker
			builder => special_builder
			digest => special_digest_generator

		AddRuleForSpecial
			name => *.special
			reh => ...

		AddRule
			name => *.special
			special_REH()
			reh => ...

		*** all user defined
			but depend, build, check, digest must be overridable

		Best would be that AddRule adds the default depend, build, check, digest (making AddRule a user defined function)
			overriding any of the base REH can generate warnings, log, whatever the REH want
				How does the "default" checker REH know that it has been overriden?
					Does the overriding REH manipulate the REH list?
					Is there a single slot for checker REH? or builder REH (although we already want multiple build REH)
				Do we need to allow the REH to check the REH list? 

		Addrule is in a module that needs to be pbsused

		top pbs just runs the top pbsfile

shorter rule syntax
	AddRule
		NAME => 'the name',
		REGEX => "some_regex",
		ACTIVE => 1,
		COMMENT => "some description",
		REH_WHATNOT => 1

	Rule 'the name', MATCHES("some regex"), IS_ACTIVE,
		COMMENT("some description")
		REH_WHATNOT => 1

other rule syntax
	do we need Rule?
		? any REH adds a rule till ; is found
			not possible with fat comma

	functions with the same names as REH allow:

	Rule 'this rule',
		MATCH => "some regex", 
		COMMENT => "some description",
		REH_WHATNOT => 1 ;

	MATCH "some regex", 
		COMMENT => "some description",
		REH_WHATNOT => 1 ;

	COMMENT "some description",
		MATCH => "some regex", 
		REH_WHATNOT => 1 ;

	DISABLED 
		MATCH => "some regex", 
		COMMENT => "some description",
		REH_WHATNOT => 1 ;

command to add non active rules
	Rule 'the name', MATCHES("some regex") ; #ACTIVE
	
	Disabled 'the name', MATCHES("some regex") 

can REH add REH in rule or do we wrap the addition of REHs in a normal function?
	
remote file syntax
	all files are local, how do we describe and access remote files

		service:server:/path/file
			service scp, webdav, http, ...
			credentials (and the dreaded key ring)

		virtual file or state
			eg: entry in DB
			not different from service:server/ ...


		difference with local file is that the signature must be computed differently
		pbs dependent doesn't care a node just a name


		Rule 
			Match(/$URL)
			REH_COMPUTE_SIGNATURE(any code/pre existing code reference)
			BUILD

		
		Rule
			match_ssh_file $server_file, credentials:xxxx
			# this also adds a REH_COMPUTE_SIGNATURE to the REH list

			# much  easier to have match_ssh_file return a list of REH rather than be an REH

REH_COMMENT
	(maybe backport to pbs)
	display the comment when the node is build
	comments could have level, like a log, and be shown over a threshold
		threshold should be dynamic

pbsuse
	does it look in the pbsfile directory or just in the include paths?

	it's not scoped within a rule (do we want that?)
	the include path are set on the CLI
		can be hacked via pbs_config but it's  hack
		needs a clean interface, with warnings, and scoping to local pbs run

	warnings (option?) if multiple files with the same name exist
	
	can we generate the libs dynamically?
		use case? (we have the mechanism to generate pbsfiles dynamically)

	modules are assumed to have a pm extentsion
	full path modules are handled but ./module is looked for in module_path not root

REH_ON_FAILURE

hardware failure
	on large clusters failure is inevitable
		how do we detect and differentiate hardware failures from build failures?
			how do we restart the part of build failing because of hardware?

text mode, data oriented
	node and node group orientd
		textual data to describe the node

	work on a local group of data text files

	distribution of processing for large data sets

	small utilities (unix style)
		check_digest
		...

remote debuggers
	possibility to run shell builders in a debugging shell
		eg:
		AR  .....
			name
			builder
				shell command 1
				shell command 2

		pbs -interactive_shell IP -name 
		
		when shell commands are to be run, a list of commands is displayed in
		the client's shell window
		
			the client can be on a different machine, thus we need to ssh back

	running the build system (or part of it) in a remote debugger

how to handle no memory in very large builds
	separate the different phases to reduce memory usage
	put nodes in DB
	on demand node loading/unloading

interactive repl, scons .98
	once the graph is created, the repl allows one to build repeatedly
		is the graph hashed at each build?
 
limit parallel build based on resource usage 
	eg do not schedule while load is high

multiple node created by a single build command

	Match(pat1 pat2), BUILD(...) 
		means both nodes are build by BUILD
		but there is not relationship between Macth and BUILD

		in pbs it is TWO builds and we try to  remember that one of the node
			was build and the second one is not run
			problem, it doesn't work in parallel, it doesn't work for multiple libs, ... 

		see the gnu make book ~ p94

	BEWARE of parallel build where process don't share data (pbs1 fails there)
		which means that we need to check if the node was already build via the file system!

		BEWARE 2 even if we use the file system sentinel 
			the processes may be NOT running on the same machine (distribution)
				can only be fixed by a common build database but complicates unnecessarily
				and is much slower and gets slower as we parallelize more

			even on the same  machine, two nodes may check for the presence of the sentinel
				at the exact same time
				this can be fixed by making the nodes depend on the last node thus forcing
				the last node (and the sentinel) to be build first
	

	AR BUILDS(regex1, regex2, ...), BUILD_MULTIPLE...

	regexes are ANDed

	BUILDS runs at depend AND build stage to link them together
		we can "tag" nodes as "build together" and act accordingly

	BUILD_MULTIPLE is a specialized BUILD


REH can be run at multiple stages

REH run order is defined by saying which REH are run before or after
	this lets us check at compile time if the REH sequence is valid

variable dependencies
	in pbs dependencies to variables are handled through a set of commands
		AddVariableDependency, ... and equivalent commands that act on uniq nodes

	REHs can replace them
		global REHs are added in a rule that matches globally 
		node REHs are added in the node rule or a rule that matches a specifi node
			node REH can remove gloabla variable dependencies
			
			config node REH can take a script as argument for complex cases
	
	this unifies the handling and reporting of dependency listing with the handling
	and reporting of digest entries


	in other build systems this is usually done by remembering the command used to build the 
	node, if it changes it has to be rebuild. In pbs  we decided that it didn't have the right
	granularity, what if a file location change, if an argument doesn't change the output, ...
	
	we also want to build nodes with multiple commands and even, maybe with builders defined
	in multiple rules

	this put a burden on the user which can be lightened slightly
		warn if a non dependency config variable is used in a build command
			separate commands to declare variables that are not part of the digest
				this removes the warning
	
	the user may want to depend on the command line and not bother with declaring variable dependencies
		Rule match((), dependencies('*.c')
			build("%CC

multiple rules builder
	a warning is displayed when multiple builders are used
	warning end up in log (all warnings should)

	they allow better rule and build granularity (specially if the rules can be composed from a pre-defined REHs)

		rule regex '*', REH_CREATE_DIR

		rule regex X, REH_CREATE_and X


	a builder REH can
		check if other builders have been run and fail
		can run only for a specific condition
	
	can rules say in which order the builders are run?
	can REHS decide in which order they are run, or after/before which other builder they should be run?


--dd, ddl, ddr
	often followed with --tno
	ca we present --dd as a tee to start with ?

use case
	Rule V all_tests: test1 test2

	# we want the tests to be run in individual directories and in parallel
	# they can't be in the same directory because they use the same input files
	# which must be different for each test

	Rule V ^test*: sub_dir*/test* @dependencies
		cd sub_dir*/test
		run the test
		
	Rule sub_dir*/test*
		mkdir %FILE_TO_BUILD


generalize the concept of object_files
	a sub target creates a list of information to be used at a higher level
		eg: a list of oject files to be linked
			the concept was created to reduce the time spend creating
			intermediary libraries

	command line utility to manipulate the object_files
	%EXTRACT to manipulate the object_files in the build commands
	change name to reflect the generic nature

	another case could be a lib that returns
		a lib
		the  location of header files

		my_stuff: informative_lib



		informative_lib: @c_files
			%cc @c_files
			object_files %FILE_TO_BUILD add LIB %FILE_TO_BUILD
			object_files %FILE_TO_BUILD add INCLUDE_PATH somewhere/ ....
			...
			
easier named dependencies
	by common prefix?
		t: dir/a dir/b another_dir/c d
			command %MATCH(dir/, %DEPENDENCIES) # lol, this is gmake macros

check gmake debugging options
	database dumo
	variable definition file:line
	--warn-undefined-variable
	...


multiple versions of the same node in the graph
	is it really worth it? 


%FILE_TO_BUILD short versions
	a la make $@
	%FTB
	%TARGET

	the build time variables should be in the config too to allow easier debugging
		they are computed per line run in a shell, not at the build start!
			users can define their own!

	in any case they should be visible for debugging
		there's an EVAL_DEBUG switch bit not sure it works on user defined %VARS

pass arguments to prerequisites targets
	a: setup(a, a1, a2, ...)
	b: setup(b, b1, b2, ...)

	setup:

	if setup is a target, it will be run just onece

	it is possible to have multiple targets by using
		%setup or setup%
		but this runs the same setup when we want to run different setups

	we can define a function and call it
		a:
			 setup(a, a1, a2, ...)
		b:
			 setup(b, b1, b2, ...)
		but it doesn't show the prerequisite nature 

matching a rule, run one time
		when all match?
		when a single one matches?

templatized output
	eg: output for when a node is build (-bni) corresponds to a template that the user can modify
		access to basic element/color, and options, are provided

		a bit like the code that does the visualization but elements are computed and made available to user
			may be less efficient

		we can start by using templates internally and moving display code to plugins
			note that node visualization is already a plugin
		
		breakpoints + bni + bnir 'no_match' is a workaround
	
	the templates should use functions that can be used in post processing
	the templates themselves should be run on node
		say during post processing or debugging I want to see the same output as during the build
			fill_template(node, template, args)


output is by default off
	opposite of -q, we need to ask for output
	output is often necessary during creation of the build rules
	output is needed when a node fails to build
		and only for the node that fails and its dependencies
			and we can generate dependency node output on demand
			if we need to see the output of the successful nodes, if not kept),
				we can build those nodes

Microwarp composition
	as the warp cache is composed of MW, multiple configuration can share the nodes
	can we check them in?
		this would give us a history of the dependency graph
			it would be nice if the system history was also under version control
				difficult to force devs to checking code when doing local builds/tests
				the nodes hash is kept in the dependency graph
					we can find which version of the source repo is used
						or if it is a local version

	
	multiple MW can refer to the same node
		but MW are the dependency graph of a node, can a single node have multiple MW?
			IE, can different tools generate a dependency graph for a node and it's the sum of all the MW
			that is the complete dependency graph for the node

log is not generated
	the log contains node information and build time information (including output from the tools)
		no need to keep tool output for node which build succeed

		better to generate a log on demand from the dependency graph and build time information
			see templatized output

		possibility to generate a single node build environment for debugging

		

REH_BREAKPOINT
	a bit like a pbs1 breakpoint, called back on events
	REH_EVENT?

	possibility to alias the name and arguments easily
		REH_ON_BUILD => REH_EVENT(TYPE => 'BUILD', POST => 1, PROCESS => sub { ...})

REH_USER_TARGET
	"targets" target which queries the registered rules and displays the user targets
	https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html

REH SHELL and ENV
	as ENV is stripped off we need a way to bring it back for applications 
	running under some SHELL

	setting ENV is done by rules which allows us to selectively apply ENV to a 
	node build

	there is a need to control which rules set environment variables (the same need
	we have to control which rules bring which dependencies, also a node
	environment control problem) 
		how to define node environment and what rules are active within it
		how external environment impacts the node environment
			in pbs rules are controlled by running in a specific package
			but that separated parts of the graph not the nodes within that
			part

			still in pbs (without --neo_config) configuration are global even
			if they are hierarchically inherited

		how to visualize the rules changing the environment
		how to control the of the interaction between rules
			how one rule can stop other rules
  
	

Create a clear display framework
	in pbs, redirection is in multiple files to handle multiple options
	it is difficult to change and get an overview of

Move dependencies to __DEPENDENCIES

graph generation, node display filters
	per node
		rules decide which nodes get which filters, this is not part of the pbsfiles (but can be)
		but use the same mechanism, eg: the nodes, even if they already are in the graph (depended) get
		subject to a set of rules that define how, and if, a node will be be displayed

			if part of a subpbs, graph rules work as node subs and save data in the node

		

		the rules also create, one or more, graph nodes where the nodes are inserted,
		this allows the creation of multiple graphs
			do we add a target for the graph generation or create graphs directly?

		
		the graphs can be rendered differently, eg: table, CSV, image, ...
		
		nodes can belong to multiple graphs and be displayed differently in each one


		eg:
		
		PBS_ROOT: graph

		graph: root_node
			create_graph
		
			


target naming
	given the rule:
		A => B, C(A)

		where C, it's name, depends on A's name
			ie '*.lib' => tests, *.module1

		if B also depends on C
			B => C(?).test

		how do we propagate A's name?


	this is because the rules are completely separated, they should be or we would not be able to
	reuse rules

	this has been implemented this way in the passed:
		my @modules = qw( module1 module ) ; 

		# we can also get the modules from a configuration
		AddConfig MODULES =>  'module1 module' ; # keep them as text
		my @modules = split /\s+/, GetConfig 'MODULES' ; # which can be hidden behind some sub


		And then rules added:

		AddRule *.lib => tests, @modules ;
		AddRule tests => map {"$_.test"} @modules ; which can also be hidden behind a sub


		with syntactic sugar where no variable is used:
		PbsUse 'sugar' ;  # define get_modules and get_modules_tests

		AddConfig MODULES =>  'module1 module' ;

		AddRule *.lib => tests, get_modules('MODULES') ;
		AddRule tests => get_module_tests( 'MODULES') ;

		# the above has the asdvantage of hidding all the details and keeping it Config and Rules only

		it is also possible to replace both rules by a meta rule:
		PbsUse 'sugar' ;  # define AddModuleRules

		AddConfig MODULES =>  'module1 module' ;

		AddModuleRules => 'MODULES' ; # looks like a module but is a rule wrapper

		we can even make it a one shot config + rules wrapper
		PbsUse 'sugar' ;  # define AddModuleRules

		AddModuleRules => 'module1 module' ; # adds config, adds rules


 		There are differences between the different solutions
			details are more or less hidden
				but it is still under the users control

			in the sugary solution, the rules and configurations are not created in the pbsfile
			but in the lib file, that's what pbs will report, except if we force it otherwise

			

		* Aternatives *

		* export the TARGET for the rules
			! a very bad idea, rules coould be far down the chain and would have to know about other
			rules


		* create config variables before running rules
		PbsUse 'ModulesConfig' ;

		AddConfig MODULES =>  'module1 module' ;
		AddModulesConfig 'MODULES' # Adds in the config everything a module needs
						# MODULES_PATHS => 'module1/module1 module2/module2'
						# MODULES_TESTS => 'module1/module1.test module2/module2.tests'
						# AddModulesConfig is verbose about the new variable creation

		AddRule *.lib => tests, GetConfigSplit => MODULES_PATHS ;
		AddRule tests => GetConfigSplit => MODULES_TESTS ; 
		

		or 

		PbsUse 'ModuleConfigs' ;

		AddConfig         MODULES =>  'module1 module' ;
		AddModulesConfig 'MODULES' ; 

		AddRule *.lib => tests, GetConfigSplit => MODULES_PATHS ;
		AddRule tests => GetConfigSplit => MODULES_TESTS ; 

		# pros and cons
		pros:
			very simple, no modifications of the API, flexibility for the user
			everything ends up in the configuration which is visible with --nc/--bni
			config locking/override is already in place
			rules are added in the right pbs file

		cons: 
			everything ends up in the configuration!
				the configuration is passed to levels below
					may be a good thing
					may be made LOCAL


Language independent builders
	when possible transform perl builder in external perl builders
		take the code and put it in a bin directory 
		if the builder accesses internals, split the builder in a builder that writes
			the needed information and a builder that is a shell command
		
			this has the disadvantage of starting a new process

	use inline::Language and keep the external language in the pbsfiles
		how easy is it to debug then?

Setting up paths for binaries under the build system control
	if the build system has a set of utilities that are used to build, add the set's path
	to $PATH before running the commands

		this removes the need for the build system users to change $PATH



	

Binary repository layer
	rather than as if a specific file has an md5 on the repository we should
	ask if it has a file with that md5, it doesn't matter where it is

	repositories can send a patch over the list of previously available artefacts to reduce traffic

	the artefacts are needed locally only when a dependent has to be build

	a node that needs to be build does not need to be checked with the repos

	feels close to what warp does except we need a physical file rather than a pseudo node in $inserted_nodes

	if a node needs to be build, it doesn't exist or a depdndency has changed, we can still find it
		using it's dependencies and config as a hash

	

in large project, digest files take a significant time to load (1s :) ) can the size be reduced?
	C includes are repeated many times

Can we get the nd5 of a sub? of a closure?

PrintDebug2
	we need to have a color tag at the beginning of print output to be able to differentiate
	different entries in the same category
		PrintInfo
			what kind of info?
				if we have three categories then it should be made clear
					print output to be able to differentiate
	different entries in the same category
		PrintInfo
			what kind of info?
				if we have three categories then it should be made clear
					aprint output to be able to differentiate
	different entries in the same category
		PrintInfo
			what kind of info?
				if we have three categories then it should be made clear
					โ โ โ 
					each โ gets colored 
					alternatively the catagory name is displayed
--display build result displays result for each builder element

Warp verification message
	display some statistics about the types of nodes in the cache in verification message
	make display single line

		Warp load time: 0.06 s.
		Verifying warp: 3801 nodes ...
		Warp verification time: 0.14 s.
		Warp total time: 0.20 s.
		Warp: Up to date.
		Total time in PBS: 0.23 s.

		Warp: UP TO DATE. 3801 nodes (1400s, 1600g, 801p), load: 0.06 s. verification: 0.14 s
		Total time in PBS: 0.23 s.


wrapper to check test result
	AddRule :Name(test)
		Is("any_command arg %arg", regex)	



bash completion should be done by pbs as some options are loaded at run time
	wrong, the options are loaded after the application is executed so we don't
	know what will happend in the completion script if we do not run the current command line
	which is prohibitive for completion purpose

warp, on pbsfile different => need to rebuild everything
	because warp doesn't have pbsfile-nodes dependency? see mini warp


Add a mode to depend as little as possible, IE no C dependencies cache, no checking sub nodes if top node needs to be rebuild, ...
	generate the dependency graph after building if the information is available

--no_warp creates warp file even if it doesn't use it

how much more time does it take to create a warp 1.5 and 1.8 compared to only warp file 


declare possible top target in pbsfile
	allows us to scan all pbsfiles (what files?! pbsfiles can be called anything) to find targets
		 - can help the user decide what target to build or where a target is build

	we can cache the target names in warp

	target can be  pbsfile tag or a reh
		1/ Target(something)
		2/ Rule :NameMatch(/xxx/), :IsTarget ;

pbs/subpbs return a miniwarp
	there is no reason to give the top part of the graph to subnode 
		linking to existing node?
		better encapsulation of sub level

	the pbs serialized the miniwarp
		calling pbs can ask for a live sub graph

	calling pbs has to link nodes if they exist in the graph
		if same node and config
			otherwise we have conflicting configs

	create check file/build sequence at the same time as the creation of the mini warp
		we can parallelize the check 
		nodes in mini warp build sequence must be tagged if they are terminal
			we don't need to compute it that in the parallelizer if it is already done

	returning a warp file + check/build sequence means that we do not have to keep the live nodes 
	in memory
		NOTE: the build sequence is warp 1.8 first level dependencies, up to the calling pbs
		
		we can create w1.8 first level on the fly

how do we detect circular dependencies if nodes are depended in different process each creating
	a graph that is not circular
	
	we can run a check pass on the dry graph just for that, same as today but much lighter

	we can merge the build sequence and if a node is present twice, we have a cyclic dependency

	use tsort

work out the user help vs the pbsfile help
	=for PBS 


sub options set the parent option
	IE: --ttno needs --tt on the cli or it will have no effect

	writing --ttno will automatically set -tt

	if parent option needs an argument, display error message and stop

display options as a tree when -h is used
	category
		sub category
			top option
				sub options
	options
	โโ help
	โ  โโ -h|help = Displays this help.
	โ  โโ -hs|help_switch=s = Displays help for the given switch.
	โ  โโ -hnd|help_narrow_display = Writes the flag name and its explanation on separate lines.
	โ  โโ -generate_bash_completion_script = Output a bash completion script and exits.
	โ  โโ -pp|pbsfile_pod =
	โ  โ  Pod declared with "=for PBS =pod_formating title" is extracted when option is set
	โ  โ
	โ  โ  =for PBS =head1 Targets\n"
	โ  โ
	โ  โ  =item * all
	โ  โ
	โ  โ  =item * debug
	โ  โ
	โ  โ  =cut
	โ  โโ pod
	โ  โ  โโ -d|display_pod_documenation:s = Interactive PBS documentation display and search.
	โ  โ  โโ -pbs2pod = Extracts the pod contained in the Pbsfile (except user documentation POD).
	โ  โ  โโ -raw_pod = -pbsfile_pod or -pbs2pod is dumped in raw pod format.
	โ  โโ wizards
	โ     โโ -wh|display_wizard_help = Tell the choosen wizards to show help.
	โ     โโ -w|wizard:s = Starts a wizard.
	โ     โโ -wi|display_wizard_info = Shows Informatin about the found wizards.
	โโ colors
	   โโ -no_colorization = Removes colors from output. Usefull when redirecting to a file.
	   โโ -c|colorize =
	   โ  If Term::AnsiColor is installed on your system, use this switch to
	   โ  colorize PBS output.
	   โ
	   โ  PBS has default colors but colorization is not turned on by default.
	   โ
	   โ  Colors can be defined through switches (try pbs -h | grep color) or
	   โ  by setting you colors in the environement variable 'PBS_FLAGS', ex:
	   โ          export PBS_FLAGS='-c -ci green -ci2 blink green -cw yellow'
	   โ
	   โ  Recognized colors are :
	   โ          'bold'
	   โ          'dark'
	   โ          ...
	   โ  Check 'Term::AnsiColor' for more information.
	   โโ element colors
	      โโ -cw|color_warning=s = Set the warning color.
	      โโ -ce|color_error=s = Set the error color.
	  
keep logs, output, ... for every run of pbs
	so we have something to look at when somethingg builds, or doesn't, when we expected it not to, even if pbs is most probably right

	one often reruns pbs just to get more information with an extra switch
	if the information is not to be displayed, keep its data in a separate file

	we need a system to cleanup periodically the unnecessary data, an option
	--run_data_limit/-rdl (and --no_run_data) which is set by default to, say 5, and that can be
	changed in the configuration.

		--nrd 		don't keep this run's data
		--rdl 0		never keep run data and remove the data found on disk

		if we keep multiple logs, we will need to keep multiple node data for nodes that are rebuild

	node data should be in the node's digest and only tree data kept in log
		we can reconstruct on the fly

		node digest's name should contain the md5 to ease its localization
		with command line tools

		node data should be kept as string to avoid compiling it when loading the digest
			in comments that we can "uncomment"
			in strings that we can ask the digest to return to us

		the node object could itself be the digest, eg: the node is serialized and it can
		be queried for its digest or data

		node data contains the build output

	* support --jobs
		builder creates node's data files

		master creates 
			warp file
			build sequence (linear, although it can be recreated from the graph if we have a list of triggered nodes)
			build event (queuing, starting, ending) which can be used to create a timeline
		
tree display additive fields
	--tt is the bare tree, one can add elements to the tree via switches
	completion and help are available

tree display color
	node name should be made clear
	additive fields are color like command line switch

HTML output
	terminal that is HTML aware to allow DHTL tree dumps

	fast output
		revert to pure text without html
		display html with max depth set
			user can still open data structure dump further
		load data on demand
			trees are just links

		filters
			show only some of the pbs phases
			show specific node
			show specific subsystem


	pbs shell should support HTML

continuous integration
	keep logs of builds and html interface
		builds are not started via interface nor via commit hooks

	check everything is commited
		commit in a CI repo

	builds when local machine is not powerful enough
		
	start remote build on local machine

	check and reuse environement if possible
		

IPFS as synchronized build cache
	a node to be build can request itself from some other build-node cache

	caches can  synchronize as long as they have disk space so if a node is 
	requested, it can be delivered in parallel from multiple build-nodes
Tmux
	like gnu parallel, in a specific session for the pbs run
		output  in a window or in a pane
		do not keep parts of the builds that succeed by default

	controlled by REH

Build distribution
	the build system can clone itself (and all deppendencies) to another computer
	if a node is changed
		if it impacts many other nodes, the node is synchronized and all the 
		build nodes co-operate to the build

		if it impacts little, we can know that from warp 1.8 data, the build is
		made locally and nodes are synchronized after the build

debugging
	when node fails to build, setup a miniature environment with copies
	of the failing node, the necessary dependencies (a warp tree for the nodes that only be
	present but not used), ... 


	use rules and REH
		ca setup an environment specific to the node type

		Rule
			MATCH_ALL
			REH_ON_FAIL => \&setup debug environment

Tmux test environment
	keep only failing tests
	stop after x number of failing tests
	

three pane debugger with preview
	a ranger like display parents (can be multiple parents), this, children
	preview shows rules, config, ...

debugger
	trace: shows how we got to the point where we are

	"next": show the rules that match, this should also show in the graphical browser

	in case of error show all the relevant data, including the results of the command, and the
	possible output, graphical browser shows what other rules would fail

	break point show type of breakpoint, pre-depend, ...

	set/unset debug point easily and quickly
		set and unset based on some code returned value
			ie, as long as number of nodes in graph < 50 continue
			have a rich data set the functions can work with
			data set is per node, module, level, range of levels, ...

	REH_DEBUG_SET_BREAKPOINT

environment variables
	pbs removes all the environment variables
		this helps but when a sub command fails or produces an unexpected output
		(because it did not check properly) this helps the user very little

	pbs removes all the environment variables if option is set

	pbs replaces all the environment variables with "SET BY PBS" to make it clear

	find a system to "break" the commands that use environment variables

	removal of environment variables should be per node/level
		node/level can set variables

	warnings if environment variables are set or not set

 
debugger watches
	extracted by code snippets from the available data set, they don't have 
	to represent a variable, they can represent whatever, a bit like an element in
	a bash prompt
		
	doesn't have to be perl code or an element of the graph
		ex. a service is available on a remote server
		ex. cpu load, free disk space, ...
	
	good if implemented as debugging REH in a rule

warp does not need normal digest
	when running in warp mode and something need to be rebuild
		this helps but when a sub command fails or produces an unexpected output
		(because it did not check properly) this helps the user very little


warp does not need normal digest
	when running in warp mode and something need to be rebuild
	the no-warp mode building is run; it generates digest files
	and c dependency files. those files are not used by the warp 
	mode. the warp mode should apply to normal build too to avoid
	generating the digests. normal mode data normally ready from 
	digest files can be obtained from the warp file.
	Note that this is not a big problem as digest file generation 
	is trivial and that most of the time is spend computing md5
	which are also needed for the warp file. It does have an 
	"advantage" if the warp data is deleted or a different warp
	mode is selected, the normal mode is fast.

warp 1.8
	can we reduce the format of the warp files, textual amount as
	well as fields in the warp files

	there is ROOT directory in the warp 1.8 data that should not be there!

	single node warp file take the longest to process, is there a way to 
	optimize the process by collating related nodes in the same file?

	node regeneration should not need to set BUILD_NAME
	try to make node regeneration more light weight
		if some rarely used plugins need more data, it is better
		to do more re-generation in the plugins

parallel depend
	done on the subpbs level
	can generate a mini warp
		who merges back
		merging should be distributed too

	merging is mini warp is no necessity, we can follow the chain
	and read multiple mini warp files

	mini warp must merge very quickly
		two data sets
			one with complete data
			one lightweight to merge quickly
				see warp 1.8 node regeneration
			keep a md5 between them
		mini warp have warp 1.8 format
		merging 
			merge checks link errors
			adding node md5 to list
			single node warp files need parent dependent added
			 
	a set of hierarchical mini warp can be merged at multiple levels
		only merge the quick data and keep reference to the complete data

	

warp nodes can be formatted as the reconstructed nodes to speed up loading
	
nodes that are the deepest trigger the most files
	verify them first as they re-vivify the most nodes and we cache those

nodes that trigger often are more likely to trigger again

sample data digest generation for big files
	md5 on a 5 Mb file takes longer than on a 4 kb file
	compute md5 on a few well chosen sections  rather than the whole file

option to generate digests for source files only
	MUCH less secure but much faster

	we should actually CHECK the digests for source only, we can still generate digests
	for generated files, that would give the possibility to run with checking or do an
	external check if needed.  

check optimization in Ag
	https://github.com/ggreer/the_silver_searcher

node name completion can be done with the help of nodes listed in the warp file
	we still need to know which warp file

log all builds
	every command line that builds should be save in a log

keep statistics about what is the most often build
	gives us an idea about what has most impact on the system to build and
	what part of the build system is most often used

	let a user specific post pbs handle that (we can give an example)

file database vs classic database
	files allow direct manipulatiom
	cdb allows fast seach

	why choose?
		generate the files and fill the db

time cursor (see Log)

	a history of the build is kept so that a cursor can be placed at a user chosen
	time when she can look at what the graph looks like, what will happen next, what rules
	inserted a node, ...

	keep a history of the graph generation, a history of the  build makes no sense as we can build in parallel
	and the order changes. It makes more sense to get the build for a specific node and select
	its children or parents to look at their build.

C depender triggering
	if dependency file does not exist, trigger and post generate the file instead for an immediate generation 
	this should be the default but an --option may be added for people that want an analysis not a build

C depender generates digests in mini warp format (because it is exactly that) and the 
	linking of the mini warp nodes for the C depender is no different from other
	mini warp

mini warp does not contain node data, just enough for regeneration

document why, when using warp, the C dependency files are neither used nor verified
	=> they are merged in the warp graph and warp doesn't care about them, but the 
	dependencies are still verified

Output from Hashes must be sorted as Perl randomized the key order

shell build nodes can receive tools, commands and the code to work on from master
	reduce the need for a shared file system

shell build nodes can share code with other nodes
	when the master starts a build, it also starts the sharing of the code, while the
	master works to find what is going to be build, the build nodes share the code.

shel build nodes keep a repository of shared code

shell build nodes can update their repository
 
build system has startup rules that install tools and checkout code
	although checking out the code with the build system (e.g. in the same commit) makes more sense

parallel depend
	OK to have multiple instances (in each process doing the depend) if the common nodes have the
	same digest, including the configuration. if the digests are different we need a mechanism to
	let the user decide what happens next.

documentation is part of every release

REH instead for named dependencies or as a complement
		rule
			named => (c-dependencies => a, b, c), 
			c-dependencies => (a, b, c), 

	this also allows the REH to 'type' the dependencies and itself


REH user defined type
	allow visualization of the REH in a user specified manner
	e.g. also when the dependencies are listed, the dependencies from a specific REH could be in red color


display dependency list 

	Node [V] './objects':
		Inserted at ./pbsfile [PBS]:__ROOT.
		dependencies:
			./1.objects
		rebuild because of:
			./1.objects (Subdependency or self)
		matching rule: #2[B] 'objects'
			=> ./1.objects
	  

	displays the REH that matched and uses the color from the REH type


rebuild because of: ./1.objects (Subdependency or self)
	be precise, dependency or self, or both, and which dependencies


always save the subpbs configuration
	possible to query the configuration for a specific node
	history of configuration is also displayed

build subset
	a better way than node@root and save/load configuration

			  .---------------------.
			  | .---.               |
	       .------------| A |--------.      |
	       |          | '---'        |      |   wait for B to build 
	       v          |              v      |   correctly to build  
	 .-----------.    |            .---.    |
	 | subsystem |    |            | C |    |
	 '-----------'    |            '---'    |
			  |              |      |
			  '--------------|------'
					 |
			  .--------------|------------.
			  |              |            |
			  |              v            |
			  |            .---.          |
			  |        .---| D |---.      |
			  |        |   '---'   |      |  Only build this till OK 
			  |        v           v      |
			  |      .---.       .---.    |
			  |      | E |       | F |    |
			  |      '---'       '---'    |
			  |                           |
			  '---------------------------'


	When building A, if an error occurs, find which subsystem the error occurs in and
	give all the necessary information to build that subset from the command line, see
	setup subset build for a manual setup

	building a subset is like building a specific subpbs with a saved configuration, there is no
	need to build the parents of the subset

	it is possible to limit the build to the first level of the subset even if configuration
	or graph changes are made at the subset level

	when building a subset, make it clear to the user that it is only a subset build so that 
	it is clear that a top build needs to be made, return an error code and the warnings


setup a subset build
	the user can ask the build system to generate the command line to build a specific file or
	subsystem.

	say that a subsystem build a library
		the user can ask for the closes pbsfile to build that library
		the build system
			creates a (universal based) command line
			creates a configuration file copy for the subsystem
	
	the creation is done 
		based on data in the warp file
			if no pbs related files trigger (libs, pbs, pbsfiles) 

		by running the system in depend only mode to generate the necessary data

user defined node type
	subsystem, debug, UI, ..

	the user can give attributes to nodes

	those attributes can be used to 
		display nodes differently
		display the attributes in a --tt
		match rules
		search for the nodes 

	queries can use node type

universal root for build
	it is possible to build from any location
		a cwd not the root of the system to build
			finding the files under . (virtual root)

		a cwd root of the system to build
			normal build

		a cwd under the root of the system to build
			subset build			

subpbs rule should not care about the path of node
	rules now have to match */regex as the start node has a path
	but the path doesn't make sense in the local environment of the subpbs, the nodes
	should get their path based on their parent's path. this would simplify the run of 
	pbs -load_config as we can give the local node name instead.

	some node have path information ./lib/xxx gets under the pbs root under ./lib (late depend)
	some nodes may be related to the root (/)

	before starting a subpbs, the node to depend could get an alias without the path
		

 	this would allow moving whole subsets of the system and still be able to use the warp file
	as is since there is no path recorded anymore




All display code is a plugin, allowing the user to change how the display looks like
	without changing the core code

	use a templating system or subs

	can the display code be triggered by injected rules?

H files are dependencies of the object file
	if two object files use the same C file, the dependencies may be different because of the
	object file configuration. Linking the C file with a configuration that is wrong, when
	depending the second object file, is an error.



virtual nodes without dependencies ALWAYS trigger
	a virtual node without dependencies always trigger
	there is no way we can know if a virtual node without dependencies "succeeded"
	we can know that it failed because the commands it runs fail but if they all succeed
	we don't have a node we can make a md5 on so we must re build the virtual node each  time

	need example of virtual node without dependencies

	this is so frustrating. All those years talking about virtual node digests in complex setup (subpbs linked nodes, warp graphs, ...) when we should have kept it simple and see what the problem is with VIRTUAL, it's simple, we didn't know where to write its digest (that's so hard to decide) and that it didn't trigger. So rather than do the right thing we introduced FORCED, Do I hate make and all the make files that other morons like me wrote that forced things.
	FORCED must die and than everything will be fine because we must do the right thing.
	a virtual node, whatever the context, as it has no digest will ONLY trigger if one of its dependencies also triggers. This means that you can add a virtual node rule and it will never trigger, you can modify a virtual node rule and it will never trigger, virtual nodes don't trigger, they have no control over their triggering, it's the dependencies that trigger them, and the dependencies may trigger for various reasons none of them related to the virtual node rule.
	You can even write a virtual node rule that has dependencies on source nodes, EG document the source nodes, and it will never trigger.
	VIRTUAL nodes don't trigger, so rather than make them trigger properly we FORCED them to trigger, I hate make.
	if virtual nodes have triggers, they will trigger on a dependency that trigger, as before, on source files, and on the pbsfile that where the virtual node rule is defined. 
	Why did we need a virtual node digest? For everything!
	Where to put the virtual node digest is obvious, in the out directory, as everything else. What if they match a directory name, no problem, the directory and the digest don't have the same name.
	It's easy to be smart after the fact but it is pretty obvious that if you don't handle nodes the same way, there are going to be differences, why didn't we handle VIRTUAL  as a normal node? why didn't we handle VIRTUAL as we defined in the documentation " a node that has no physical representation in the file system", a 2 lines check, but instead make a monster out of it.
	Next PBS will be better, VIRTUAL will have a digest. 

	what if the dependency is a virtual node itself, what do we write in the digest?
		the virtual dependency digest!

2 dependents share dependencies. I don't think it will be in the form t1, t2 -> d1, ....
	but rather t1 -> d1, ... ; t2 -> get_deps(t1).
	that allows a tx -> get_deps(t1, t2, whatnot) picking up dependencies other nodes have without having to change t1, t2 pbsfiles. probably late_depend will work on them too so t2 can be dependent on t1 dependencies even if t1 is not in the graph yet


NAME => 'any generated data is exportable to another format',

NAME => 'defining_subpbs_with_a_sub',
LONG_DESCRIPTION => <<'EOD',
	give a sub that checks the type of the node to generate and create
	a virtual subpbs if non exists in the sub directory (for known types)
 
	show a message if a subpbs is generated
	use pbsfile if it exists
	if given --generate_missing_pbsfile, ask if a real
		pbsfile should be generated. practical if the virtual
		generated pbsfile doesn't fit (ex directories or files to ignore, more configurations)


REH to match configurations
	AddRule
		MATCH => $regex
		MATCH_CONFIG => ...

	this is related to REH_IF

REH to match steps in the pbs run
	this is already done in the registration of the REH which doesn't look like rules
		and REH can not be registered to multiple steps 

	it also need to match a node and pbssteps are not nodes (yet)

	a good example is -gtg, we generate a graph at specific moment
		gtg is implemented as a plugin in pbs1, thus pbs calls it

All output is done via a registrable sub to allow PBS2 to be embedded in another
	system, EG: neo

	display system can be setup to display information in specific cases only
		node
		pbsfile
		pbs run
		...


REH  NAMED_CONFIG AND NAMED_CONFIG_GROUP
	no problem adding the REH but how does one get to the config
	by name later?

command line options and wizards
	can a rule match a command line option as if it was a target
		MATCH_CLI => /dd/
		
		how do we define our command line options
			some global place plus in the plugins
	
	wizard is just a target 
		how do we add all the targets?
			just load a library with the rules

plugins
	some are just targets, ie generate_graph, which need to be run at specific
	pbs time

	Rule 'generate_graph'
		MATCH_CLI => /-gtg/
		GENERATE_GRAPH_REH => ....  # knows when to be run


	bleah! make the target a virtual node!
		Rule 'generate_graph'
			MATCH => '__pbs_graph'
			AND_MATCH_CLI => /-gtg/
			BUILD => ...
		
plugins
	some are called during the pbs run, eg they register subs that pbs calls
		EvaluateShellCommand
		CheckNodeName
		
		The problem being is that they are not node specific
		we can eliminate global plugins and query the nodes for the 
		plugins to run. A global plugin simply matches all nodes

	AddRule
		MATCH => $regex
		EVALUATE_SHELL_COMMAND_specific => 1

	We can't audit plugins as we did with pbs1, finding the plugins becomes more
	difficult as they can be inlined 

prefix all the REH that have an impact on internal implementation
	DISPLAY_DEPENDENCIES => 1
	PBS_DISPLAY_DEPENDENCIES => 1

	except if it is the DISPLAY_DEPENDENCIES REH itself that does the displaying

-bni ,which show a node header, makes it clear which node is being build, there is no such system
	for -dd, the display is very compact

NODE_LINKING is a PBS step with potentially matching REH
	what configuration to check
	allowed or not

configuration dependency for node
	knowing what configuration is used to build a node makes it possible to check
	if a linked node uses the same configuration as the current pbsconfig  build node
		maybe the linked node, with a different configuration and dependencies is OK!
			need a mechanism to allow that.

	extract all the configuration variables from the build commands
	force declarative style for linked node checking
		note that this can still check the build commands

	addrule
		name xxx
		regex '*all*'
		NODE_LINKING_ENABLE => 0 # current pbsfile run must provide one

		NODE_LINKING_ENABLE => 1
		NODE_LINKING_CHECK_VARIABLES => ['name', 'name2', ..]
		NODE_LINKING_CHECK_VARIABLES => {'name' => \&checker, ..}
		NODE_LINKING_CHECK_COMMAND_LINE => 1

		
	knowing which configuration is used also allows to not rebuild some nodes declared in
		the same pbsfile because of a configuration change that has no impact
		on the node

if a rule uses sub rules, EG lib uses object rules, when the rules for obj
	are used, the user can easily trace it back to the lib rule and to where it was used
	
	IE. inserted_at is not enough as all libs are inserted at the same place, the lib rule

move statistic display to plugin (or plugins)
	add a plugin display point in pbs

console
	possibility to query between steps

	starts build or loads a graph dump

	loads warp and checks
		query about warp and 	
	
	depend
		can stop
		can add breakpoints
		can query about graph or node
		can generate graphs

	check

	build
		
option so warp information display is mutted

ExcludeFromDigest may not make sense
	use to say that a node is a source node, better call it that
	why not give a digest to a source node
		win time generating and checking it
		forces the node to be treated differently


EvaluateShellCommand REH
	pre-build REH

	does not evaluate the shell command but createa node specific configuration to match %Whaetever
	
	this allows us to define the REH in a user lib and it can be reused

	a better name is REH_EVAL_CONFIG for a generic sub declaration 

REH can be argument less
	they are more like sub calls then

	this allows a more declarative style for the REH tha do not need arguments
		Rule
			Name => 'declarative rule'
			DECLARATIVE_REH,
			...
			;
		
Pbs creators generate mini build systems
	mechanism used to generate and check the creator digest
	pbs command line switches (-bni, -conf, ...) are also used
	
Mini warp are mini build systems
	getting into a sub directory the user shouldn't hav eto do more than "pbs" on the command line
	to build that sub system again, with the top config!

Use file type "matchers"
	rather than use regex use a file type (which still can be implemented as a regex for simple cases)
	the "matcher" can match depending on a configuration (eg the current OS, tool chain, ...)
	
multiple GetBuildName subs defined in the code

Merge STE PBS

Create template/example for STE like data driven pbsfile (neo)

option to filter out/in nodes when displaying tree
	generate list of files that are displayed and not displayed, their amount, ...
	
	if options are pbsconfig variables, the REH an use them

possibility to generate multiple trees with different roots
	to display only the relevant nodes
	can still filter nodes in and out
	
generate DHTML tree


Multiple node builders
	builders run in the order of rule matching
		option to display the builders and their order
		
	builders declare if they are singletons, an error is generated if builders exists before or are added after
	
	
build phases
	a node with multiple builders has its builders run in a specific order
	a builder declares which phase it belongs to
	a rule can declare the phases a builder can belong to 
		check is done for multiple rules declaring different orders
		check is done to verify that each phase has a builder
			should it fail?
	
	
Mechanism, at a higher level, to declare in which order REH are run
	similar to build phases
	
	
Builders chaining
	get all previous builders results
	get information pointer to the previous builder
	get the last builder build buffer
		can request the build buffers of all the previous builders
		
	builder can make variables available after build
		eg: tell the rest of the build chain what files are created, ...
		

Build buffers 
	switch to keep build buffers
		filter which ones are kept
			faild ones always kept

failed build buffer
	always keep the buffer
		garbage collect the filters after successful build
			rule matching all the files
			do we want to garbage collect at the global level or after each node, after each subpbs, ...
				object_files can collect the names of the buffers to garbage collect

			do we keep the build buffers in case of multiple failures?
		
		
	keep information about the builder
	create a mini build system
		configuration
		possibility to run just that builder/ builders for a node
		
	
possibility to display the tree in warp mode
	global tree, warp tree
	filters should still apply
	
File not found for MD5 computation
	most probably a node that is not declared as virtual (although we have defined somewhere that virtual nodes should have a digest)
	builder failed
	=> display as much information as possible
		mini build system for just that error
		
generation of mini build systems
	in big systems, the developer does not want to re-run the build system just to find out what the problem is but wants a small build to debug the problem
	
Post pbs 
	can be implemented with a rule that matches the pbs run virtual node
		better than a rule that matches a target in case there are multiple runs of the pbsfile with different targets
		REH_POST_PBS => \&post_pbs_sub
		REH_POST_PBS => GetPBSConfig('POST_PBS_FILE')
		
	C depender should use the flags defined by the user rather than force flags on the user
	
	
override after **------ -dpl
	don't know what I meant
	if subpbs run (two extra phases here prepare to run subpbs and run subpbs, plus subpbs ran) matches a rule, it can display something else
	
	
Make clear how build command line parameters (%FILE_TO_BUILD, ...) are defined and handles
	also defined in plugins or rules
	
	
plugin to generate report on configuration usage
	a post pbs part of the examples in the distribution 
	
	configuration in, defined, used, delta with parent, delta with children (available after the subpbs runs)
	knowing how many configuration variables (along with rules, targets) can be used to automatically find what pbsfiles should be split
	
give example of C code generation
	or anything that needs to be depended
	explanation and example of IMMEDIATE_BUILD or creators
	
Creator, IMMEDIATE_BUILD, VIRTUAL, FORCED
	all can be REH!
	
rethink/document IMMEDIATE_BUILD FORCED, LOCAL_RULES and other exceptional mechanisms

put generated file and source file under version control
	allows us to run pbs and undo what the run as done
		we can pattialy undo if we want

	
IMMEDIATE build in a REPL
	user can point at a node and ask to have it build
		a bit like IMMEDIATE_BUILD
	

IMMEDIATE_BUILD
	first depend the node then build it before returning from the node's depend phase
		what if the node has a late dependency?
			warn, error, wait till all the late dependencies are available to run the node's
				IMMEDIATE_BUILD (fancy!)

CREATOR differs from IMMEDIATE_BUILD as the node is immediately available for other depender to run on it
	eg: C file creator has the node on disk before the C file depender runs on it
	
	if IMMEDIATE_BUILD was used, the C_depender wouldn't find the file on disk

	one solution to run multiple rules
		IMMEDIATE_BUILD C -> some dependencies
			create C

		C -> C_DEPENDER
			CC C -o ...

		the problem is that rules are often loaded and the first rule must be registered before the standard C rule
			but we have a solution! as the rules are named it is possible to ask for a rule to be run before or after another

		in rule.pm
			[NAME] C -> C_DEPENDER
				CC C -o ...


		use rule.pm

		IMMEDIATE_BUILD C -> some dependencies
			BEFORE_RULE => NAME
			create C

	next problem is that a node that has been depended (possibly by multiple rules in the same package) will
		not be depended again but linked to

		the example above works as all the rules are in the same package but if the are created in one package 
		and the rules to build them are in another package, those rules will not be run

	next problem is that the node is build twice and nodes are never build twice
		a solution would be to make the node as not build but immediate build, that stops us to immediate build a node twice


	we REALLY want IMMEDIATE_BUILD to be a normal build and CREATOR to be an IMMEDIATE_BUILD because we just have one system then
	and there is no need to handle digests, caches, warp in a special way as we do for CREATOR in pbs1

		CREATOR is useful on it's own, interestingly it's not needed if it's dependent is an IMMEDIATE_BUILD node!
			creator is run at depend time but if the dependent is iMMEDIATE_BUILD it will be build at depend time and
			all it's dependencies will also be build, so the CREATOR node can be a normal node with a normal builder

	REH_CREATOR can run before the depend step
		here's a requirement that says REHs can define their step name and put it before other steps
			REH_CREATOR, STEP_CREATOR before STEP_DEPEND


		REH_CREATOR has its own dependencies
		REH_CREATOR can do whatever it wants, including generating a build system and run it!
			we don't need to generate files (PBS_CONTENT) but it's a good idea, we get a log of the build to
				pbs generates a file for PBS_CONTENT anyway
			
			it's possible to run pbs (since we are in pbs) and ask the core to build in a different graph layer

			it's possible to run pbs as an external command and as it to generate a layer that is imported

			it's possible to run another build system, or even a bash script, an import nodes after


importing graph layer
	pbs can serialize and import layers generated by other builds


REH_TRIGGER rather than pbs functionality
	starts a subpbs before the REH_LINK_TO
	
C_FILE_SYNCH
	it's a post build REH
	Make it visible
	
ON_ERROR REH
	for un interesting parts of the build just ignore the failures
		need to make it very clear
		
		
Express complicated dependencies
	references to dependency lists, but still locally defined
	depender subs are all mighty already
	simple interface to the dependers, better wizard
	
user defined wizards
	possibility to have multiple wizard directories 
		no need to put user wizards where pbs wizards are

replace plugins with rules
	CheckNodeName, rule matching all nodes
	CreateDump, rule matching top node, what if the build fails
	CreateLog, rule matching top node, what if the build fails
	EvaluateShellCommand, replace with EVAL_CONFIG, there is no reason to evaluate the shell command just
		to handle %SOMETHING. Adding SOMETHING to the config as the side effect to be self documenting
			- SOMETHING stays visible rather than transient during EvaluateShellCommand
			- the rule doing the evaluation is logged
	ExpandObjects, just a specific EvaluateShellCommand that should only define a configuration variable
		can be used directly as a REH (pre build) in specific rule:
			Rule
				Name => 'some_lib'.
				Match ...
				...
				ExpandObject,
				Build => "linker %DEPENDENCY_LIST_OBJECTS_EXPANDED"
				EndRule

			or as a REH global in the pbs run
			
			use 'Lib/ExpandObjects' ;
			# which contains
				Rule
					Name => 'expand object'.
					MatchAll,
					ExpandObject,
					EndRule

			or use the top rule injection mechanism at the top and have the rule available everywhere
			
	FileWatchClient, REH CHECK
		advantage, 
			nodes checked individually, maybe some optimization can come from it
				IE: node does not have to check itself if dependency has triggered already

		disadvantage:
			
	GraphGeneration, rule matching top, or any node if sub graph is wanted
	PackageVisualisation, rule matching all nodes
	PostPbs, rule matching top node, what if build fails?, can we have nodes representing PBS steps?
	SimplifyRule, a simplified, named, REH
	TreeVisualisation, rule matching top or any node
	Visualisation (-dc and other node visualisation switches), rule matching any node


	making the plugin match nodes means that we can run some functionality at any level we want
		IE: sub graph, sub tree, ....

		timing REH
			today we get timing for the whole build or a pbsfile run, we could get information
			per node or sub system

		most display options, especially if we have pbs, pbs step, config, ... nodes


plugins cli switches handling
	today:
		so they are called, ie: --generate_tree_graph
		so they get arguments, ie: --tree_graph_file xyz.png
		so they get options , ie: -- tree_graph_no_configuration
	
	call plugins/plugin-directory like switches?

	=> scan directory for switches?
		call a registration sub, let it register itself, return registration data
			cache the registration if libs are unchanged
				could be useful to cache the rules
					cache them in memory if server is used
	
	=> solution
		remove possibility to set path in prf, instead have a pbs_set.prf, this removes the need
		to run pbs.prf.
		
		pbs can scan the cli itself, as it already does, for cli path options

		
	defining "plugin" switches
		plugins are replaced by pbsfiles, libs really), so any pbsfile can ad switches
			the switches are scanned at start time, the pbsfile is loaded and registration
			sub is called in the pbsfile, the registration sub is replaced by a NOP sub, or
			a verification sub to catch non scan-registrated pbsfile which call the sub.

		the pbsfiles that define switches need to be declared in pbs_set.prf
			pbs can scan a single file, a directory, a directory with sub directories, use
			regex to select or deselect specific files when scanning a directory

		the options can take arguments, be called multiple times (array), ...

		option definition contains a help text

	user can define it's own switches via sub in a pbsfile (lib) where options are defined
		define aliases for pbs switches, eg: for switches that do not have short versions or simpler names
		switch grouping, eg: --debug for "-dd -dur -post_pbs ..."
		alias for -D, eg: --user_defined 1 => goes into the config as -D special=1 would do
			a nicer looking integration of the user's process

	we can verify which user defined switch that was put on the command line was not used during the run
		and warn user!

	option can add target
		also good for pbs so we can make some pbs options rules
			-h, -v, -gtg, -tt, ...

	user options can be cached so the pbsfiles defining them do not need to be reloaded
		"generating user options cache ..." # no cache
			--display_option_cach_generation
				shows what files are scanned and what options are added

			--no_user_option_override makes the optionsimmutable 

		"" # silent if cache is valid
		"regenerating user option cache", same options as above apply
		
help is a target
	option -h still exists but it adds a target to the top pbs

	let -h display user help rather than pbs help, user decides by renaming rules if they want

	possibility to tailor the pbs help by removing or reordering entries which is not easy when the
	help is part of PBS distribution.


wizards are rules and started with targets
	wizards target and normal target can be mixed, which is surprising and maybe should be warned for

	wizards are still defined in the wizard directory for pbs but user wizards could be anywhere as long
		as the rules are included in the pbsfile

	option -w can add the targets

keep a list of all the files loaded
	libs, pbs modules, prf, plugins, ...

	keep in warp file (today we have prf data entries but it's not set properly!)


warp file is a pbs run file
	it contains information about a build
	some of the information is warp speedup information
	warp 0 has a warp file


if a hierarchical display is requested (IE pbs config for all pbs runs, config, ...)
	display a delta between the level
	if no delta, display changed values in different colors
	if config is local, display it in special color

	use two color scheme for levels
		eg: level % 2 in green, level !% 2 in bright green or cyan ...
		it's easy to miss the level change in large data amounts

256 color mode if the terminal supports it
	not 256 color but different colors for different elements, user defines colors sequences they want
		we stop using Terminal::AnsiColor
			or recognize "red on blue" otherwise use the user code
			or immediately tranform "red on blue in the config" which is a user config so we don't care about it

Immutable rule set
	pbsfiles that always generate the same rules 
		no if-else or REH_IF used to decide which rules are added
		they can use configuration variables in the builders

	can be cached in memory
		pbsuse should be faster
		in server memory in between pbs tool runs

	may be serialized in a more efficient format than the pbsfile

	cache is invalidated when pbsfile is changed (clearly!)

